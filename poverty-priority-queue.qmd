---
title: "Poverty and Priority Queueing"
author: "Marcos Gallo and Kavya Rajagopalan"
date: "2023-07-10"
abstract: |
  Pre-existing literature suggests that relative material scarcity – particularly wealth inequality – is a significant contributing factor in dictating how people behave. We characterize irrational decision-making across impoverished groups by examining the effects of inefficiency in time and effort allocation. We experimentally model time allocation in low SES groups by administering an artificial priority queue where agents must attend to tasks with differing levels of effort, urgency and value. Observations suggest that individuals from low SES groups prioritize urgent tasks while agents from high SES groups prioritize high value tasks.
execute:
  echo: false
  warning: false
format: 
  pdf: 
    documentclass: report
    toc: true
    number-sections: true
    colorlinks: true
    code-line-numbers: true
    keep-tex: true
    include-in-header:
      - text: |
          \usepackage{dcolumn}
---

```{r init, warning=FALSE, include=FALSE}
library(tidyverse)
library(tidymodels)
library(stringi)
library(viridis)
library(latticeExtra)
library(rstan)
library(pglm)
library(factoextra)
library(psych)
library(gt)
library(stargazer)
library(texreg)

# © 1998-2023 RANDOM.ORG
# 
# 496181801	
# Timestamp: 2023-08-02 17:58:21 UTC
set.seed(496181801)

reticulate::use_condaenv(condaenv = "py-poverty")

```

``` {r load-pilot}
load("./Models/pilot/joint_pilot.Rdata")
load("./Models/pilot/prolific1StanData.Rdata")
load("./Models/pilot/MTurk_sample_nolimit2.Rdata")
demograph <- qualtrics[qualtrics$PROLIFIC_PID %in% joint_pilot$participant,]

```

# Introduction

Poverty is a multi-dimensional problem, and behavioral scientists have focused on the effects of the environment on the decision-making process across socio-economic levels (Bertrand et al., 2004). Their underlying assumption is that humans share the same underlying biology and psychology, and that "poverty" causes significant changes in people's environments and, in turn, their decisions. For example, living in poverty often means having a limited set of options in life (from choosing what to have for dinner to which occupation to pursue), and it increases the number of demands in terms of time and mental resources (Banerjee & Duflo, 2012). This lack of control over choices leads to a chronic state of vigilance and stress (Chemin et al., 2013).

In this paper, we focus on the trade-offs between urgency and importance in day-to-day decisions. It is hypothesized that, in the mass of to-dos and responsibilities, those with limited resources have to leave specific tasks undone. Consequently, we argue that they may not have time to complete all tasks or the necessary money and, as a result, must decide what to prioritize in their lives. Although one could theoretically calculate the most optimal course of action, it is improbable that individuals would take this actuarial approach. Instead, we argue that they are more likely to use heuristics or intuition to decide what problem to address, where to spend money, and what to leave undone. Such heuristics, however, are prone to fail under particular circumstances.

We argue that, under the strain faced by the poor, a series of behaviors and physiological phenomena arise. Making "urgent versus important" trade-offs causes stress and anxiety levels to increase and shift attention towards specific features of a choice. We propose that an environment of poverty shifts the weight placed on the urgency of a task (e.g., estimating that urgent tasks will "come back to bite" much faster than others and estimating that nonurgent opportunities are unlikely to disappear or change). This urgency mindset may increase stress and anxiety levels, leading the poor to spend significant portions of their income on tobacco, alcohol, and lotteries (Banerjee & Duflo, 2007; Blalock et al., 2007; Haisley et al., 2008; World Health Organization, 2021). Individuals in low socio-economic groups tend to save too little (Shurtleff, 2009) frequently borrow at exorbitant interest rates (Banerjee & Duflo, 2007; Skiba & Tobacman, 2008), and limit preventive healthcare services (Lusardi et al., 2010).

## Poverty Traps

We argue that the poor are caught in an "urgency trap," where neglect of nonurgent tasks may cause an increase of urgency in the future. For example, not undergoing regular medical check-ups may increase susceptibility to unexpected illnesses.

This phenomenon is closely related to the theory of poverty traps. This framework defines a self-perpetuating phenomena that arise when an economy is caught within a cycle that suffers from persistent undevelopment. In this paper, we model poverty traps as an equilibrium which favors disutility over iterative cycles. To determine causal relationships between such outcomes and the behavior of low SES (type 1) agents, we examine cases of suboptimality that are distinct from high SES (type 2) agents. To assess self-reinforcing behavior intrinsic to poverty traps, we classify and compare the choice behavior of type 1 agents in regards to their time allocation.

### Priority Queues, Urgency and Importance

Although some scientists have proposed a "Scarcity" view of poverty (Mullainathan & Shafir, 2014), their conclusions have not withstood the scrutiny of science, leaving the causes and mechanisms of these phenomena largely unexplained (O'Donnell et al., 2021). We seek a more rigorous understanding of how relative-poverty can be self-perpetuating through poor time allocation. We explain prioritization of day-to-day tasks as an attempt to balance two requirements: (1) maximize life satisfaction given one's limited resources, and (2) minimize the potentially harmful effects of leaving tasks undone change with time. We call the former requirement "importance" and the latter "urgency" (Bratterud et al., 2020).

The Eisenhower Matrix (see @app-eisenhower for details), a simple tool for determining optimal long-term decisions, is a simplification of how individuals determine their queue for attending to daily tasks. This framework uses dimensions of urgency (time scarcity) and importance (expected value maximization) as primary motivations for which tasks require completion. We intend to characterize the mapping between urgency $U$ and importance $I$ , namely $\{ U,I \} \mapsto \mathbb{R}$. As discussed in @sec-poverty, the literature speculates the influence of effort costs in decision-making - thereby suggesting Eisenhower Matrices should be modified to account for the added parameter.

# Theory

In this section, we present a novel decision-making model that underpins various real-life activities, from mundane daily choices to high-stakes strategic decisions. When individuals face multiple action options, they select the one that maximizes perceived value or utility. Our model integrates urgency, importance, and value, drawing on principles from decision theory, the Eisenhower matrix, and Markov Decision Processes (MDPs) (Puterman, 1994; Eisenhower, 1961).

## **Conceptual Framework**

In our model, urgency refers to the time-sensitivity of a decision or the period until a choice is no longer viable. This concept captures the temporal aspect of decision-making, reflecting that opportunities for action often have a limited lifespan. For example, deciding to invest in a rapidly changing market or respond to a time-limited offer requires considering urgency. Importance is the value of a decision state, contingent on future states and transition probabilities. This concept captures the strategic aspect of decision-making, reflecting the reality that the consequences of a decision often depend on future events and conditions. For example, investing in education or training may be important because it affects future career opportunities and earning potential (Howard, 1960). Value is the present-discounted reward from choosing an action, incorporating the opportunity cost of a choice, which is the value of the best choice one must forego. This concept captures the economic aspect of decision-making, reflecting that resources such as time, money, and effort are limited and that choosing one action can often mean giving up the opportunity to choose another (Bellman, 1957). The optimal policy balances immediate rewards with future rewards, considering urgency, importance, and likelihood. It depends only on current, not past, states (Bellman, 1957).

### Model Components

The model comprises several components inspired by the structure of MDPs, a mathematical framework for modeling decision-making in situations where outcomes are partly random and partly under the control of a decision-maker (Howard, 1960).

**State Space**: The current situation or context. Each state is associated with a set of possible actions. The state space captures the situational aspect of decision-making, reflecting that the available choices often depend on the current circumstances. For example, deciding to invest in a particular market depends on the current market conditions (Sutton & Barto, 2018).

**Action Space**: The available actions in a given state. Each action leads to a transition to a new state. The action space captures the behavioral aspect of decision-making, reflecting the reality that different actions can lead to different outcomes. For example, the decision to invest in a risky asset can lead to a high return or a significant loss (Daw et al., 2005).

**Transition Probabilities**: The likelihood of transitioning from one state to another, given a particular action. Transition probabilities capture the inherent uncertainty and randomness in real-world decision-making scenarios. For example, the decision to invest in a risky asset involves uncertainty about the future state of the market (Daw et al., 2005).

**Rewards**: The outcomes or results of a particular action from a given state. Rewards can be 1) immediate or delayed, and 2) positive (benefits) or negative (costs). The concept of rewards captures the motivational aspect of decision-making, reflecting that the desire to achieve positive outcomes and avoid negative ones can often drive decisions (Sutton & Barto, 2018).

**Discount Factor**: Reduces the value of future rewards to reflect that individuals value immediate rewards more highly than future ones. The discount factor encapsulates the decision maker's time preference or discount rate. For example, investing in a long-term project involves discounting the future benefits to reflect their present value (Bellman, 1957).

**Policy**: This strategy defines which action to take in each state. The policy can be deterministic (always choosing the same action in a given state) or stochastic (choosing among several actions with specific probabilities). The concept of policy captures the strategic aspect of decision-making, reflecting that decisions often involve a sequence of actions over time (Puterman, 1994).

### Comparison to the Two-Step Task

The two-step task is a well-established paradigm in cognitive neuroscience used to assess two types of reinforcement learning: model-free and model-based learning. Model-free learning depends on the direct association between actions and their outcomes. In contrast, model-based learning involves planning and decision-making through a mental model of the task structure (Daw et al., 2005). The proposed decision-making model can be related to the two-step task, providing a richer understanding of the dynamics involved in these types of learning. In the two-step task, participants make two sequential decisions that navigate them through two "stages" defined by different stimuli. The first-stage choices lead to one of two second stages with varying probabilities, and each second-stage choice is associated with some probability of receiving a reward. The goal of the subject is to maximize rewards in the second stage, which requires continuous learning and adaptation to the changing reward probabilities.

For example, consider the first stage with an initial state that includes two choices: "buying a phone" or "taking a course." The transition probabilities are defined by the likelihood of moving to the second stage, given the first-stage choice. For instance, choosing "taking a course" could lead more often to a state where one gets a promotion (State 2a), while "buying a phone" could lead more often to a state where one does not get promoted and keeps the same job (State 2b). In the second stage, the state spaces include another choice, such as "buying a car." In State 2a (getting a promotion), the decision maker could choose "buying a phone" or "buying a car," where the car would be brand new and fancy, reflecting the increased financial resources in this state. In State 2b (keeping the same job), the decision maker could choose "taking a course" or "buying a car," where the car would be cheap and used, reflecting the lower financial resources in this state. In this context, both stages have rewards associated with the actions that are not a result of the transition to future states. Specifically, buying a phone would lead to immediate subjective value (e.g., the thrill of having a new gadget), and so would education (e.g., the fulfillment of getting a diploma or gaining knowledge). The value of each action, however, is the sum of its associated reward and the value of all future states weighted by their respective transition probabilities. The policy in this context would be the strategy that defines which action to take in each state. For instance, the decision maker might adopt a policy of always choosing the action with the highest immediate reward or adopt a more complex strategy that considers each action's urgency, importance, and value. Key in this decision is also the discount factor, which reflects the decision maker's time preference or discount rate. For instance, the decision maker might value the immediate pleasure of buying a phone more highly than the potential future benefit of a promotion (Daw et al., 2005).

```{mermaid}
graph TD
    A[First Stage: Buy Phone or Take Course] -->|70%| B[Second Stage: Keep Job]
    A -->|30%| C[Second Stage: Get Promotion]
    B --> D[Choices: Take Course or Buy Used Car]
    C --> E[Choices: Buy Phone or Buy New Car]

```

### Priority Queuing

In our two-step task example, we observed how the unchosen task was "transferred" to the next state. This characteristic is a crucial feature of a priority queueing model, which we will delve into to enrich our understanding of decision-making dynamics further.

Priority queueing models often represent ordinal choices of tasks attended to based on some subjective value or utility function. These models are prevalent in various real-world scenarios, such as triaging bays, which treat queues as a function of urgency and order of arrival, and donor matching programs, which facilitate queues based on a point system that weights time, severity, and likelihood of survival.

Cobham and Barabasi have developed two critical priority queueing models. Cobham's model treats a queue as an infinite list of tasks with varying task arrival times and execution rates. On the other hand, the Barabasi model treats the queue as a finite size list with waiting times ($\tau_w$). The mathematical expression for the waiting time distribution in the Barabasi model is as follows:

$$
P(\tau_w) = \left\{
            \begin{array}{ll}
            1 - \frac{1-p^2}{4p}\ln\frac{1+p}{1-p},\\
            \frac{1-p^2}{4p(\tau_w - 1)}[(\frac{1+p}{2})^{\tau_w-1} - (\frac{1-p}{2})^{\tau_w - 1}],
            \end{array}
            \right.
$$

Interestingly, as \$p \\rightarrow 0\$, this distribution reduces to an inverse Poisson distribution. This expression is independent of the priority distribution, suggesting that the alignment of task priorities has no role in the time for these respective tasks to be executed.

Despite their powerful predictions, these existing models for priority queues have limitations in their applications. The literature is scarce about priority queuing in marginalized groups and how priority queuing is rationalizable. Some literature describes priority queues as a double-sided matching market with queues that depend on priorities and impatient customers (Castro et al., 2020). In this literature, customers of high value are matched prior to those of low value. Likewise, impatient customers can leave the queue if they are not matched immediately with a customer of their priority. This behavior is representative of many real-life cases but does not align with the behavior that the extended literature from Role Strain suggests about the decision-making choices of individuals from low SES. There is an apparent disconnect between how the average individual prioritizes tasks and how individuals from low SES do.

In our model, we aim to bridge this gap by integrating the principles of priority queueing into the decision-making process. By considering each task's urgency, importance, and value, we can create a more nuanced and realistic representation of how individuals allocate their time and resources. This approach allows us to capture the complexities of decision-making in a way that traditional models cannot, providing a more comprehensive understanding of the dynamics involved in model-free and model-based learning.

In the next sections, we will explore how this integration of priority queueing into our model can provide new insights into the decision-making process, particularly in the context of individuals from low SES.

## Simulation

Priority queue models offer a tangible mechanism for capturing the choices and inter-event times that agents require when making decisions about daily tasks. Drawing on the existing literature surrounding poverty, we simulate an artificial priority queue using a priority function:

$$
\text{Priority} = \alpha U + (1- \alpha) I
$$ {#eq-prio}

where $U, I, \alpha$ represent "urgency," "importance," and the urgency weight, respectively.

Our first step is to run a discrete-event simulation (DES) to uncover the relationship between $\alpha$, the probability of survival, and burstiness measures. DES is a technique for modeling stochastic, dynamic, and discretely evolving systems, making it a powerful tool for understanding complex decision-making processes (Banks, J., Carson, J. S., Nelson, B. L., & Nicol, D. M. (2005). Discrete-Event System Simulation. Prentice Hall.). In this framework, we consider:

1.  An individual who is capable of completing any job,
2.  A ready supply of jobs with no prospect of any shortages,
3.  Jobs are allocated a priority when they arrive in the queue according to @eq-prio,
4.  The time taken to complete a job is variable but independent of the task.

We define the completion time for the different activities as random draws from an exponential distribution with $\lambda = 5$. Similarly, the interarrival times for tasks are from an exponential distribution of $\lambda = 5$. Each incoming task receives $U, I \sim \text{Unif}(0,1)$ and a priority according to @eq-prio. Tasks are completed in the order of priority.

Importantly, each task contains a survival rate as a function of its importance. The higher the urgency, the more likely the task will fail (or die off). This feature internalizes the fact that urgent tasks may bring imminent negative consequences. A Weibull distribution with a monomial function gives the survival probability of a task:

$$
\Pr (\text{survival}|\alpha = s(1+U),\beta=1) = 1 - e^{(-t/\alpha)^\beta}
$$

where $t$ is the wait time, and $s$ is a scaling parameter (in the following simulations, calibrated to 100). As such, each task contains a survival probability, which is then accumulated throughout the task, such that the cumulative survival rate of later tasks are smaller than those of earlier ones.

By simulating this queue, we can graph a heatmap with the relationship of the weight of urgency on the priority function (\$\\alpha\$) and cumulative survival rate:

```{r}
#| cache: true
#| label: img-simmer-simulation
#| img-cap: "Probability of Survival by Urgency Weight"

urgency_survival_grid <- read_csv("urgency-survival-grid.csv") %>%
  rename(time = mean_time) %>%
  filter(!is.na(mean_survival)) %>%
  filter(time < 20) # Anything greater is close to 0

levelplot(mean_survival ~ time * weight, urgency_survival_grid, 
          panel = panel.levelplot.points, cex = 0
    ) + 
    latticeExtra::layer_(panel.2dsmoother(..., n = 200))

```

@img-simmer-simulation shows that those with higher urgency weights are more likely to survive longer in the queue. This finding suggests that the weight of urgency in the priority function plays a significant role in determining the survival probability of tasks in the queue. This finding underscores the importance of considering both urgency and importance when prioritizing tasks, particularly in contexts where survival rates are critical, such as in decision-making scenarios faced by individuals living in poverty.

## Integrating Our Model with Poverty {#sec-poverty}

Integrating our model with poverty is crucial in understanding its complex dynamics and effects on various aspects of life. Poverty is not just a state of financial deprivation but a multifaceted issue that affects health, education, and overall quality of life (Barrett et al., 2016). Our model aims to capture the combined effect of these complexities.

We integrate poverty by considering it a multidimensional variable that influences and is influenced by various factors: 1) Poverty can affect health outcomes by limiting access to healthcare services and nutritious food. In turn, poor health can exacerbate poverty by reducing a person's ability to work and earn income; 2) Social factors can be determinants of poverty. These include education, employment, and social support, which can significantly influence a person's likelihood of falling into poverty; 3) Poverty is not a fixed state but a condition that changes with time and circumstances. People can move in and out of poverty over time. Though past research has explored the dynamics of these three phenomena, we offer a novel integration of these physical, mental, social, and temporal determinants into our priority queueing model.

### Temporal Discounting

Temporal discounting, as a behavioral economic concept, plays a pivotal role in our model, particularly in poverty. It refers to the well-established tendency to value immediate rewards at the expense of future outcomes (Frederick et al., 2002). This bias is often associated with lower wealth. It is more pronounced in populations with lower socioeconomic status (SES) (Ruggeri et al., 2022, The globalizability of temporal discounting. Nature Human Behaviour).

In our model, we incorporate temporal discounting as a critical factor influencing the decision-making process of individuals in poverty. The model allows for flexibility in the rate of temporal discounting, and individuals with lower SES are likely to have higher rates. In the context of poverty, temporal discounting can exacerbate financial difficulties. For instance, individuals facing financial strain may opt for immediate, smaller rewards instead of larger, delayed ones, potentially perpetuating a cycle of poverty (Haushofer & Fehr, 2014, On the psychology of poverty. Science).

To illustrate this, consider the decision-making process in our model. The decision-maker, who is in a state of poverty, is faced with two choices: "Work an extra shift" or "Attend a free community college class." The former offers an immediate reward, while the latter promises a future benefit. According to previous findings, some decision-makers in low SES are likely to choose the immediate reward due to the higher rate of temporal discounting. In many cases, the immediate need for financial resources outweighs the potential future benefits of attending a class. Our model captures this behavioral preference through a discount factor, denoted by $\gamma$.

However, this decision-making process is dynamic. It evolves as the decision-maker's circumstances change and as they gain more information about the potential future benefits of their actions. For instance, if the decision-maker learns that attending a class could significantly increase their future income, they might be more inclined to choose this option, even if it means forgoing the immediate reward of working an extra shift. This ability to foresee or predict future states is central to our model, and the following section will address it.

### Foreseeing Future States

Individuals with lower SES often face uncertainty and instability, which can cloud the decision-making process, making it difficult to foresee the long-term consequences of their actions (Mullainathan & Shafir, 2013). This uncertainty is not merely a passive process but an active one. A study by Peters and Büchel (2010) found that the ability to vividly imagine future events can reduce temporal discounting.

Individuals likely learn to imagine future events in their social environments. Notably, community trust plays a significant role in this temporal discounting. Research by Farah and Hook (2017) suggests that SES significantly predicts high temporal discounting, particularly in environments characterized by low community trust (Farah & Hook, 2017, Trust and the poverty trap. Proceedings of the National Academy of Sciences). This finding implies that trust within a community can serve as a buffer against temporal discounting, encouraging individuals to make more beneficial decisions in the long term. Perhaps one channel through which this modulation occurs is learning from one's peers' experiences and expanding their set of imagined possible states, particularly for actions with small immediate rewards.

McIvor and Paton (2007) present an interesting example of social influences in future state prediction. Specifically, they look at preparedness for natural hazards and show that people are more likely to take precautions against earthquakes if they are part of a community that encourages safety measures and if they believe that taking action will have a positive impact on their safety. This finding suggests that the relationship between individuals and their community, including their trust in community institutions, can significantly influence their ability to visualize and predict future states (McIvor and Paton, 2007, Preparing for natural hazards: normative and attitudinal influences).

### Transition Probabilities

Transition probabilities, which determine the likelihood of moving from one state to another, play a crucial role in our model. These probabilities influence individuals' choices based on their actions' potential outcomes, and correctly estimating them is essential to maximizing value.

In the context of decision-making strategies, psychologists have identified two primary approaches: model-free and model-based strategies. Model-free strategies do not rely on transition probabilities but evaluate actions based solely on their reward history (Daw et al., 2005). On the other hand, model-based strategies rely on transition probabilities, using a cognitive model of potential actions and their consequences to make goal-directed choices (Daw et al., 2005). The balance between these two strategies can be fluid and contextually sensitive, with the reliance on a given strategy depending on the cognitive and affective demands placed on the individual (Otto, Gershman, et al., 2013, The curse of planning: dissecting multiple reinforcement-learning systems by taxing the central executive; Otto, Raio, Chiang, Phelps, & Daw, 2013, Working-memory capacity protects model-based learning from stress. ).

Previous research has found that factors such as stress and education levels can affect the proportion of model-free and model-based strategies used in decision-making. Research suggests stress can also impact decision-making, leading to a greater reliance on model-free strategies (Schwabe & Wolf, 2013, tress and multiple memory systems: from 'thinking' to 'doing'). Furthermore, education levels can influence the ability to use model-based strategies, with higher education levels associated with greater use (Worthy et al., 2011, Heterogeneity of strategy use in the Iowa gambling task: A comparison of win-stay/lose-shift and reinforcement learning models).

### Urgency

Our model is beneficial for analyzing the decisions of individuals in low-SES (Socioeconomic Status) environments. Here, we build on the two-stage decision-making model by incorporating urgency. In the first stage of our model, the decision-maker, an individual encounters two choices: "Work an extra shift" or "Attend a free community college class." The choice of "Work an extra shift" predominantly leads to a state where the individual has extra money (State 2a), while "Attend a free community college class" more frequently leads to a state where the individual gains new skills (State 2b). The urgency component is crucial in this stage. The opportunity to work an extra shift is fleeting, available only on the current day. If not seized, this opportunity will expire, and the potential for additional income will be lost. Conversely, the community college class, part of a recurring weekly course, presents a less urgent choice. The individual could attend the class the following week, but missing classes could lead to a cumulative knowledge gap, jeopardizing the overall benefit of the course. In the second stage, the state space expands to include another choice. In State 2a (having extra money), the individual could choose between "Buy groceries" or "Pay utility bills." In State 2b (gaining new skills), the individual could opt to "Apply for a better job" or "Start a small business." Urgency is also a pivotal factor in the second stage. The utility bill payment is due imminently, and failure to pay will discontinue essential services. On the other hand, buying groceries, while a recurring necessity, may not have the same urgency. However, a prolonged delay in this action could lead to health and well-being implications, underscoring its medium-term urgency.

```{mermaid}
flowchart TD
   subgraph "State s"
   A1[Buy Phone]
   A2[Take Course]
   end
   subgraph C[State s'2: Get Promotion]
   E[Buy Phone and Used Car \n or\n Take Course]
   end
   subgraph B[State s'1: Keep Job]
   D[Buy Phone \n or\n Buy Used Car]
   end
   A1 -->|70%| B
   A1 -.->|30%| C
   A2 -.->|30%| B
   A2 -->|70%| C
```

To illustrate the role of urgency in decision-making, we will use a mathematical representation of our model. We will consider a simplified version of the two-stage decision-making scenario described above, focusing on the first stage, where the decision-maker must choose between "Work an extra shift" or "Attend a free community college class."

Let us denote the state of the decision-maker by $s$ and the set of available actions by $A(s) = \{\text{``Work an extra shift"}, \text{``Attend a class"}\}$. The urgency of action $a \in A(s)$ is the time limit $T_a$, after which the action is no longer available.

The decision-maker's policy $\pi$ determines the action to take in each state. The policy is a function of the current state and time, $\pi(s, t)$, and it changes over time as the urgency of the actions changes.

The value $V(s, t)$ of a state $s$ at time $t$ is the expected future reward when following policy $\pi$, discounted over time:

$$V(s, t) = \mathbb{E}_{\pi}\left[R(s_t, a_t) + \gamma \sum_{s' \in S} P(s' | s_t, a_t) V(s', t+1)\right],$$

where $R(s_t, a_t)$ is the immediate reward from taking action $a_t$ in state $s_t$, $P(s' | s_t, a_t)$ is the transition probability from state $s_t$ to state $s'$ given action $a_t$, and $\gamma \in [0, 1]$ is the discount factor that determines the present value of future rewards.

The urgency of an action affects the value of a state by limiting the time available to take the action. As the deadline $T_a$ approaches, the decision-maker's available time budget decreases, constraining the set of feasible actions.

Now, consider the case where "Work an extra shift" is an "immediate-reward task" with a high reward of $R_{\text{work}} = 100$ and a short deadline of $T_{\text{work}} = 1$ day. If the decision-maker does not work the extra shift within one day, they will miss the opportunity to earn additional income. However, this action does not significantly change the future state values, as working an extra shift does not lead to a permanent increase in income.

On the other hand, "Attend a class" is a "future-reward task" with a lower immediate reward of $R_{\text{class}} = 10$ and a longer deadline of $T_{\text{class}} = 7$ days. If the decision-maker does not attend the class within a week, they will miss the opportunity to gain new skills, which could lead to better job opportunities and higher future state values.

The optimal policy $\pi^*$ balances the immediate rewards with the future rewards, considering the actions' urgency and potential future benefits. It is given by:

$$\pi^*(s, t) = \arg\max_{a \in A(s)} Q(s, a, t),$$

where $Q(s, a, t)$ is the action-value function that represents the expected future reward from taking action $a$ in state $s$ at time $t$:

$$Q(s, a, t) = R(s, a) + \gamma \sum_{s'} P(s' | s, a) V(s', t+1),$$

where $P(s' | s, a)$ is the transition probability from state $s$ to state $s'$ given action $a$.

In this case, if the decision-maker follows the optimal policy, they will choose "Work an extra shift" on the first day due to its high immediate reward and urgency and then "Attend a class" on the subsequent days to maximize the potential future benefits. This example illustrates how the urgency of tasks and the distinction between immediate and future rewards can influence the optimal decision-making policy. By incorporating urgency into the decision-making model, we can capture the temporal dynamics of real-life decisions and provide a more accurate representation of the decision-making process.

### Suboptimal Time Allocation

Inefficient time allocation of daily tasks is another factor that can contribute to the persistence of poverty. Individuals make a sequence of decisions and bargains to reduce the strain of their daily demands and roles in a process similar to an economic decision: Allocating limited resources such as energy, time, emotions, and goods in different ways (Goode, 1960). For individuals from a higher SES, delegating these roles becomes far more manageable, and the bandwidth to tackle other tasks increases significantly. The converse is true, however: the poorer one is, the more uncontrolled demand for time and money.

A recent study by Jachimowicz et al. (2022) provides a compelling illustration of this phenomenon. The authors found that financial scarcity is associated with greater distress intensity in everyday life. They propose that financial resources allow individuals to reduce the distressing impact of everyday hassles, increasing one's life satisfaction. This research suggests that financial scarcity shrinks the sense that one can use economic resources to reduce the adverse impact of daily hassles. While money may not necessarily buy happiness, it reduces the intensity of stressors experienced in daily life---and thereby increases life satisfaction.

In the context of our model, suboptimal time allocation can exacerbate the effects of poverty, leading to a cycle of immediate-reward task selection and persistent financial scarcity. The immediate reward of completing a task and reducing the day's demands can outweigh the potential future benefits of tasks that require more time and effort. This feature is particularly true for individuals facing financial scarcity who may not have the luxury of investing time in tasks with delayed rewards.

The ability to delegate tasks significantly alleviates this burden. Delegation allows individuals to offload tasks to others, freeing up their time and mental resources. This advantage is especially beneficial for urgent tasks, which can consume a disproportionate amount of time and attention. However, the ability to delegate is often a privilege reserved for those with sufficient financial resources. For individuals facing financial scarcity, the cost of delegation may be prohibitive.

By incorporating these dynamics into our model, we can better understand the decision-making processes of individuals in different socioeconomic circumstances.

### Role Strain

Introduced by sociologist William Goode in 1960, the concept of role strain motivates our theoretical framework. Goode proposed that individuals, faced with an impossibility of satisfying all role demands, engage in role decisions and bargains to modulate these demands. This process necessitates allocating limited resources such as time, emotions, and goods across various role obligations. The ultimate goal is to minimize perceived role strain, defined as the cognitive and emotional exertion involved in fulfilling duties (Goode, 1960).

Role strain is particularly salient among individuals experiencing poverty, who often grapple with an elevated effort dimension or the subjective value ascribed to task completion. Morris and Coley's 2004 study on role strain correlates among mothers revealed many factors that amplify "strain" in this demographic, many of which are income-related (Morris & Coley, 2004). A separate study on family caregivers of adult cancer patients in Kenya further exemplifies this phenomenon. The researchers discovered that these caregivers, typically under financial strain, experienced significant role strain due to the simultaneous management of multiple responsibilities (Mugenda et al., 2020). These findings underscore the disproportionate burden of role strain borne by those in poverty, who must navigate a labyrinth of tasks and roles with scarce resources.

Adding tasks to already demanding circumstances intensifies role strain, while providing social support to assist with tasks can mitigate it (Lewis, 1989 <https://www.jstor.org/stable/2784697).> A proposed cause of poverty traps is the tendency of impoverished individuals to overcommit to high-urgency tasks, thereby neglecting or under-committing to high-effort or high-importance tasks.

Goode's theory differentiates between role conflict, where two roles present mutually exclusive demands, and role overload, where an individual lacks the resources to meet the demands of multiple roles. The latter is particularly pertinent to our research objectives. Role overload arises when an individual is tasked with fulfilling multiple roles concurrently and struggles to meet these roles' demands. For instance, a full-time student may concurrently struggle to care for young children (Nickerson, C. (2023) <https://www.simplypsychology.org/what-is-role-strain-in-sociology.html).>

Our model seeks to elucidate how task overload influences decision-making processes and outcomes, contributing to our understanding of poverty dynamics.

### Scarcity

The intricate interplay between poverty and cognitive function is critical to socioeconomic studies. Individuals from lower socioeconomic strata often grapple with a dearth of resources, significantly influencing their behavioral patterns and cognitive abilities. This observation has sparked investigations into the so-called "scarcity mindset," a psychological state hypothesized to precipitate three primary cognitive effects: attentional drift, pronounced trade-off thinking, and diminished mental bandwidth (de Bruijn & Antonides, 2022). These cognitive shifts, in turn, can elucidate common behavioral characteristics observed among those of low socioeconomic standing, including overborrowing, more consistent consumption decisions, and increased time discounting and risk aversion (de Bruijn & Antonides, 2022).

For instance, experiments designed to induce a scarcity mindset by deliberately limiting resources revealed that participants demonstrated heightened focus on tasks due to the limited opportunities for success (Shah et al., 2012; Shah et al., 2019). While this increased focus improved efficiency and accuracy in task completion, it also increased borrowing and elevated stress levels, making tasks increasingly taxing and requiring more attention. However, other studies suggest that further evidence is required to substantiate these conclusions (de Bruijn & Antonides, 2022).

Moreover, the assertion that poverty reduces mental bandwidth and increases time discounting and risk aversion requires further empirical support (O'Donnell et al., 2021). Current studies only partially align with empirical data and need more precision for a comprehensive understanding (de Bruijn & Antonides, 2022). Notably, a replication study by Shah et al. (2019) examined how different forms of scarcity affect attention and borrowing behavior, finding no evidence that scarcity on one task leads to cognitive fatigue on subsequent tasks, thereby contradicting the results from Shah et al. (2012).

In a more recent study, Madsen et al. (2022) conducted a field experiment using Danish unemployed social assistance recipients to test the psychological consequences of scarcity. The researchers randomly assigned survey recipients to three groups: (a) those surveyed before receiving social assistance benefits, (b) those surveyed after receiving them, and (c) those surveyed in the middle of the month. Interestingly, they found no impact of the scarcity manipulation (those surveyed before payment) on the mindsets of social welfare recipients. However, they did find that subjective scarcity, or "the feeling of having too little," correlated positively with an increased focus on problem-solving but negatively with psychological well-being, mastery, and job search self-efficacy.

The relationship between poverty and cognitive function is complex and multifaceted. While scarcity can lead to heightened focus and efficiency in task completion, it also induces a scarcity mindset that can lead to suboptimal decisions and behaviors. Our theory builds on this literature and suggests that people must balance their current and future expenses when they have limited budgets and uncertain incomes. This strain can be challenging and requires attention, executive control, and working memory, leaving fewer cognitive resources for other less urgent tasks. As such, we seek to understand the mechanisms underlying these effects and how they may perpetuate poverty.

## Affective States

The present study proposes that the behavioral deviations observed in individuals living in poverty, specifically the overweighting of urgency, are mediated by affective states such as stress and anxiety. This proposition is rooted in the understanding that stress and anxiety can significantly influence decision-making processes. For instance, a meta-analysis by Starcke and Brand (2016) found that stress generally increases risk-taking.

Indeed, individuals of low socioeconomic status (SES) often report feeling overwhelmed, which can exacerbate stress and anxiety. A study by Williams (2018) on populations of color, who often experience low SES, found that race-related stressors can significantly affect mental health, leading to higher levels of psychological distress. Similarly, a study by Heers and Lipps (2022) found that almost one fifth of parents reported feeling overwhelmed by homeschooling obligations during the Covid-19 pandemic, with women, mid-aged and lower-educated individuals, as well as those with young children and a lower income, being particularly affected. This feeling of being overwhelmed did not cause changes in life satisfaction, stress, and negative affect, but it did lead to a decrease in positive affect.

The intricate relationship between poverty and mental health has been the subject of extensive research, with numerous studies suggesting a bidirectional link between the two. Poverty can exacerbate mental health issues due to the stress and strain of living in financial hardship. In contrast, mental health issues can lead to poverty due to reduced productivity and employment opportunities (Lund et al., 2010). Ridley et al. (2020) further corroborated this relationship, highlighting the detrimental impact of mental illness on economic outcomes.

As mentioned, the stress and tension arising from role strain are central to our hypothesis. Morris and Coley (2004) identified several factors that increase role strain among mothers, including low income, lack of social support, low education, lack of health insurance, and reliance on government welfare.

Similarly, Stack and Meredith (2018) found that single parents are at high risk of financial hardship, leading to poor mental health and low psychological well-being. Single parents often experience higher levels of chronic stress, loneliness, and depression, despite making extensive efforts to meet their financial obligations.

Thus, our proposed model suggests two channels through which role strain may increase the urgency bias. The first channel posits that the subjective experience of strain, which can be exacerbated by factors such as low income, lack of social support, and reliance on government welfare, can lead to an urgency bias in decision-making. The second channel suggests that the stress and anxiety resulting from role strain can also lead to an urgency bias.

```{mermaid}
%%| fig-width: 5
flowchart LR
  A[Income] --> B{Role Strain}
  C[Social Support] --> B
  D[Education] --> B
  E[Health Insurance] --> B
  F[Gov't Welfare] --> B
  B --> G(Subjective Ratings of Strain)
  B --> H(Stress and Anxiety)
  G --> I(Urgency Bias)
  H --> I
```

<!-- # Literature Review -->

## Research Questions

1.  How do urgency and importance shape task selection, and what are the underlying cognitive processes that drive these effects?

2.  To what extent does Socioeconomic Status influence task prioritization, and what is the mediating role of role strain in this process?

3.  What are the key affective mechanisms that contribute to suboptimal time allocation, and how do they interact with cognitive and environmental factors?

# Pilot Experiment

## Methodology

Our experimental design simulates the environment of an ice cream parlor using an interactive online game. The game was developed in PsychoPy version 2023.1.3 and hosted on the Pavlovia platform. Participants played the role of ice cream parlor owners whose goal was to maximize profit by completing tasks with varying characteristics.

### Structure

In the game interface, participants saw a queue of tasks representing ice cream orders on the sides of the screen. Each task varied according to three characteristics: effort, importance, and urgency. These characteristics corresponded to icons on each task image to aid the participants' decision-making process, as depicted in @img-choice.

![Example of two tasks with differing levels of Importance (Value), Effort, and Urgency.](images/tasks_example.png){#img-choice}

1\. Effort: We operationalized effort through the number of clicks required to complete an order. More complex orders required more elements on the ice cream, some of which were relatively difficult to discern (e.g., the different types of sprinkles). We deem tasks with more elements, or hard-to-discern elements, more effortful.

2\. Importance (value): We equate importance with subjective value, represented by dollar signs on the image. A single dollar sign indicated low importance (yielding one point), while two dollar signs indicated high importance (yielding two points). The points were the participants' earnings, and each point was worth \$0.05. The total earnings, a proxy for the participant's performance, were displayed at the top of the screen.

3\. Urgency: We used clock icons on each image to convey the degree of urgency of a task. Two clock icons denoted a high-urgency order, while one clock icon represented a low-urgency order. High-urgency tasks lost value (dollar signs) if participants did not complete them in a given round (e.g., an urgent task worth 2 points would become an urgent task worth 1 point in the next round, and an urgent task worth 1 point would lose all of its value). If a high-urgency task lost all its value, it would disappear from the queue, and the participant was "punished" by having only one order in the queue for the following two rounds. Conversely, low-urgency tasks stayed in the queue until selected and completed.

In each round, participants saw the screen shown in @img-pilot-exp. They were instructed to select a task from the queue (left or right) and click on the matching ice cream icons in the center of the screen to complete it. If they made a mistake, they could use the trash can icon to discard the current order and start over. The game continued for a total of 20 orders. Participants were not restricted to a specific order of task completion; they could choose any task from the queue at any time. This open-choice design allowed us to observe and analyze the decision-making and prioritization strategies employed by the participants. Note that we incentivized players in the game by offering a prize of up to $\$1.00$ , contingent on the total number of points players accumulated throughout the game.

### Simulation

We devised a theoretical model for how we expect rational decision-making to manifest in our priority queuing experiment such that frequency of deviations from rationality can be monitored. To formalize the optimal, or rational, set of behavior for maximizing rewards over long-term exposure in a queue, we developed a closed-form model. We hypothesize that this decision-making process reduces to a simple subjective-value function, where every individual determines the priority or preference $\succeq_q$ by the subjective value utility representation. We thus developed a stochastic model, as follows:

$$
\begin{aligned} 
V(s) &= \max\limits_{a}(r(s,a) + \gamma\sum\limits_{S}P(s,a, s')V(s'))\\
    S &= \{HHU \times HHU, HHU \times HH0, LHU \times LHU, …\}\\
    r(a,s) &= i_a - c_a\\
    R &= {r(HHU, HHV \times HHU) = 1 - c_H, …}\\
    V(s_{final}) &= \max\limits_{a}(r(s_{final}, a))
\end{aligned}
$$

In @eq-model the agent calculates the value of state $s' \in S$ (which is the next state, i.e., next period). $i$ is the reward (in dollars) for completing a task, $c_i$ is the effort cost (estimated in dollar unites), and $r(a,s)$ is the net payoff of completing action $a$ at state $s$. $P$ is the probability of transitioning from state $s$ to another state $(s')$, given that our agents takes action $a$ in state $s$. $V(s')$ is the value of that new state. We subsequently sum these results over all the possible future states. Note we use $\gamma$ as our discount factor. In our normative model, we set the discounting factor to be 1, given the tasks are very close to each other in time. Note that this model only has two cost parameters $c=\{c_L, c_H\}$.

We build upon this by then generating an optimal protocol for identifying the best set of choices at any stage for maximizing long-term outcomes. Using dynamic programming, a recursive method of taking the outcomes of subgames and applying it to the entire scheme, we identify which tasks should be chosen at any given stage of the 2-task queue. Given this framework, we can graph the ratio of urgent choices at each given state, as a function of the cost parameter $c_H$ and the discount factor (here $c_L = 0$ for all cases).

```{r}
#| label: fig-dynaprog-simulation
#| fig-cap: "Percentage of Urgent Choices"

urgency_ratio_grid <- read_csv("data/Pilot/urgency-ratio-grid.csv")
urgency_ratio_grid <- urgency_ratio_grid %>%
  rename(gamma = `...1`) %>%
  pivot_longer(!gamma, names_to = "cost", values_to = "urgent") %>%
  mutate(cost = as.numeric(cost))

levelplot(urgent ~ cost * gamma, urgency_ratio_grid, 
          panel = panel.levelplot.points, cex = 0
    ) + 
    latticeExtra::layer_(panel.2dsmoother(..., n = 200))

```

@fig-dynaprog-simulation shows that the optimal percentage of urgent choices varies by around 0.10, with lower probabilities centered around low cost parameters and high discount factors.

## Hypotheses

We hypothesize that many participants may rush their decisions due to the induced scarcity, which could lead to stress and potentially affect their performance. To gather data on participants' socioeconomic status and anxiety levels, we administered pre- and post-experiment surveys.

While certain task scenarios in the game require minimal cognition (e.g., a high value, high urgency task will always be prioritized), other scenarios present more complex decisions. For instance, when presented with a high importance, low urgency task and a high urgency, low importance task, the optimal course of action may not be immediately clear. We analyze the choices made by participants under these circumstances to gain insight into their prioritization strategies.

## Data

We administered our experiment over both Mturk and Prolific. In our MTurk administration, we acquired N = 22 participants, and via Prolific, N = 53. Here, we treat these samples as independent replications.

```{r}
#| label: data-wrangling-pilot
ordered_factor <- function(fact_var) {
  categories <- levels(fact_var)
  n_cat <- length(categories)
  cont <- matrix(data = 0, nrow = n_cat, ncol = (n_cat - 1))
  cont[col(cont) < row(cont)] <- 1
  rownames(cont) <- categories
  colnames(cont) <- paste(categories[2:n_cat],
                          categories[1:(n_cat - 1)],
                          sep = " vs. ")
  contrasts(fact_var) <- cont
  return(fact_var)
}

joint_pilot %>%
  group_by(platform) %>%
  mutate(
    high_income = 
      case_when(as.numeric(income) >= median(as.numeric(income), na.rm = TRUE) ~ 1,
                as.numeric(income)  < median(as.numeric(income), na.rm = TRUE) ~ 0),
    high_anxiety = 
      case_when(stai >= median(stai, na.rm = TRUE) ~ 1,
                stai  < median(stai, na.rm = TRUE) ~ 0)
  ) %>%
  mutate(
    high_income = factor(high_income,
                         ordered = TRUE,
                         labels = c("Low Income", "High Income")),
    high_anxiety = factor(high_anxiety,
                          ordered = TRUE,
                          labels = c("Low Anxiety", "High Anxiety"))
  ) %>%
  # Extract the indeces which differ for each variable: 
  mutate(
    heart = (u1 != u2), # <-- index @ which diff urgency
    dollar = (i1 != i2), # <-- index @ which diff importance
    effort = (e1 != e2), # <-- index @ which diff effort
    left_choice = (choice == "L"), # < --- index when left is chosen
    right_choice = (choice == "R"), # <--- index when right is chosen
    split = ((u1 != u2) & (i1 != i2) & (u1 != i1)), # <--- "hard" decision
    ui_leftsplit = left_choice*split, # <--- "hard" decision AND left is chosen
    ui_rightsplit = right_choice*split
  ) %>% 
  # Find the means of the values:
  mutate(
    huli = case_when(split == 0 ~ NA,
                     ui_leftsplit  == 1 & u1 == 2 ~ 1,
                     ui_rightsplit == 1 & u2 == 2 ~ 1,
                     ui_leftsplit  == 1 & u1 == 1 ~ 0,
                     ui_rightsplit == 1 & u2 == 1 ~ 0),
    luhi = case_when(split == 0 ~ NA,
                     ui_leftsplit  == 1 & i1 == 2 ~ 1,
                     ui_rightsplit == 1 & i2 == 2 ~ 1,
                     ui_leftsplit  == 1 & i1 == 1 ~ 0,
                     ui_rightsplit == 1 & i2 == 1 ~ 0)
  ) -> joint_pilot

joint_pilot$income <- ordered_factor(joint_pilot$income)
joint_pilot$education <- ordered_factor(joint_pilot$education)
```

```{r}
#| label: wrangle-stai-demo
qualtrics <- read_csv("data/Pilot/PrioQ - Consolidated_January 13, 2022_18.42.csv")
qualtrics <- qualtrics[-c(1:2),]
vars <- c("Q36", "Q37", "Q39", "Q40", "Q42", "Q45", "Q46", "Q47", "Q50", "Q51",
          "Q34", "Q35", "Q38", "Q41", "Q43", "Q44", "Q48", "Q49", "Q52", "Q53...54",
          "Q26", "Q27", "Q32")
qualtrics <- qualtrics %>%
  mutate(across(all_of(vars), as.numeric))
qualtrics <- qualtrics %>%
  mutate(
    stai = (Q36 + Q37 + Q39 + Q40 + Q42 + Q45 + Q46 + Q47 + Q50 + Q51 +
      5*10 - Q34 - Q35 - Q38 - Q41 - Q43 - Q44 - Q48 - Q49 - Q52 - Q53...54),
    age = 2021 - Q26
  ) %>%
  rename(
    income = Q32,
    education = Q27
  )
```

```{r}
#| label: processing-data
participants_df <- aggregate(points ~ participant, data=joint_pilot, FUN = mean)
demograph <- merge(y = qualtrics,
                  x = participants_df,
                  by.y = "PROLIFIC_PID",
                  by.x = "participant")
ip2zip <- read_csv("data/ZIPcode/ip2zip.csv")
demograph <- merge(y = demograph,
                   x = ip2zip,
                   by.y = "IPAddress",
                   by.x = "IP")
### HERE:
poverty <- read_csv("data/ZIPcode/ACSST5Y2019.S1701_data_with_overlays_2021-12-21T174024.csv")
poverty <- poverty %>%
  dplyr::select(NAME,S1701_C03_001E) %>%
  mutate(ZIP = as.numeric(str_sub(NAME, start= -5))) %>%
  dplyr::select(-NAME)
demograph <- demograph %>%
  left_join(poverty, by = "ZIP")

income <- read_csv("data/ZIPcode/ACSST5Y2019.S1903_data_with_overlays_2021-11-16T180635.csv")
income <- income %>%
  dplyr::select(NAME,S1903_C03_001E) %>%
  mutate(ZIP = as.numeric(str_sub(NAME, start= -5))) %>%
  dplyr::select(-NAME)
demograph <- demograph %>%
  dplyr::select(-"IP") %>% ## Remove IP for privacy and cleaning
  left_join(income, by = "ZIP") %>%
  mutate(
    S1701_C03_001E = as.numeric(S1701_C03_001E),
    S1903_C03_001E = as.numeric(S1903_C03_001E)
  )


rm(ip2zip, income, poverty)

```

```{r}
#| label: accuracy-code
# Extracting parameter values
ShinyStan_2 <- summary(MTurk_sample_nolimit2)$summary
costs <- data.frame(matrix(nrow = 56))
costs$cL <- ShinyStan_2[c(5:60),1]
costs$cH <- ShinyStan_2[c(61:116),1]
costs <- costs[,-c(1)]

# With estimated parameters, find optimal choice
ev <- c(0,0)
value <- c(0,0,0,0)
#Tsubj <- Tsubj$n
value_lookup = model_data$value_lookup
counterpart <- model_data$counterpart
choice_best <- as.data.frame(matrix(0, 56, 40))
Tsubj <- model_data$Tsubj
state_lookup <- model_data$state_lookup
prob_weight <- model_data$prob_weight
opt_st <- model_data$opt_st
#opt_st <- opt_st[,-c(1)]
for (i in c(1:model_data$N)) {
  ev <- c(0,0)
  ch <- matrix(0, 80, Tsubj[i])
  st <- matrix(0, nrow = 52, ncol = Tsubj[i])
  
  # Declaring values for each option, lookup table (make it loop later)
  value[1] = 2 - costs[i,2];
  value[2] = 1 - costs[i,2];
  value[3] = 1 - costs[i,1];
  value[4] = 2 - costs[i,1];
  for(option in c(1:80)) {
    ch[option, Tsubj[i]] = value[value_lookup[option]]
  }
  for(state in c(1:52)) {
    if (ch[state_lookup[state,1], Tsubj[i]] >= ch[state_lookup[state,2], Tsubj[i]]) {
      st[state, Tsubj[i]] = ch[state_lookup[state,1], Tsubj[i]]
    } else if (ch[state_lookup[state,1], Tsubj[i]] < ch[state_lookup[state,2], Tsubj[i]]) {
      st[state, Tsubj[i]] = ch[state_lookup[state,2], Tsubj[i]]
    }
  }
  ev[1] = ch[as.numeric(opt_st[i, Tsubj[i]]), Tsubj[i]]
  ev[2] = ch[counterpart[as.numeric(opt_st[i, Tsubj[i]])], Tsubj[i]]
  if (ev[1] >= ev[2]) {
    choice_best[i, Tsubj[i]] = 1
  } else {
    choice_best[i, Tsubj[i]] = 2
  }
  
  if (!Tsubj[i] == 1) {
    
    for (t in c(1:(Tsubj[i]-1))) {
      round_back = Tsubj[i] - t
      for(option in c(1:80)) {
        weighted_value = as.numeric((prob_weight[option,])) %*% st[,(round_back + 1)]
        ch[option, round_back] = value[value_lookup[option]] + weighted_value
      }
      for(state in c(1:52)) {
        if (ch[state_lookup[state,1], round_back] >= ch[state_lookup[state,2], round_back]) {
          st[state, round_back] = ch[state_lookup[state,1], round_back]
        } else if (ch[state_lookup[state,1], round_back] < ch[state_lookup[state,2], round_back]) {
          st[state, round_back] = ch[state_lookup[state,2], round_back]
        }
      }
    }
    for (t in c(1:(Tsubj[i]-1))) {
      ev[1] = ch[as.numeric(opt_st[i, t]), t]
      ev[2] = ch[counterpart[as.numeric(opt_st[i, t])], t]
      if (ev[1] >= ev[2]) {
        choice_best[i, t] = 1
      } else {
        choice_best[i, t] = 2
      }
    }
  }
}

#####  Accuracy of all trials
# Ignores people with less than 10 trials:
choice <- model_data$choice
choice_best <- choice_best[Tsubj > 10,c(1:36)]
choice1 <- choice[Tsubj > 10,-c(1)]
choice1[choice1 == 0] <- NA
choice2 <- choice_best
choice2[choice2 == 0] <- NA
comparison <- (choice[Tsubj > 10,] == choice_best)
comparison[is.na(choice2)] <- NA
Accuracy <- rowMeans(comparison, na.rm=T)
Accuracy <- cbind(Accuracy, as.character(demograph[Tsubj > 10,]$participant))
Accuracy <- merge(x = Accuracy, y = demograph, by.x = "V2", by.y = "participant")
Accuracy$Accuracy <- as.numeric(Accuracy$Accuracy)

comparisonLONG <- as.data.frame(comparison) %>%
  cbind(as.character(demograph[Tsubj > 10,]$participant)) %>%
  rename(participant = `as.character(demograph[Tsubj > 10, ]$participant)`) %>%
  pivot_longer(cols = c(1:36), values_drop_na = TRUE, names_to = "round", values_to = "Optimal") %>%
  mutate(round = as.numeric(round))

## Adding poverty measure
joint_pilot <- joint_pilot %>% 
  left_join(demograph[,c(2,10:11)], by = "participant") %>%
  group_by(participant) %>%
  arrange(points) %>%
  mutate(round = row_number()) %>%
  ungroup()

joint_pilot <- demograph %>%
  dplyr::select("participant","S1701_C03_001E","S1903_C03_001E") %>%
  right_join(joint_pilot,by = "participant") %>%
  left_join(comparisonLONG, by = c("participant", "round")) %>%
  ungroup() %>%
  mutate(poverty_zip = as.vector(scale(as.numeric(S1701_C03_001E))),
         median_income_zip = log(as.numeric(S1903_C03_001E)))

trade_off_accuracy <- joint_pilot %>%
  group_by(participant) %>% 
  filter(length(RT) >= 10) %>%
  filter(u1 != u2, i1 != i2, i1 != u1) %>%
  mutate(Urgency = ifelse(u1 == 2 & choice == "L", 1,
                          ifelse(u2 == 2 & choice == "R", 1, 0 )))
```

### Demographics

For both Mturk and Prolific, we distinguish high-low income and high-low anxiety by a median split. The high income mean is about 70k, while the low income mean is around 30k $(p<0.001)$. Likewise, the high anxiety mean score is 56.29, while low anxiety mean score is 37.17 $(p<0.001)$.

+------------------+------------+----------------------+----------------------+----------------------+
| MTurk\           | Mean       | Median               | Min                  | Max                  |
| N=22 x 20 trials |            |                      |                      |                      |
+:=================+:===========+:=====================+:=====================+:=====================+
| Age              | 34.53      | 33                   | 19                   | 50                   |
+------------------+------------+----------------------+----------------------+----------------------+
| Income           |            | \$40,000 to \$49,999 | Less than \$10,000   | \$90,000 to \$99,999 |
+------------------+------------+----------------------+----------------------+----------------------+
| Education        |            | Bachelor's degree    | High school graduate | Master's degree      |
+------------------+------------+----------------------+----------------------+----------------------+
| STAI             | 44.21      | 47                   | 20                   | 67                   |
+------------------+------------+----------------------+----------------------+----------------------+

+------------------+------------+----------------------+----------------------+----------------------+
| Prolific\        | Mean       | Median               | Min                  | Max                  |
| N=53 x 20 trials |            |                      |                      |                      |
+:=================+:===========+:=====================+:=====================+:=====================+
| Age              | 30.13      | 28                   | 18                   | 75                   |
+------------------+------------+----------------------+----------------------+----------------------+
| Income           |            | \$40,000 to \$49,999 | Less than \$10,000   | \$90,000 to \$99,999 |
+------------------+------------+----------------------+----------------------+----------------------+
| Education        |            | Bachelor's degree    | High school graduate | Master's degree      |
+------------------+------------+----------------------+----------------------+----------------------+
| STAI             | 45.04      | 45                   | 20                   | 68                   |
+------------------+------------+----------------------+----------------------+----------------------+

: The two samples display similar demographics

### Measures of Poverty

Although income-based measures have long been the standard for assessing poverty, studies have since determined that purchasing power and standard of living are not accurately measured by such a metric (CITE). Rather, relative deprivation and state-trait anxiety measures are often more accurate empirical measurements of an individual's socioeconomic status (SES).

#### Self-Reported Income

Though the simplest measure to collect, self-reported incomes has a number of limitations. Participants may have the incentive not to divulge their true income levels. This bias can occur in both directions depending on the context and demand effects (e.g., a participant may want to appear richer or poorer than they actually are). Further, because exact income, when combined with other demographic measures, could potentially be used to identify participants, it is customary to elicit income brackets (vs. absolute income levels). This limitation may also reduce power and granularity in the our analysis.

#### ZIP code Measures

To supplement the self-reported income data and account for any potential measurement errors, we employed additional economic indicators based on participants' ZIP codes. The Internet Protocol (IP) addresses collected automatically by Qualtrics were used to determine the ZIP code of each participant's location. From these ZIP codes, we extracted relevant economic data, including median income and poverty measures, which provided a broader context for each participant's socioeconomic status.

The poverty measures in our analysis come from the American Community Survey (ACS) conducted by the U.S. Census Bureau. The ACS determines poverty status based on a set of income thresholds that vary by family size and composition. It provides a comprehensive and nuanced understanding of poverty by incorporating the complexity of family structures and income levels into its poverty thresholds.

The median income data we used is also sourced from the ACS. This data reflects the median income distribution across all households and families within each ZIP code, including those with no income. As a result, it provides a robust measure of the overall economic status of the communities in which our participants reside.

For a more detailed understanding of these measures, please refer to the ACS Subject Definitions document available at [this link](https://www2.census.gov/programs-surveys/acs/tech_docs/subject_definitions/2021_ACSSubjectDefinitions.pdf).

#### ¶Composite Measure (PCA)

Given that poverty is a multidimensional variable, we attempt to capture it through a series of questions (see @questionnaires for details). We created several questions about physical, mental, and monetary deprivation. We then summarized these results in a PCA. We use only the top two components, as per the Scree plot:

```{r}
#| label: img-pcascree

# PCA
qualtrics[,c(55:141)] <- sapply(qualtrics[,c(55:141)],as.numeric)
qualtrics.prepca <- 
  qualtrics[,c(55:141)][,(apply(qualtrics[,c(55:141)], 2, var, na.rm=TRUE) != 0) &
                          !is.na(apply(qualtrics[,c(55:141)], 2, var, na.rm=TRUE))]
qualtrics.prepca <- qualtrics.prepca %>%
  add_column(PROLIFIC_PID = qualtrics$PROLIFIC_PID)
qualtrics.prepca <- na.omit(qualtrics.prepca[!is.na(qualtrics.prepca$PROLIFIC_PID),])
qualtrics.pca <- prcomp(qualtrics.prepca[,-c(48)], center = TRUE, scale = TRUE)
### Scree plot
fviz_eig(qualtrics.pca)
# Results for Variables
qualtrics.var <- get_pca_var(qualtrics.pca)
# Results for individuals
qualtrics.ind <- get_pca_ind(qualtrics.pca)
deprivation <- as.data.frame(qualtrics.ind$coord[,c(1:2)])   # Coordinates
deprivation$PROLIFIC_PID <- qualtrics.prepca$PROLIFIC_PID

qualtrics <- qualtrics %>%
  left_join(deprivation, by = "PROLIFIC_PID")

qualtrics <- qualtrics %>%
  select(PROLIFIC_PID, IPAddress, stai, income, education, age, Dim.1, Dim.2)

```

```{r data for pcacorrelations}
write_csv(qualtrics, file = "data/Pilot/qualtrics.csv")

```

```{r}
#| label: fig-pcacorrelations
#| fig-cap: "Plot"
#| layout-ncol: 2

## PCA internal relationships
# Creating the plot
plot(qualtrics$income, qualtrics$Dim.1, pch = 19, col = "lightblue",
     xlab="Income", ylab="Component 1")
# Regression line
abline(lm(qualtrics$Dim.1 ~ as.numeric(qualtrics$income)), col = "red", lwd = 3)
# Pearson correlation
text(paste("Correlation:", round(cor(qualtrics$Dim.1, as.numeric(qualtrics$income), use = "complete.obs"), 2)), x = 6, y = .7)

plot(as.numeric(qualtrics$income), qualtrics$Dim.2, pch = 19, col = "lightblue",
     xlab="Income", ylab="Component 2")
# Regression line
abline(lm(qualtrics$Dim.2 ~ as.numeric(qualtrics$income)), col = "red", lwd = 3)
# Pearson correlation
text(paste("Correlation:", round(cor(qualtrics$Dim.2, as.numeric(qualtrics$income), use = "complete.obs"), 2)), x = 6, y = .7)
########
plot(qualtrics$stai, qualtrics$Dim.1, pch = 19, col = "lightblue",
     xlab="Anxiety", ylab="Component 1")
# Regression line
abline(lm(qualtrics$Dim.1 ~ qualtrics$stai), col = "red", lwd = 3)
# Pearson correlation
text(paste("Correlation:", round(cor(qualtrics$Dim.1, qualtrics$stai, use = "complete.obs"), 2)), x = 40, y = -2)

plot(qualtrics$stai, qualtrics$Dim.2, pch = 19, col = "lightblue",
     xlab="Anxiety", ylab="Component 2")
# Regression line
abline(lm(qualtrics$Dim.2 ~ qualtrics$stai), col = "red", lwd = 3)
# Pearson correlation
text(paste("Correlation:", round(cor(qualtrics$Dim.2, qualtrics$stai, use = "complete.obs"), 2)), x = 40, y = .7)

```

##### "Dimension 1" top 5 contributors:

(Higher dimension values = higher "depression")

1.  How would you rate your mental health over the past 4 weeks? (1-5)
2.  Please select Yes or No for each of the following questions (YES = 1, NO = 2).
    a.  I am happy about achieving something good in the last 4 weeks.
    b.  Depressed and unhappy.
3.  Over the past 2 weeks, how often have you felt down, depressed, or hopeless?
4.  Over the past 2 weeks, how often have you felt little interest or pleasure in doing things?

##### "Dimension 2" top 5 contributors:

(Higher dim. values = higher "concern for mental health")

1.  How important are the following:
    a.  How you feel about yourself
    b.  Your mental state of being
    c.  Your physical state of being
2.  How important are the following aspects of your life?
    a.  I need to be mentally healthy
    b.  Having a good house to stay in

Note: We included other deprivation questions related to physical/monetary deprivation. However, those questions did not yield sufficient variance.

## Results

The dataset from our experiment comprised multiple choice variables (Important, Hard, and Urgent tasks) and participant demographic information (STAI score, income level, and platform). We used this dataset to conduct a regression analysis to examine how participants' choice behavior influenced their total points accumulated in the task.

### Task Performance

We compiled data on each participant's selection and non-selection of each type of task (Important, Hard, and Urgent), then computed the frequency with which each participant picked a particular task type when given an option. @tbl-totalpoints indicates that the decision to complete Important tasks significantly affected the total points a participant amassed (Estimate = 16.098, p \< .001). Specifically, a ten percentage point rise in the ratio of selected Important tasks (two points, as opposed to one point) resulted in an increase of 1.6 points in the overall score. However, the percentage of times a participant chose Hard or Urgent tasks did not significantly explain the total points accumulated (Estimate = -7.563, p = .371 for Hard tasks; Estimate = 6.539, p = .142 for Urgent tasks).

We also included demographic variables and participant characteristics (STAI score, income level, and platform) as control variables in the regression model, but none showed a significant relationship with total points.

The model accounted for approximately 20.24% of the variance in total points (Adjusted R-squared = 0.132), with an overall significant model fit (F(6,68) = 2.877, p \< .05).

```{r data for totalpoints}
write_csv(joint_pilot, file = "data/Pilot/joint_pilot.csv")
```

```{r, results='asis'}
#| label: tbl-totalpoints
#| tbl-cap: "Regression analysis of total points on participants' choice behavior and demographic variables. The predictors include the percentage of choices where Important, Hard, and Urgent tasks were chosen, participants' STAI score, income level (High vs. Low), and the platform on which the experiment was conducted (Prolific vs. Mturk)."

joint_pilot <- joint_pilot %>%
  mutate(chosen_i = ifelse(choice == "L", i1, i2) - 1,
         chosen_e = ifelse(choice == "L", e1, e2) - 1,
         chosen_u = ifelse(choice == "L", u1, u2) - 1,
         not_chosen_i = ifelse(choice == "L", i2, i1) - 1,
         not_chosen_e = ifelse(choice == "L", e2, e1) - 1,
         not_chosen_u = ifelse(choice == "L", u2, u1) - 1)

# Calculate total points per participant
points_per_participant <- joint_pilot %>%
  group_by(participant) %>%
  summarise(total_points = max(points),
            stai = first(stai),
            high_income = first(high_income),
            platform = first(platform))

# Calculate the percentage of times when the urgent, important and effortful options were chosen
choice_percentages <- joint_pilot %>%
  mutate(
    urgent_chosen = ifelse(chosen_u > not_chosen_u, 1, 0),
    important_chosen = ifelse(chosen_i > not_chosen_i, 1, 0),
    effort_chosen = ifelse(chosen_e > not_chosen_e, 1, 0)
  ) %>%
  group_by(participant) %>%
  summarise(perc_urgent_chosen = mean(urgent_chosen, na.rm = TRUE),
            perc_important_chosen = mean(important_chosen, na.rm = TRUE),
            perc_effort_chosen = mean(effort_chosen, na.rm = TRUE))

performance <- inner_join(points_per_participant, choice_percentages, by = "participant")

# Run regression
regression_model <- lm(total_points ~ perc_important_chosen + 
                         perc_effort_chosen + perc_urgent_chosen +
                         stai + high_income + platform, data = performance)

# summary_stats <- summary(regression_model)

reduced_model <- lm(total_points ~ perc_important_chosen +
                      perc_effort_chosen + perc_urgent_chosen,
                    data = performance)

stargazer(regression_model, reduced_model, 
          type = "latex", 
          header = FALSE, 
          align = TRUE,
          covariate.labels = c("Percentage of Important task chosen",
                               "Percentage of Hard task chosen",
                               "Percentage of Urgent task chosen",
                               "STAI Score",
                               "Low Income",
                               "Platform: Prolific (vs. Mturk)"),
          dep.var.labels = c("Total Points"),
          star.cutoffs = c(.05, .01, .001), 
          star.char = c("*", "**", "***"),
          column.sep.width = "10pt")


```

### Trade-off Decisions

When we compare an individual's choice of "challenging" tasks: decisions between high urgency - low importance or low importance - high urgency tasks, we observe that high anxiety and low income individuals more often choose high urgency tasks over high value tasks, which corroborates the current non-quantitative literature as can be observed in the plots below.

```{r}
#| label: fig-tradeoff-results
#| fig-cap: "Choice proportions by income and anxiety"
#| fig-subcap:
#|   - "Income"
#|   - "Anxiety"
#| layout-ncol: 2

joint_pilot %>%
  group_by(platform, high_income) %>%
  filter(!is.na(high_income)) %>%
  summarise(choose_urg = sum(huli, na.rm = TRUE),
            total = sum(!is.na(huli)),
            mean_huli  = mean(huli, na.rm = TRUE)) %>%
  mutate(se = sqrt((mean_huli * (1-mean_huli)) / total)) %>%
  
  ggplot(aes(platform, mean_huli, fill = high_income),
         alpha=0.7) + 
  geom_col(position = "dodge") +
  labs(title="Choice Frequency of Urgent vs Non-urgent Tasks",
       x ="Platform",
       y = "Frequency of urgent/not important choices",
       fill = "") +
  scale_fill_brewer() +
  theme_minimal() +
  geom_errorbar(aes(ymin = mean_huli - se, ymax = mean_huli + se),
                width=0.4,
                alpha=0.9,
                position = position_dodge(0.9)) + 
  geom_hline(yintercept=0.5, linetype=2)


joint_pilot %>%
  group_by(platform, high_anxiety) %>%
  filter(!is.na(high_anxiety)) %>%
  summarise(choose_urg = sum(huli, na.rm = TRUE),
            total = sum(!is.na(huli)),
            mean_huli  = mean(huli, na.rm = TRUE)) %>%
  mutate(se = sqrt((mean_huli * (1-mean_huli)) / total)) %>%
  
  ggplot(aes(platform, mean_huli, fill = high_anxiety),
         alpha=0.7) + 
  geom_col(position = "dodge") +
  labs(title="Choice Frequency of Urgent vs Non-urgent Tasks",
       x ="Platform",
       y = "Frequency of urgent/not important choices",
       fill = "") +
  scale_fill_brewer() +
  theme_minimal() +
  geom_errorbar(aes(ymin = mean_huli - se, ymax = mean_huli + se),
                width=0.4,
                alpha=0.9,
                position = position_dodge(0.9)) + 
  geom_hline(yintercept=0.5, linetype=2)

```

Accuracy in trade-off decisions as a function of income and anxiety

Multiple regression models to test the same hypotheses with different measures of income.

```{r}
#| label: proportion-tests

joint_pilot %>%
  mutate(huli = factor(huli,
                       ordered = FALSE,
                       levels = c(1,0),
                       labels = c("High Urgency, Low Importance",
                                  "Low Urgency, High Importance"))) %>%
  prop_test(formula = huli ~ high_income,
            alternative = "greater",
            order = c("Low Income", "High Income")) -> pooled_income_test

joint_pilot %>% 
  mutate(huli = factor(huli,
                       ordered = FALSE,
                       levels = c(1,0),
                       labels = c("High Urgency, Low Importance",
                                  "Low Urgency, High Importance"))) %>%
  prop_test(formula = huli ~ high_anxiety,
            alternative = "less",
            order = c("Low Anxiety", "High Anxiety")) -> pooled_anxiety_test

joint_pilot %>%
  filter(high_income == "Low Income") %>%
  mutate(huli = factor(huli,
                       ordered = FALSE,
                       levels = c(1,0),
                       labels = c("High Urgency, Low Importance",
                                  "Low Urgency, High Importance"))) %>%
  prop_test(formula = huli ~ NULL,
            success = "High Urgency, Low Importance",
            p = 0.5,
            alternative = "greater") -> low_income_test

joint_pilot %>%
  filter(high_anxiety == "High Anxiety") %>%
  mutate(huli = factor(huli,
                       ordered = FALSE,
                       levels = c(1,0),
                       labels = c("High Urgency, Low Importance",
                                  "Low Urgency, High Importance"))) %>%
  prop_test(formula = huli ~ NULL,
            success = "High Urgency, Low Importance",
            p = 0.5,
            alternative = "greater") -> high_anxiety_test

```

Percent of urgent choices (vs. important) as a function of income and anxiety.

### General Urgency Bias

Individuals in the low income groups and in the high anxiety groups chose urgent tasks more often than important tasks. This result is not consistent for high income or low anxiety groups. Future graphs in this document will show that the difference-in-difference is not as clear.

1.  

2.  Multiple regression models to test the same hypotheses with different measures of income.

```{r data for urgencypoverty}
two_options <- joint_pilot %>%
  filter(!is.na(participant), !is.na(round)) %>%
  filter(!is.na(chosen_i), !is.na(chosen_e),
         !is.na(not_chosen_i), !is.na(not_chosen_e), !is.na(not_chosen_u)) %>%
  mutate(income = as.numeric(income),
         logRT = log(as.numeric(RT))) %>%
  filter(logRT != Inf & logRT != -Inf)

write_csv(two_options, file = "data/Pilot/two_options.csv")
```

```{r}
#| label: tbl-urgencypoverty

pglm(formula = chosen_u ~ Dim.1*Dim.2 +
                          age + education + points +
                          chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u,
     data = two_options,
     effect = "twoways",
     index = c("participant", "round"),
     model = "random",
     family = binomial('logit')) -> urg_bias_pca

pglm(formula = chosen_u ~ income*stai +
                          age + education + points +
                          chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u,
     data = two_options,
     effect = "twoways",
     index = c("participant", "round"),
     model = "random",
     family = binomial('logit')) -> urg_bias_income

pglm(formula = chosen_u ~ poverty_zip*stai +
                          age + education + points +
                          chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u,
     data = two_options,
     effect = "twoways",
     index = c("participant", "round"),
     model = "random",
     family = binomial('logit')) -> urg_bias_zipdeprivation

pglm(formula = chosen_u ~ median_income_zip*stai +
                          age + education + points +
                          chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u,
     data = two_options,
     effect = "twoways",
     index = c("participant", "round"),
     model = "random",
     family = binomial('logit')) -> urg_bias_zipincome

```

It seems that when controlling for Dim 1 and 2, some effects become significant. Multicollinearity might be a problem, although correlations between STAI and PCA components are not higher than 0.6 (see correlation plots above). These results might be a result of a separation between State and Trait Anxiety. Although we only included the State questions of STAI, state and trait scores are likely correlated. PCA dimensions 1 and 2 may control for this confounding effect.

We review the Key Results from the first pages: urgent choices do seem to be above 50% for key groups, but the differences-in-differences across income and anxiety levels are not significant.

Again, people might not mind leaving the High Importance task undone. This is what some friends have called the "insurance ice cream." That is, if I leave this High Importance task in my queue, I can use it when I get a task that is High Effort but Low Urgency.

### Reaction Time

```{r}
#| label: tbl-reactiontime
#| tbl-cap: "Regression analysis of reaction time (RT) on participants' PCs and anxiety measures."

plm(formula = logRT ~ Dim.1*Dim.2 +
                      age + education + points +
                      chosen_i + chosen_e + chosen_u +
                      not_chosen_i + not_chosen_e + not_chosen_u,
     data = two_options,
     effect = "twoways",
     index = c("participant", "round"),
     model = "random") -> rt_bias_pca

plm(formula = logRT ~ income*stai +
                      age + education + points +
                      chosen_i + chosen_e + chosen_u +
                      not_chosen_i + not_chosen_e + not_chosen_u,
     data = two_options,
     effect = "twoways",
     index = c("participant", "round"),
     model = "random") -> rt_bias_income

plm(formula = logRT ~ poverty_zip*stai +
                      age + education + points +
                      chosen_i + chosen_e + chosen_u +
                      not_chosen_i + not_chosen_e + not_chosen_u,
     data = two_options,
     effect = "twoways",
     index = c("participant", "round"),
     model = "random") -> rt_bias_zipdeprivation

plm(formula = logRT ~ median_income_zip*stai +
                      age + education + points +
                      chosen_i + chosen_e + chosen_u +
                      not_chosen_i + not_chosen_e + not_chosen_u,
     data = two_options,
     effect = "twoways",
     index = c("participant", "round"),
     model = "random") -> rt_bias_zipincome
```

### Accuracy

We also obtain a comparison of the choices participants make and the optimal, or rational, protocol we generated. This is done by estimating a hierarchical Bayesian model...

```{r}
#| label: fig-costs
#| fig-cap: "Histogram of Estimated Costs per Participant"
dat <- data.frame(dens = c(costs$cH, costs$cL), 
                  lines = rep(c("cH", "cL"), each = nrow(costs)))
ggplot(dat, aes(x = dens, fill = lines)) + 
  #geom_histogram() +
  geom_density(alpha = 0.5)
```

This score is calculated by first estimating the cost parameters for each participant and then using them with backwards induction to discover the optimal choice at each presented state.

```{r data for accuracy}
write_csv(Accuracy, file = "data/Pilot/Accuracy.csv")
```

```{r}
#| label: fig-accuracy
#| fig-cap: "Histogram of Accuracy Proportions"

hist(Accuracy$Accuracy, breaks=10)

```

@fig-accuracy highlights how participants typically make optimal decisions (when given 'challenging' tasks) with a probability in between 0.5 and 0.6. This is generally what we expect to observe.

#### Accuracy, Anxiety, and Income

1.  Accuracy in trade-off decisions as a function of income and anxiety

Finally, we compare for each participant, how many of their choices are identical to a model that observed the full horizon for the Markov decision process. Each participant is a dot, y axis is the percentage of correct choices in the experiment while x axis is the STAI (anxiety measure). Generally the results are very similar to figure 1.5.

```{r}
#| label: fig-accuracy-results
#| fig-cap: "Participant Accuracy by Income and Anxiety"
#| fig-subcap:
#|   - "Prolific, Income"
#|   - "Prolific, Anxiety"
#| layout-ncol: 2
#| column: page-right
ggplot(Accuracy, aes(x=income, y=Accuracy)) +
  geom_point() +
  stat_smooth(method=loess) +
  geom_label(x=6, y=.8,
             label=paste("Correlation:",
                         round(cor(Accuracy$Accuracy, Accuracy$income), 2)))

ggplot(Accuracy, aes(x=stai, y=Accuracy)) +
  geom_point() +
  stat_smooth(method=loess) +
  geom_label(x=30, y=.8,
             label=paste("Correlation:",
                         round(cor(Accuracy$stai, Accuracy$Accuracy), 2)))

```

It appears that Accuracy does not vary across income and anxiety levels with these measures. Some possibilities of this fact might include that, since time discounting here is virtually 0, leaving the important task behind will not affect participants as much (depending, of course, of the estimated cost parameters).

#### General Linear Models of Accuracy

```{r}
#| label: tbl-accuracy
pglm(formula = Optimal ~ income*stai +
                         age + education + points +
                         chosen_i + chosen_e + chosen_u +
                         not_chosen_i + not_chosen_e + not_chosen_u,
             data = two_options,
             effect = "twoways",
             index = c("participant", "round"),
             model = "random",
             family = binomial('logit')) -> accuracy_income

pglm(formula = Optimal ~ Dim.1*Dim.2  +
                      age + education + points +
                      chosen_i + chosen_e + chosen_u +
                      not_chosen_i + not_chosen_e + not_chosen_u,
             data = two_options,
             effect = "twoways",
             index = c("participant", "round"),
             model = "random",
             family = binomial('logit')) -> accuracy_pca

pglm(formula = Optimal ~ poverty_zip*stai +
                      age + education + points +
                      chosen_i + chosen_e + chosen_u +
                      not_chosen_i + not_chosen_e + not_chosen_u,
             data = two_options,
             effect = "twoways",
             index = c("participant", "round"),
             model = "random",
             family = binomial('logit')) -> accuracy_zipdeprivation

pglm(formula = Optimal ~ median_income_zip*stai  +
                      age + education + points +
                      chosen_i + chosen_e + chosen_u +
                      not_chosen_i + not_chosen_e + not_chosen_u,
             data = two_options,
             effect = "twoways",
             index = c("participant", "round"),
             model = "random",
             family = binomial('logit')) -> accuracy_zipincome
```

# Experiment 1

## Methodology

Experiment 1 was developed in PsychoPy version 2023.1.3 and hosted on the Pavlovia platform.

### Structure

In line with the pilot study, the game interface for Experiment 1 presented participants with a queue of tasks, each varying in effort, importance, and urgency. As previously depicted in @img-choice, we visually represented these characteristics with corresponding icons on each task image.

1.  Effort: As in the pilot study, we operationalized effort through the number of clicks required to complete an order, with more complex orders demanding more effort.

2.  Importance (value): The representation of importance remained consistent with the pilot study, with dollar signs indicating the subjective value of a task. However, with each point now worth \$0.05, participants now earn up to \$4.00 based on their total points.

3.  Urgency: The urgency of tasks was conveyed similarly to the pilot study, with clock icons indicating the degree of urgency. However, low-urgency tasks now remained in the queue for four rounds before being replaced, and, unlike high-urgency tasks, there was no penalty if low-urgency tasks disappeared after four rounds.

In each round, participants saw the screen shown in @img-exp. They were instructed to select a task from the queue (left or right) and click on the matching ice cream icons in the center of the screen to complete it. The game continued for 40 orders, doubling the length of the pilot study to provide a more robust measure of participant behavior. As in the pilot study, participants were not restricted to a specific order of task completion, allowing for an open-choice design that facilitated the observation and analysis of decision-making and prioritization strategies. The potential earnings increased to a maximum of $\$4.00$, contingent on the total number of points accumulated throughout the game, to further incentivize participation.

Experiment 1 introduced a critical modification to the task queue logic, distinguishing it from the pilot study. As previously noted, specific task scenarios in the game posed more complex decision-making challenges, where the optimal course of action was not immediately apparent (e.g., choosing between a high-importance, low-urgency task, and a high-urgency, low-importance task). Due to the uniform task sampling employed in our pilot study, these "hard choices" were infrequently encountered.

Experiment 1 addressed this limitation by adjusting the task queue logic. Specifically, if the remaining task in the queue was of high importance and low urgency, there was a 50% chance that the subsequent task would be of high urgency and low importance, and vice versa. This element of randomness introduced an additional layer of unpredictability into the task queue, thereby enhancing the realism and complexity of the decision-making process for participants. This significant redesign from the pilot study increased the frequency of "hard choices," enabling us to delve deeper into analyzing participants' decision-making and prioritization strategies under these more challenging circumstances.

![Game interface for Experiment 1. Participants have a queue, with a task on each side, and a series of icons they must press in order to complete a task. The clocks and dollar signs on a task represent the urgency and importance of the task, respectively. The top of the screen displays a points counter and a rounds counter.](images/exp_example.png){#img-exp}

<!-- ## Power Analysis -->

<!-- ### Behavioral Measures -->

<!-- ### Perceived Effort -->

## Hypotheses

## Data

Our experiment was conducted on the Prolific platform. In total, we acquired data from N = 92 participants, each of whom completed the modified experimental paradigm and revised questionnaires designed to explore the relationships between financial status, anxiety, and decision-making under uncertainty.

```{r load-data-and-analysis, message=FALSE, warning=FALSE}
library(mice)
library(caret)

# Load the data
load(file = "data/Exp1/df.Rdata")

df$Q23 <- factor(df$Q23,
                 levels = c("Less than $10,000",
                            "$10,000 - $15,000",
                            "$15,001 - $25,000",
                            "$25,001 - $50,000",
                            "$50,001 - $75,000",
                            "$75,001 - $100,000",
                            "$100,001 - $150,000",
                            "More than $150,000"))
df$Q24 <- factor(df$Q24, ordered = FALSE)
df$Q49_1 <- factor(df$Q49_1,
                   levels = c("Never True",
                              "Sometimes",
                              "Often"))
df$Q49_2 <- factor(df$Q49_2,
                   levels = c("Never True",
                              "Sometimes",
                              "Often"))
df$Q49_3 <- factor(df$Q49_3,
                   levels = c("Never True",
                              "Sometimes",
                              "Often"))
df$Q51 <- factor(df$Q51,
                 levels = c("Never",
                            "Some months, but not every month",
                            "Only 1 or 2 months",
                            "Almost every month"))
df$Q54 <- factor(df$Q54,
                 levels = c("Never",
                            "Some months, but not every month",
                            "Only 1 or 2 months",
                            "Almost every month"))
df$Q56_1 <- factor(df$Q56_1,
                   levels = c("Never true",
                              "Sometimes true",
                              "Often true"))
df$Q56_2 <- factor(df$Q56_2,
                   levels = c("Never true",
                              "Sometimes true",
                              "Often true"))
df$Q56_3 <- factor(df$Q56_3,
                   levels = c("Never true",
                              "Sometimes true",
                              "Often true"))


# Clean column names
names(df) <- gsub("\\s", "_", names(df))  # Replace spaces with underscores
names(df) <- gsub("\\(|\\)", "", names(df))  # Remove parentheses

# Define the mapping from ordinal to numeric values
binary_vars <- c("Q33_1", "Q33_2", "Q33_3", "Q33_4", "Q33_5", "Q33_6", "Q36",
                 "Q46_1", "Q46_2", "Q46_3", "Q46_4", "Q46_5", "Q46_6", "Q46_7", 
                 "Q47_1", "Q47_2", "Q47_3", "Q47_4", "Q47_5", "Q47_6", "Q47_7", "Q47_8", "Q47_9",
                 "Q48_1", "Q48_2", "Q48_3", "Q48_4", "Q48_5", "Q48_6", "Q48_7",
                 "Q50", "Q52", "Q53", "Q55", "Q57", "Q58", "Q59", "Student_status")
df[binary_vars] <- lapply(df[binary_vars],
                          function(x) as.numeric(as.character(x) == "Yes"))

# Infer Variables from Survey logic
df$Q51[df$Q50 == 0] <- "Never"
df$Q54[df$Q53 == 0] <- "Never"
df$Q56_1[df$Q55 == 0] <- "Never true"
df$Q56_2[df$Q55 == 0] <- "Never true"
df$Q56_3[df$Q55 == 0] <- "Never true"
df$Q57[df$Q55 == 0] <- 0
df$Q36[df$Q33_1 == 0] <- 0

# Remove columns that are all NA
df <- df[, colSums(is.na(df)) != nrow(df)]
# Detect and remove zero-variance predictors
nzv <- nearZeroVar(df[,-129], saveMetrics = TRUE)
# Remove the variables with zero variance from the data
df <- df[, c(!nzv$zeroVar, TRUE)]

# Perform multiple imputation
# ## Create df without the trial info:
# df_mice <- df %>% select(!CSV_Data)
# ## Set up the predictorMatrix
# df_mice <- df_mice[,-c(1:5,73:113,114)]
# predictorMatrix <- make.predictorMatrix(df_mice)
# 
# ## Compute the maximum percentage of missing values
# max_missing_percentage <- round(max(colMeans(is.na(df_mice))) * 100)
# imputed_data <- mice(df_mice, m = max_missing_percentage,
#                      method = 'rf', maxit = 5,
#                      predictorMatrix = predictorMatrix)
# 
# save(imputed_data, file = "data/Exp1/imputed_data.Rdata")
load(file = "data/Exp1/imputed_data.Rdata")

# Calculate STAI
df <- df %>%
  mutate(across(c(paste0("Q", 3:22),
                  paste0("Q", 77:96),
                  paste0("Q", 99:118)), as.numeric))
df <- df %>%
  mutate(across(c("Q3", "Q4", "Q7", "Q10", "Q12", "Q13", "Q17", "Q18", "Q21",
                  "Q22", "Q77", "Q78", "Q81", "Q84", "Q86", "Q87", "Q91", "Q92",
                  "Q95", "Q96"), function(x) 5 - x),
         across(c("Q99", "Q101", "Q104", "Q105", "Q108",
                  "Q111", "Q112", "Q114", "Q117"), function(x) 5 - x),
         SAI_pre = rowSums(select(df, Q3:Q22), na.rm = TRUE),
         SAI_post = rowSums(select(df, Q77:Q96), na.rm = TRUE),
         TAI_post = rowSums(select(df, Q99:Q118), na.rm = TRUE))

# Transform all to numeric
completed_data <- complete(imputed_data, 1) %>%
  mutate(Q23 = as.numeric(Q23),
         ResidenceValue = as.numeric(ResidenceValue),
         Q49_1 = as.numeric(Q49_1),
         Q49_2 = as.numeric(Q49_2),
         Q49_3 = as.numeric(Q49_3),
         Q51 = as.numeric(Q51),
         Q53 = as.numeric(Q53),
         Q54 = as.numeric(Q54),
         Q56_1 = as.numeric(Q56_1),
         Q56_2 = as.numeric(Q56_2),
         Female = ifelse(Sex == "Female", 1, 0)) %>%
  select(!Sex)
# For 'work_type'
work_type <- model.matrix(~Q24-1, data = completed_data)
# For 'Ethnicity_simplified'
ethnicity_dummies <- model.matrix(~Ethnicity_simplified-1, data = completed_data)
# For 'Country_of_birth'
country_dummies <- model.matrix(~Country_of_birth-1, data = completed_data)
completed_data <- completed_data %>%
  bind_cols(ethnicity_dummies[,-c(ncol(ethnicity_dummies))], # Baseline: White
            country_dummies[,-c(ncol(country_dummies))], # Baseline: US
            work_type[,-c(ncol(work_type))]) %>% # Baseline: Salaried
  mutate(AnnualSalary = log1p(AnnualSalary)) %>%
  select(!c(Q24, Ethnicity_simplified, Country_of_birth))

# Factor Analysis
poverty1 <- fa(completed_data[,c(21:78)], nfactors = 1, n.rotations = 50,
              rotate = "oblimin", fm = "pa", scores = "tenBerge")
poverty2 <- fa(completed_data[,c(21:78)], nfactors = 2, n.rotations = 50,
              rotate = "oblimin", fm = "pa", scores = "tenBerge")
poverty3 <- fa(completed_data[,c(21:78)], nfactors = 3, n.rotations = 50,
              rotate = "oblimin", fm = "pa", scores = "tenBerge")
poverty4 <- fa(completed_data[,c(21:78)], nfactors = 4, n.rotations = 50,
              rotate = "oblimin", fm = "pa", scores = "tenBerge")
poverty5 <- fa(completed_data[,c(21:78)], nfactors = 5, n.rotations = 50,
              rotate = "oblimin", fm = "pa", scores = "tenBerge")

factor_scores <- factor.scores(completed_data[,c(21:78)], poverty3)

# Data for Analysis
variables <- names(df[,c(1:5,28,114:118,121:124)])
df <- df %>%
  select(variables) %>%
  bind_cols(factor_scores$scores)

```

### Demographics

Our experiment involved participants with various income levels and anxiety scores. @tbl-exp1-demo summarizes the demographics of the participants. Regarding income, we observed a significant difference between high-income and low-income participants (p = 0.05). The mean income for the high-income group was approximately \$146,012.57, while for the low-income group, it was around \$17,571.42. This substantial income disparity within our sample reflects the economic diversity of the participants, ranging from those experiencing financial hardship to those with more substantial financial resources.
For anxiety scores, as measured by the State-Trait Anxiety Inventory (STAI), we observed stark differences between the high- and low-anxiety groups, both pre- and post-experiment. Before the experiment, the mean State Anxiety score for the high-anxiety group was 48.38, compared to 39.97 for the low-anxiety group (p < 0.001). Similar patterns were observed post-experiment, with a mean State Anxiety score of 48.81 for the high anxiety group and 38.23 for the low anxiety group (p < 0.001). The Trait Anxiety scores followed a similar pattern, with a mean of 48.65 for the high-anxiety group and 39.43 for the low-anxiety group (p < 0.001).

``` {r}
#| label: tbl-exp1-demo
#| tbl-cap: "Descriptive statistics for income and anxiety scores. Mean values are provided for high- and low-income groups and high- and low-anxiety groups. The p-values from t-tests comparing high and low groups are also included."

df <- df %>%
  mutate(SAI_post = case_when(SAI_post == 0 ~ NA,
                              .default = SAI_post),
         TAI_post = case_when(TAI_post == 0 ~ NA,
                              .default = TAI_post))

# Calculate the median of AnnualSalary and Anxiety scores
median_salary <- median(df$AnnualSalary, na.rm = TRUE)
median_SAI_pre <- median(df$SAI_pre, na.rm = TRUE)
median_SAI_post <- median(df$SAI_post, na.rm = TRUE)
median_TAI_post <- median(df$TAI_post, na.rm = TRUE)

# Create two new columns to distinguish high-low income and high-low anxiety
df$IncomeGroup <- ifelse(df$AnnualSalary > median_salary, 'High', 'Low')
df$AnxietyGroup_SAI_pre <- ifelse(df$SAI_pre > median_SAI_pre, 'High', 'Low')
df$AnxietyGroup_SAI_post <- ifelse(df$SAI_post > median_SAI_post, 'High',
                                   ifelse(!is.na(df$SAI_post),'Low',NA))
df$AnxietyGroup_TAI_post <- ifelse(df$TAI_post > median_TAI_post, 'High',
                                   ifelse(!is.na(df$TAI_post),'Low',NA))

# Perform t-tests to compare means of high and low income groups and high and low anxiety groups
t_test_income <- t.test(df$AnnualSalary[df$IncomeGroup == 'High'], df$AnnualSalary[df$IncomeGroup == 'Low'])
t_test_anxiety_SAI_pre <- t.test(df$SAI_pre[df$AnxietyGroup_SAI_pre == 'High'], df$SAI_pre[df$AnxietyGroup_SAI_pre == 'Low'])
t_test_anxiety_SAI_post <- t.test(df$SAI_post[df$AnxietyGroup_SAI_post == 'High'], df$SAI_post[df$AnxietyGroup_SAI_post == 'Low'])
t_test_anxiety_TAI_post <- t.test(df$TAI_post[df$AnxietyGroup_TAI_post == 'High'], df$TAI_post[df$AnxietyGroup_TAI_post == 'Low'])

# Calculate mean of each group
mean_high_income <- mean(df$AnnualSalary[df$IncomeGroup == 'High'], na.rm = TRUE)
mean_low_income <- mean(df$AnnualSalary[df$IncomeGroup == 'Low'], na.rm = TRUE)
mean_high_anxiety_SAI_pre <- mean(df$SAI_pre[df$AnxietyGroup_SAI_pre == 'High'], na.rm = TRUE)
mean_low_anxiety_SAI_pre <- mean(df$SAI_pre[df$AnxietyGroup_SAI_pre == 'Low'], na.rm = TRUE)
mean_high_anxiety_SAI_post <- mean(df$SAI_post[df$AnxietyGroup_SAI_post == 'High'], na.rm = TRUE)
mean_low_anxiety_SAI_post <- mean(df$SAI_post[df$AnxietyGroup_SAI_post == 'Low'], na.rm = TRUE)
mean_high_anxiety_TAI_post <- mean(df$TAI_post[df$AnxietyGroup_TAI_post == 'High'], na.rm = TRUE)
mean_low_anxiety_TAI_post <- mean(df$TAI_post[df$AnxietyGroup_TAI_post == 'Low'], na.rm = TRUE)

# Reshape the results data frame
results_reshaped <- data.frame(
  Group = c("Income", "State Anxiety (pre-experiment)", "State Anxiety (post-experiment)", "Trait Anxiety"),
  Mean_High = c(mean_high_income, mean_high_anxiety_SAI_pre, mean_high_anxiety_SAI_post, mean_high_anxiety_TAI_post),
  Mean_Low = c(mean_low_income, mean_low_anxiety_SAI_pre, mean_low_anxiety_SAI_post, mean_low_anxiety_TAI_post),
  p_value = c(t_test_income$p.value, t_test_anxiety_SAI_pre$p.value, t_test_anxiety_SAI_post$p.value, t_test_anxiety_TAI_post$p.value)
)

# Format the table
gt(results_reshaped) %>%
  fmt_number(columns = c(Mean_High, Mean_Low), decimals = 2) %>%
  fmt_scientific(columns = c(p_value), decimals = 3, drop_trailing_zeros = FALSE) %>%
  tab_style(style = cell_borders(sides = "bottom"), locations = cells_body(rows = 4)) %>%
  cols_label(
    Group = "Group",
    Mean_High = "Mean High",
    Mean_Low = "Mean Low",
    p_value = "p-value"
  )

```

### Comprehensive Poverty Measures

To develop a more nuanced measure of poverty, we revisited our questionnaire to address variance issues (@pca-measure). We contemplated expanding our sample to include more lower-income individuals or introducing new questions to elicit more variance. Our current iteration of comprehensive measurements is available in @questionnaires.

We employed Factor Analysis, a statistical technique widely used to identify underlying relationships between measured variables. This method is particularly advantageous when dealing with scale compatibility issues, reducing many variables into fewer factors, and assisting in data interpretation, especially in large datasets.

Before proceeding with the Factor Analysis, we addressed the issue of missing data in our dataset, as it can significantly skew the results. We opted to use Multiple Imputation by Chained Equations (MICE), an approach that fills in missing values multiple times to create several complete datasets. The number of imputations was set to the overall percentage of missing cases in the dataset, ensuring a robust and comprehensive imputation strategy. We chose the Random Forest (rf) method for our imputations. Random Forest is a flexible, non-parametric method that can handle complex interactions and non-linear relationships between variables, making it suitable for datasets with complex structures and patterns, like ours.

Following this, we conducted a Factor Analysis on the complete datasets generated by the MICE procedure. This analysis aimed to uncover latent variables, or factors, that explain the variability among observed, correlated variables. This method is particularly useful in understanding the structure of correlations among the variables. For this specific analysis, we selected a subset of the survey data, including responses to questions regarding household conditions, work conditions, and food deprivation. We performed the factor analysis using principal axis factoring, a method of extraction primarily used when the analysis aims to identify latent constructs underlying the variables. It is a commonly used extraction method for psychological and social data. We also employed an oblique rotation method to facilitate the interpretation of the factors. Such a method simplifies and clarifies the data structure and allows for the factors to be correlated, which is a more relaxed and often more realistic assumption. Lastly, we used a correlation-preserving scoring method (TenBerge), which provides unbiased estimates of the factor scores.

@fig-new-pov-scree displays the scree plot, a graphical representation of the proportion explained variance for each factor in an exploratory factor analysis. It helps in determining the number of factors to retain in the analysis. The x-axis represents the number of factors, and the y-axis represents the proportion explained variance. The point at which the slope of the curve is leveling off (the "elbow") indicates the number of factors to retain. Although the elbow is a standard guideline, the decision to choose the number of factors should also consider the interpretability of the factors and the theoretical understanding of the measured constructs. In our case, the elbow in the scree plot suggested that two factors might be sufficient. However, upon further analysis, we found that a three-factor model provided a more meaningful and comprehensive understanding of poverty.

``` {r}
#| label: fig-new-pov-scree
#| fig-cap: ""

# Create a data frame with the proportion explained variance for each model
explained_variance <- data.frame(
  Factor = c(1, 2, 3, 4, 5),
  Model1 = c(poverty1$Vaccounted["Proportion Var",], NA, NA, NA, NA),
  Model2 = c(poverty2$Vaccounted["Proportion Var",], NA, NA, NA),
  Model3 = c(poverty3$Vaccounted["Proportion Var",], NA, NA),
  Model4 = c(poverty4$Vaccounted["Proportion Var",], NA),
  Model5 = c(poverty5$Vaccounted["Proportion Var",])
)

# Reshape the data frame to a long format
explained_variance_long <- gather(explained_variance, Model, Variance, -Factor)

# Plot the data
ggplot(explained_variance_long, aes(x = Factor, y = Variance, color = Model)) +
  geom_line() +
  geom_point() +
  labs(x = "Factor", y = "Proportion Explained Variance") +
  theme_minimal()


```

More specifically, the two-factor model included "Financial Hardship" and "Employment and Economic Status" factors, which, while simpler, did not capture the full complexity of our data. The four-factor model added two additional factors. The third factor was a "Housing Status" factor, and the fourth was the "physical condition of the home ."It included variables related to a leaking roof, broken windows, exposed electrical wires, and a malfunctioning stove or refrigerator. However, the four-factor model did not significantly improve model fit. After careful consideration and analysis, we have opted for the three-factor model as the most appropriate means of capturing the complexity of poverty in our data. This model balances complexity and interpretability, allowing for a comprehensive understanding of poverty's main dimensions while remaining concise and comprehensible. The three distinct factors that comprise this model---financial hardship, employment and economic status, and housing status---align with the multidimensional nature of poverty, which extends beyond mere income deprivation to encompass various other aspects of life.

Our three-factor model fits our data moderately well. The root mean square of residuals (RMSR), which measures the average residual correlation among variables, was 0.08, indicating a moderate fit. However, the Tucker-Lewis Index (TLI) was 0.475, below the desired threshold of 0.90, also suggesting only a moderate model fit. The root mean square error of approximation (RMSEA), which measures the discrepancy between the observed covariance matrix and the model covariance matrix per degree of freedom, was 0.073, with 90% confidence intervals between 0.069 and 0.08. This value suggests a reasonable error of approximation.

The derived factors, based on their highest loadings, represent the following constructs:

1. **Factor 1 (PA1)**: This factor had high loadings primarily on the 'Q48' series and 'Q50' questions, which indicate experiences of financial hardship and food insecurity within the past 12 months. We labeled Factor 1 as a "Financial Hardship" factor. This factor is moderately negatively correlated with Factor 3 (PA3).

2. **Factor 2 (PA2)**: The highest loadings on this factor were hours worked weekly and the participant's annual salary, suggesting that this factor might be related to the work and economic conditions of the respondents. There was a slight positive correlation between this factor and Factor 3 (PA3). Given the nature of the variables that load heavily on this factor, we interpreted it as an "Employment and Economic Status" factor.

3. **Factor 3 (PA3)**: This factor had the highest loadings on questions related to home ownership. Thus, we interpret Factor 3 as a "Housing Status" factor. This factor had a negative correlation with Factor 1 (PA1) and a slight positive correlation with Factor 2 (PA2).

The correlation of the factor scores with the factors for PA1, PA2, and PA3 were 0.99, 0.94, and 0.91, respectively, indicating high accuracy of the factor scores. Similarly, the multiple R square of scores with factors for PA1, PA2, and PA3 were 0.98, 0.88, and 0.83, respectively, suggesting a strong relationship between the observed variables and the extracted factors. The minimum correlation of possible factor scores were 0.97, 0.77, and 0.67 for PA1, PA2, and PA3, respectively, further supporting the adequacy of the factor scores.

### Zip Code Poverty Measures

Similar to our pilot study, we validated participants' income reports by analyzing economic data from their ZIP codes. We used the American Community Survey to obtain poverty and median income measures, allowing us to analyze the impact of geographic and community-level factors on individual experiences of poverty.

``` {r}
#| label: fig-exp1-zip-poverty
#| fig-cap: "Income and Poverty Levels by ZIP Code"

# Load the ip to zip code data
ip2zip <- read_csv("data/ZIPcode/ip2zip_exp1.csv")

# Merge the demographics data with the ip to zip code data
df <- merge(y = df,
           x = ip2zip,
           by.y = "IPAddress",
           by.x = "IP")

# Load the poverty data
poverty <- read_csv("data/ZIPcode/ACSST5Y2019.S1701_data_with_overlays_2021-12-21T174024.csv")

# Process the poverty data
poverty <- poverty %>%
  dplyr::select(NAME, S1701_C03_001E) %>%
  mutate(ZIP = as.numeric(str_sub(NAME, start= -5))) %>%
  dplyr::select(-NAME)

# Merge the demographics data with the poverty data
df <- df %>%
  left_join(poverty, by = "ZIP")

# Load the income data
income <- read_csv("data/ZIPcode/ACSST5Y2019.S1903_data_with_overlays_2021-11-16T180635.csv")

# Process the income data
income <- income %>%
  dplyr::select(NAME, S1903_C03_001E) %>%
  mutate(ZIP = as.numeric(str_sub(NAME, start= -5))) %>%
  dplyr::select(-NAME)

# Merge the demographics data with the income data and remove the IP column for privacy
df <- df %>%
  dplyr::select(-"IP") %>%
  left_join(income, by = "ZIP") %>%
  mutate(
    zip_poverty = as.numeric(S1701_C03_001E),
    zip_income = as.numeric(S1903_C03_001E)
  ) %>%
  select(!c(S1701_C03_001E, S1903_C03_001E))

# Generate summary statistics
summary_stats <- df %>%
  summarise(
    mean_income = mean(zip_income, na.rm = TRUE),
    mean_poverty_rate = mean(zip_poverty, na.rm = TRUE),
  )

library(ggmap)
library(maps)
library(maptools)

# Add a new column for the transformed poverty level
df$zip_poverty_log <- log1p(df$zip_poverty)
# Define the colors and breakpoints
colors <- c("blue","blue","white", "red","red")
breaks <- quantile(df$zip_poverty_log, probs = c(0, 0.5, 1), na.rm = TRUE)
# Create a color gradient function
color_gradient <- colorRampPalette(colors)
# Get the US map data
us_map <- map_data("state")
# Generate the plot
ggplot() +
  # Draw the map
  geom_polygon(data = us_map, aes(x = long, y = lat, group = group), fill = "white", color = "black") +
  # Add the points
  geom_point(data = df[!is.na(df$zip_poverty),],
             aes(x = Long, y = Lat, size = zip_income, color = zip_poverty_log)) +
  # Define the color scale
  scale_color_gradientn(colors = color_gradient(100), 
                        breaks = breaks, 
                        labels = round(expm1(breaks), 2),
                        guide = "colorbar") +
  # Define the size scale
  scale_size_continuous(range = c(1, 5)) +
  # Add labels for the color and size scales
  labs(color = "Poverty Level", size = "Median Income") +
  # Set the plot theme
  theme_minimal() +
  # Remove the grid lines
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.text = element_blank(), 
        axis.ticks = element_blank(),
        # Move the legends to the bottom
        legend.position = "bottom") +
  # Remove the axis labels
  labs(x = "", y = "")

detach("package:maps", unload = TRUE)
detach("package:ggmap", unload = TRUE)
detach("package:maptools", unload = TRUE)

```

## Results

### Choice


### Task Performance

We compiled data on each participant's selection and non-selection of each type of task (Important, Hard, and Urgent), then computed the frequency with which each participant picked a particular task type when given an option. @tbl-exp1-totalpoints indicates that the decision to complete Important tasks significantly affected the total points a participant amassed (Estimate = 16.098, p \< .001). Specifically, a ten percentage point rise in the ratio of selected Important tasks (two points, as opposed to one point) resulted in an increase of 1.6 points in the overall score. However, the percentage of times a participant chose Hard or Urgent tasks did not significantly explain the total points accumulated (Estimate = -7.563, p = .371 for Hard tasks; Estimate = 6.539, p = .142 for Urgent tasks).

We also included demographic variables and participant characteristics (STAI score, income level, and platform) as control variables in the regression model, but none showed a significant relationship with total points.

The model accounted for approximately 20.24% of the variance in total points (Adjusted R-squared = 0.132), with an overall significant model fit (F(6,68) = 2.877, p \< .05).

```{r, results='asis'}
#| label: tbl-exp1-totalpoints
#| tbl-cap: "Regression analysis of total points on participants' task choice behavior and personal characteristics. The predictors include the percentage of choices where Important, Hard, and Urgent tasks were chosen, participants' pre- and post-experiment STAI scores, and three poverty-related factors."

# Define a function to create the chosen and not_chosen variables
create_choice_vars <- function(game_data) {
  game_data <- game_data %>%
    mutate(chosen_i = ifelse(choice == 1, i1, i2),
           chosen_e = ifelse(choice == 1, e1, e2),
           chosen_u = ifelse(choice == 1, u1, u2),
           not_chosen_i = ifelse(choice == 1, i2, i1),
           not_chosen_e = ifelse(choice == 1, e2, e1),
           not_chosen_u = ifelse(choice == 1, u2, u1))
  
  return(game_data)
}

# Define a function to compute choice percentages
compute_choice_percentages <- function(game_data) {
  game_data %>%
    mutate(
      urgent_chosen = ifelse(chosen_u > not_chosen_u, 1, 0),
      important_chosen = ifelse(chosen_i > not_chosen_i, 1, 0),
      effort_chosen = ifelse(chosen_e > not_chosen_e, 1, 0)
    ) %>%
    group_by(participant) %>%
    summarise(perc_urgent_chosen = mean(urgent_chosen, na.rm = TRUE),
              perc_important_chosen = mean(important_chosen, na.rm = TRUE),
              perc_effort_chosen = mean(effort_chosen, na.rm = TRUE))
}

# Define a function to compute total points for a participant
compute_total_points <- function(game_data) {
  game_data %>%
    group_by(participant) %>%
    summarise(total_points = max(points))
}

# Filter out rows where CSV_Data is NULL
df <- df %>% filter(!sapply(CSV_Data, is.null))

# Apply the function to each game data nested in the CSV_Data column
df$CSV_Data <- map(df$CSV_Data, create_choice_vars)

# Apply this function to each participant's game data
choice_percentages_list <- map(df$CSV_Data, compute_choice_percentages)
# Combine all the results into a single data frame
choice_percentages_df <- bind_rows(choice_percentages_list)

# Apply this function to each participant's game data
total_points_list <- map(df$CSV_Data, compute_total_points)
# Combine all the results into a single data frame
total_points_df <- bind_rows(total_points_list)
# Join the total_points_df with choice_percentages_df
performance <- inner_join(total_points_df %>% ungroup(),
                          choice_percentages_df %>% ungroup(),
                          by = "participant") %>%
  group_by(participant) %>%
  summarize(
    total_points = mean(total_points),
    perc_urgent_chosen = mean(perc_urgent_chosen),
    perc_important_chosen = mean(perc_important_chosen),
    perc_effort_chosen = mean(perc_effort_chosen)
  )

# Join the performance data frame with the main data frame
df <- inner_join(df, performance, by = c("PROLIFIC_PID" = "participant"))

# Run regression
reg_total1 <- lm(total_points ~ perc_important_chosen + 
                         perc_effort_chosen + perc_urgent_chosen,
                       data = df)
reg_total2 <- lm(total_points ~ perc_important_chosen + 
                         perc_effort_chosen + perc_urgent_chosen +
                         SAI_pre + SAI_post + TAI_post,
                       data = df)
reg_total3 <- lm(total_points ~ perc_important_chosen + 
                         perc_effort_chosen + perc_urgent_chosen +
                         PA1 + PA2 + PA3,
                       data = df)
reg_total4 <- lm(total_points ~ perc_important_chosen + 
                         perc_effort_chosen + perc_urgent_chosen +
                         SAI_pre + SAI_post + TAI_post +
                         PA1 + PA2 + PA3,
                       data = df)

stargazer(reg_total1, reg_total2, reg_total3, reg_total4,
          type = "latex", 
          header = FALSE, 
          align = TRUE,
          covariate.labels = c("Important task chosen",
                               "Hard task chosen",
                               "Urgent task chosen",
                               "SAI (Pre)",
                               "SAI (Post)",
                               "TAI (Post)",
                               "Factor 1",
                               "Factor 2",
                               "Factor 3"),
          dep.var.labels = c("Total Points"),
          star.cutoffs = c(.05, .01, .001), 
          star.char = c("*", "**", "***"),
          column.sep.width = "10pt")

```

### Trade-off Decisions

When we compare an individual's choice of "challenging" tasks: decisions between high urgency - low importance or low importance - high urgency tasks, we observe that high anxiety and low income individuals more often choose high urgency tasks over high value tasks, which corroborates the current non-quantitative literature as can be observed in the plots below.

```{r}
#| label: fig-exp1-tradeoff
#| fig-cap: "Choice proportions by income and anxiety"
#| fig-subcap:
#|   - "Income"
#|   - "Anxiety"
#| layout-ncol: 2

# Define a function to create the huli variable
create_huli_var <- function(game_data) {
  game_data <- game_data %>%
    mutate(tradeoff = ifelse(u1 > u2
                         & i1 < i2, 1,
                         ifelse(u1 < u2
                                & i1 > i2, 1, 0)),
           urgent_choice = case_when(tradeoff == 0 ~ NA,
                                     chosen_u == 1 ~ 1,
                                     chosen_u == 0 ~ 0))
  
  return(game_data)
}

# Apply the function to each game data nested in the CSV_Data column
df$CSV_Data <- map(df$CSV_Data, create_huli_var)

# Apply this function to each participant's game data
tradeoff_list <- map(df$CSV_Data, function(x) {
  x %>%
    group_by(participant) %>%
    filter(!is.na(urgent_choice)) %>%
    summarize(urgent_choice = mean(urgent_choice))
})
# Combine all the results into a single data frame
tradeoff_df <- bind_rows(tradeoff_list) %>%
  group_by(participant) %>%
  summarize(urgent_choice = mean(urgent_choice))

# Join the tradeoff_df with the main data frame
df <- inner_join(df, tradeoff_df, by = c("PROLIFIC_PID" = "participant"))

median_PA1 <- median(df$PA1, na.rm = TRUE)
median_PA2 <- median(df$PA2, na.rm = TRUE)
median_PA3 <- median(df$PA3, na.rm = TRUE)
# Create two new columns to distinguish high-low income and high-low anxiety
df$PAGroup1 <- ifelse(df$PA1 > median_PA1, 'High', 'Low')
df$PAGroup2 <- ifelse(df$PA2 > median_PA2, 'High', 'Low')
df$PAGroup3 <- ifelse(df$PA3 > median_PA3, 'High', 'Low')

# Pivot the data to longer format
df_long <- df %>%
  pivot_longer(cols = starts_with("PAGroup"),
               names_to = "PovertyFactor",
               values_to = "PovertyGroup")

# Group by PovertyFactor and PovertyGroup, and create the plot
df_long %>%
  group_by(PovertyFactor, PovertyGroup) %>%
  filter(!is.na(PovertyGroup)) %>%
  summarise(choose_urg = sum(urgent_choice, na.rm = TRUE),
            total = sum(!is.na(urgent_choice)),
            mean_huli  = mean(urgent_choice, na.rm = TRUE)) %>%
  mutate(se = sqrt((mean_huli * (1-mean_huli)) / total)) %>%
  
  ggplot(aes(PovertyFactor, mean_huli, fill = as.factor(PovertyGroup)),
         alpha=0.7) + 
  geom_col(position = "dodge") +
  labs(title="Choice Frequency of Urgent vs Non-urgent Tasks",
       x ="",
       y = "Frequency of urgent/not important choices",
       fill = "Stability") +
  scale_x_discrete(labels = c("PAGroup1" = "Food Stability",
                              "PAGroup2" = "Employment Stability",
                              "PAGroup3" = "Housing Stability")) +
  scale_fill_brewer() +
  theme_minimal() +
  geom_errorbar(aes(ymin = mean_huli - se, ymax = mean_huli + se),
                width=0.4,
                alpha=0.9,
                position = position_dodge(0.9)) + 
  geom_hline(yintercept=0.5, linetype=2)


# Pivot the data to longer format
df_long <- df %>%
  pivot_longer(cols = starts_with("AnxietyGroup"),
               names_to = "AnxietyType",
               values_to = "AnxietyGroup")
# Group by AnxietyType and AnxietyGroup, and create the plot
df_long %>%
  group_by(AnxietyType, AnxietyGroup) %>%
  filter(!is.na(AnxietyGroup)) %>%
  summarise(choose_urg = sum(urgent_choice, na.rm = TRUE),
            total = sum(!is.na(urgent_choice)),
            mean_huli  = mean(urgent_choice, na.rm = TRUE)) %>%
  mutate(se = sqrt((mean_huli * (1-mean_huli)) / total)) %>%
  
  ggplot(aes(AnxietyType, mean_huli, fill = AnxietyGroup),
         alpha=0.7) + 
  geom_col(position = "dodge") +
  labs(x ="",
       y = "Frequency of urgent/not important choices",
       fill = "Anxiety Level") +
  scale_x_discrete(labels = c("AnxietyGroup_SAI_pre" = "State Anxiety Pre",
                              "AnxietyGroup_SAI_post" = "State Anxiety Post",
                              "AnxietyGroup_TAI_post" = "Trait Anxiety Post")) +
  scale_fill_brewer() +
  theme_minimal() +
  geom_errorbar(aes(ymin = mean_huli - se, ymax = mean_huli + se),
                width=0.4,
                alpha=0.9,
                position = position_dodge(0.9)) + 
  geom_hline(yintercept=0.5, linetype=2)

```
``` {r clean environment}
#| echo: false
rm(list = setdiff(ls(), c("df","poverty3","imputed_data")))
gc(verbose = FALSE)
```

### General Urgency Bias

``` {r merge datasets Exp1}

# Function to add participant-level data to each trial dataframe
add_participant_data <- function(trial_data) {
  trial_data %>%
    left_join(participant_data, by = c('participant' = 'PROLIFIC_PID'))
}

# Convert df (excluding column 14) to a data frame and ensure participant ID is unique
participant_data <- df[,-c(14)] %>%
  group_by(PROLIFIC_PID) %>%
  summarise(across(where(~ !is.numeric(.)), ~ first(na.omit(.))), 
            across(where(is.numeric), mean, na.rm = TRUE))

# Use lapply to add participant data to each data frame in df$CSV_Data
df_list <- lapply(df$CSV_Data, add_participant_data)

# Combine the data frames in df_list
df_combined <- bind_rows(df_list) %>%
  group_by(participant) %>%
  mutate(round = row_number())

```

In this section, we delve into the urgency bias, or the tendency for individuals to prioritize urgent tasks over others. @tbl-exp1-urgencypoverty displays our analysis of the interplay between this bias and various socio-economic parameters to elucidate their contributory roles.

Model 1 takes into account the role of stability in three fundamental life domains: food security (PA1), job security (PA2), and housing stability (PA3). Our findings reveal a marginally significant negative influence of job security on urgency bias, suggesting that a stable job situation may attenuate the propensity towards urgency bias. However, food supply and housing stability do not significantly sway urgency bias.

Models 2 and 3 explore the potential relationship between urgency bias and pre- and post-experiment anxiety levels. Our results do not yield a significant correlation, suggesting that the state of anxiety, either before or after the experiment, does not hold significant sway over urgency bias.

Model 4 probes the impact of area-level poverty (as measured by ZIP poverty level) on urgency bias. Interestingly, the results indicate a marginally significant negative relationship, hinting that individuals residing in areas with higher poverty levels may exhibit a slightly reduced tendency towards urgency bias.

In all models, we account for a variety of control variables, including the total number of Prolific approvals (as a proxy for platform experience), gender, age, the perceived importance and effort of the chosen task, and the perceived urgency, importance, and effort of the unchosen task. A consistent pattern emerges across all models, accentuating the role of task attributes in shaping urgency bias. This observation underscores the dynamic nature of urgency bias, suggesting that it can change with the inherent characteristics of tasks in the queue, such as their perceived importance and urgency.

```{r, results='asis'}
#| label: tbl-exp1-urgencypoverty
#| tbl-cap: "Controls include total approvals, sex, age, the effect of chosen and not chosen tasks, round left true, and sigma."

# Random effects logistic regression with interaction term between FA dimensions
pglm(formula = chosen_u ~ PA1 + PA2 + PA3 +
                          Total_approvals + Sex + Age +
                          chosen_i + chosen_e + RoundLeft +
                          not_chosen_i + not_chosen_e + not_chosen_u,
     data = df_combined,
     effect = "twoways",
     family = binomial('logit'),
     model = "random",
     index = c("participant", "round")) -> urg_bias_PA

pglm(formula = chosen_u ~ SAI_pre +
                          Total_approvals + Sex + Age +
                          chosen_i + chosen_e + RoundLeft +
                          not_chosen_i + not_chosen_e + not_chosen_u,
     data = df_combined,
     effect = "twoways",
     index = c("participant", "round"),
     model = "random",
     family = binomial('logit')) -> urg_bias_SAI_pre

pglm(formula = chosen_u ~ SAI_post +
                          Total_approvals + Sex + Age +
                          chosen_i + chosen_e + RoundLeft +
                          not_chosen_i + not_chosen_e + not_chosen_u,
     data = df_combined,
     effect = "twoways",
     index = c("participant", "round"),
     model = "random",
     family = binomial('logit')) -> urg_bias_SAI_post

pglm(formula = chosen_u ~ zip_poverty_log +
                          Total_approvals + Sex + Age +
                          chosen_i + chosen_e + RoundLeft +
                          not_chosen_i + not_chosen_e + not_chosen_u,
     data = df_combined,
     effect = "twoways",
     index = c("participant", "round"),
     model = "random",
     family = binomial('logit')) -> urg_bias_ZIP

# Generate the table
## Specify the names for the variables
custom_coef <- list("PA1" = "PA1 (Food Stability)",
                 "PA2" = "PA2 (Job Stability)",
                 "PA3" = "PA3 (Housing Stability)",
                 "SAI_pre" = "Anxiety Pre",
                 "SAI_post" = "Anxiety Post",
                 "zip_poverty_log" = "ZIP poverty level")

## Create the table
knitreg(list(urg_bias_PA,
            urg_bias_SAI_pre,
            urg_bias_SAI_post,
            urg_bias_ZIP),
       caption = "Urgency Bias Regression Models",
       stars = c(0.001, 0.01, 0.05, 0.1),
       custom.coef.map = custom_coef)

```

### Accuracy

We also obtain a comparison of the choices participants make and the optimal, or rational, protocol we generated. This is done by estimating a hierarchical Bayesian model...

```{r, eval=FALSE}
#| label: fig-exp1costs
#| fig-cap: "Histogram of Estimated Costs per Participant"
dat <- data.frame(dens = c(costs$cH, costs$cL), 
                  lines = rep(c("cH", "cL"), each = nrow(costs)))
ggplot(dat, aes(x = dens, fill = lines)) + 
  #geom_histogram() +
  geom_density(alpha = 0.5)
```

This score is calculated by first estimating the cost parameters for each participant and then using them with backwards induction to discover the optimal choice at each presented state.

```{r exp1-accuracy, eval=FALSE}
write_csv(Accuracy, file = "data/Pilot/Accuracy.csv")
```

```{r, eval=FALSE}
#| label: fig-exp1-accuracy
#| fig-cap: "Histogram of Accuracy Proportions"

hist(Accuracy$Accuracy, breaks=10)

```

@fig-accuracy highlights how participants typically make optimal decisions (when given 'challenging' tasks) with a probability in between 0.5 and 0.6. This is generally what we expect to observe.

#### Accuracy, Anxiety, and Income

1.  Accuracy in trade-off decisions as a function of income and anxiety

Finally, we compare for each participant, how many of their choices are identical to a model that observed the full horizon for the Markov decision process. Each participant is a dot, y axis is the percentage of correct choices in the experiment while x axis is the STAI (anxiety measure). Generally the results are very similar to figure 1.5.

```{r, eval=FALSE}
#| label: fig-exp1-accuracy-results
#| fig-cap: "Participant Accuracy by Income and Anxiety"
#| fig-subcap:
#|   - "Prolific, Income"
#|   - "Prolific, Anxiety"
#| layout-ncol: 2
#| column: page-right
ggplot(Accuracy, aes(x=income, y=Accuracy)) +
  geom_point() +
  stat_smooth(method=loess) +
  geom_label(x=6, y=.8,
             label=paste("Correlation:",
                         round(cor(Accuracy$Accuracy, Accuracy$income), 2)))

ggplot(Accuracy, aes(x=stai, y=Accuracy)) +
  geom_point() +
  stat_smooth(method=loess) +
  geom_label(x=30, y=.8,
             label=paste("Correlation:",
                         round(cor(Accuracy$stai, Accuracy$Accuracy), 2)))

```

It appears that Accuracy does not vary across income and anxiety levels with these measures. Some possibilities of this fact might include that, since time discounting here is virtually 0, leaving the important task behind will not affect participants as much (depending, of course, of the estimated cost parameters).

#### General Linear Models of Accuracy

```{r, eval=FALSE}
#| label: tbl-exp1-accuracy
pglm(formula = Optimal ~ income*stai +
                         age + education + points +
                         chosen_i + chosen_e + chosen_u +
                         not_chosen_i + not_chosen_e + not_chosen_u,
             data = two_options,
             effect = "twoways",
             index = c("participant", "round"),
             model = "random",
             family = binomial('logit')) -> accuracy_income

pglm(formula = Optimal ~ Dim.1*Dim.2  +
                      age + education + points +
                      chosen_i + chosen_e + chosen_u +
                      not_chosen_i + not_chosen_e + not_chosen_u,
             data = two_options,
             effect = "twoways",
             index = c("participant", "round"),
             model = "random",
             family = binomial('logit')) -> accuracy_pca

pglm(formula = Optimal ~ poverty_zip*stai +
                      age + education + points +
                      chosen_i + chosen_e + chosen_u +
                      not_chosen_i + not_chosen_e + not_chosen_u,
             data = two_options,
             effect = "twoways",
             index = c("participant", "round"),
             model = "random",
             family = binomial('logit')) -> accuracy_zipdeprivation

pglm(formula = Optimal ~ median_income_zip*stai  +
                      age + education + points +
                      chosen_i + chosen_e + chosen_u +
                      not_chosen_i + not_chosen_e + not_chosen_u,
             data = two_options,
             effect = "twoways",
             index = c("participant", "round"),
             model = "random",
             family = binomial('logit')) -> accuracy_zipincome
```



### Reaction Time

### Accuracy

# Discussion

Our findings underscore the critical importance of prioritization strategies in task performance. Despite the intuitive appeal of tending to urgent matters, our data suggest that focusing on important tasks yielded superior performance outcomes.

### Intergenerational Poverty

People likely learn how to estimate transition probabilities from parents and peers. If people in this support network are not themselves proficient in estimating, then the individual is left to their own devices. Further, affective states can be passed down generations (e.g., anxiety, stress, depression).

# Future Directions: Experiment 2

## Methodology

### Structure

1.  A clock on the screen will display how long you have until that task, or the customer, decides to leave the line.

2.  This will mean you can no longer make money for that task.

3.  In the first round of this experiment, you will experience monetary "shocks." This means that at random times, some money might be taken from your total accumulated reward with no warning.

4.  In the second round of this experiment, the rate at which orders arrive will be doubled at random times. However, there will be no monetary shocks.

5.  Queue length is not fixed.

\- Skin conductance, Cortisol, Eye tracking

#### §Probabilistic Choice

As seen in @accuracy-results,

Revisit the experiment to address the range of urgent choices. One possibility is to add an artificial discount factor. Another possibility is to explore non-deterministic choices (that is, urgency does not mean certain decay of value from one state to another, but a probable decay).

#### Flexible Queue Size

### Simulation

### Power Analysis

#### §Behavioral Measures

```{r}

#### For Power Analysis
trade_off_scaled <- trade_off_accuracy %>%
  ungroup() %>%
  mutate(
    Dim.1 = scale(Dim.1),
    Dim.2 = scale(Dim.2),
    stai = scale(stai),
  ) %>%
  filter(!is.na(participant) &
         !is.na(stai) &
         !is.na(Dim.1))

# Urgency is whether I choose the urgent task
# in trials where there is a trade off (data = trade_off_scaled)
model_scaled <- 
  pglm(formula = Urgency ~ (Dim.1 + Dim.2)*stai,
       data = trade_off_scaled,
       effect = "twoways",
       index = c("participant", "round"),
       model = "random",
       family = binomial('logit'))

# Success rate at the 1 sd of STAI
exp(model_scaled$estimate["(Intercept)"] + model_scaled$estimate["stai"]) /
  (1 + exp(model_scaled$estimate["(Intercept)"] + model_scaled$estimate["stai"]))

# Success rate at the 1 sd of Dim.2
exp(model_scaled$estimate["(Intercept)"] + model_scaled$estimate["Dim.2"]) /
  (1 + exp(model_scaled$estimate["(Intercept)"] + model_scaled$estimate["Dim.2"]))

# Success rate at the 1 sd of stai:Dim.2
exp(model_scaled$estimate["(Intercept)"] + model_scaled$estimate["Dim.2:stai"]) /
  (1 + exp(model_scaled$estimate["(Intercept)"] + model_scaled$estimate["Dim.2:stai"]))

# Success rate at the mean of stai:Dim.2
exp(model_scaled$estimate["(Intercept)"]) /
  (1 + exp(model_scaled$estimate["(Intercept)"]))

# calculate McFadden's R-squared

model_null <- 
  pglm(formula = Urgency ~ 1,
       data = trade_off_scaled,
       index = c("participant", "round"),
       family = binomial('logit'))

as.numeric(1 - logLik(model_scaled)/logLik(model_null))

# number of effective trials per subject
length(trade_off_scaled$participant)/length(unique(trade_off_scaled$participant))


## With income + STAI

```

#### ¶Physiological Measures

"Sartorial Symbols of Social Class Elicit Class-Consistent Behavioral and Physiological Responses: A Dyadic Approach" (Kraus et al 2014)

Goal of paper: Determine the psychological response among participants paired across socio-economic groups.

N = 128, 64 dyads (20 upper class, 20 lower class, 24 neutral condition)

DV = HRV (Heart Rate Variability) reactivity differences between high vs. low class

Prior = Upper-class = -0.69, se = 0.31; Lower-class = 0.04, se = 0.31

```{r}

# # HVC across SES
# Estimated sample sizes for a two-sample means test
# t test assuming sd1 = sd2 = sd
# HO: m2 = m1 versus Ha: m2 != m1
# Study parameters:
# alpha = 0.0500
# power = 0.8000
# delta = -0.7300
# m1 = 0.0400
# m2 = -0.6900
# sd = 1.3860
# Estimated sample sizes:
# N=
# N per group =
# 116
# 58
```

#### Perceived Effort

Stress has been suggested to increase perceived effort (e.g., the study will investigate whether it's more tiring to complete a task when stressed), leading low-income individuals to be less likely to take up welfare programs, regardless of eligibility (Bertrand et al., 2006; Hernanz et al., 2004).

In our model, cost can include a subjective component. Instead of counting it as simply the number of clicks, we can assume that the agent may dread or fantasize about action $a$. As such, someone who likes the task might not be bothered by doing it so the cost may be very close to zero (or negative). And vice versa for someone who hates it. Similarly, we can account for substituting *subjective* probability for objective probability. That is, people might distort the actual probability of future events.

## Hypotheses

## Population

In Los Angeles, 18% of residents worry every day or almost every day about paying their bills, and 23% worry about job loss (Baldassare et al., 2021). This constant mindset of worry likely affects the livelihood of these citizens. In a recent PPIC survey, about "one in five Californians report that they or someone in their household has cut back on food (21%), put off seeing a doctor or purchasing medicine to save money (18%), been unable to pay a monthly bill (17%), or had difficulty paying the rent or mortgage (17%) in the last 12 months" (Baldassare et al., 2021).

### Online Sample

Pros and cons.

### Homeless

M: Look Sera's studies

IRB: Justification

### Other Low SES Cohorts

M: Proposal

# Conclusion

# References

# Appendix: Supplementary Models and Analyses

## Burstiness and Memory in Discreet Event Simulation

Further, with interevent times, we can calculate the burstiness and memory as a function of urgency weights.

```{r}
#| label: fig-simmer-burstiness
#| fig-cap: "Burstiness by Urgency Weight"

urgency_burstiness_grid <- read_csv("data/Pilot/urgency-burstiness-grid.csv")

plt_bursty <-
  ggplot(urgency_burstiness_grid,
         aes(x = M, y = B)) +
  geom_jitter(aes(color = weights),
              size = 1,
              alpha = 0.8) +
  labs(color = "Urgency Weight") +
  scale_color_viridis(option = "D")

plt_bursty +
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = 0)

```

@simmer-burstiness shows that the surviving tasks are indeed around the area of bursty phenomena as reported in the literature. However, there does not seem to be a relationship between urgency weighting and burstiness.

## Fantasy and Dread Model

$$
\begin{aligned}
& V\left(s^{\prime}\right)=r(a)-c(a)+\gamma \sum_s P\left(a, s^{\prime}, s^{\prime \prime}\right) V\left(s^{\prime \prime}\right) \\
& \mathrm{SV}\left(\mathrm{s}^{\prime}\right)=\mathrm{r}(\mathrm{a})-e\left(a \mid z_e\right)+\gamma \sum_s S P(\cdot) V\left(s^{\prime}\right) \\
& e\left(a \mid z_e\right)=z_e(c(e)) \\
& \mathrm{SP}\left(a, s^{\prime}, s^{\prime \prime} \mid z_p\right)=z_p\left(P\left(a, s^{\prime}, s^{\prime \prime}\right)\right)
\end{aligned}
$$

where $z_e, z_p$ correspond to fantasy/dread and a sense of urgency, respectively. One possible

P() depends on whether unattended task "decays"

::: {#fig-prob-weighting layout-ncol="2"}
![Probability Weighting](images/prob-weighting.png){#fig-prob-weight}

![Probability Example](images/sense-urgency-illustration.png){#fig-sense-urg}

Example of Subjective Probabilities
:::

## Priority Queuing Simulation

```{r pri-q-simulation, eval=FALSE, include=TRUE}

library(simmer)
library(simmer.plot)
library(latex2exp)
#library(data.table)

# Parameters
lambda <- 5
mu <- 5
t_simul <- 150 #Calibrated to optimize simulation time (prob_continue ≈ 0)
n_simul <- 2
scale = 100 # The scale on alpha to transfer runif(0,1) to something with more variance

weights <- seq(0, 1, by = 0.001)
arri <- list()
attr <- list()
total <- list()

# Simulations with simmer
for (w in 1:length(weights)) {
  env <- simmer("poverty")
  
  person <- trajectory("Poor's Trajectory") %>%
    set_attribute(keys = "urgency", function()
      runif(1, 0, 1)) %>%
    set_attribute(keys = "importance", function()
      runif(1, 0, 1)) %>%
    set_attribute(keys = "weight", weights[w]) %>%
    set_prioritization(function() {
      prio <-
        10000 * (
          get_attribute(env, "weight") * get_attribute(env, "urgency") +
            (1 - get_attribute(env, "weight")) * get_attribute(env, "importance")
        )
      c(prio, NA, NA)
    }) %>%
    # log_(function() {
    #   paste("Priority is: ", get_prioritization(env)[1])
    # }) %>%
    seize("person", amount = 1) %>%
    timeout(function()
      rexp(1, mu)) %>%
    release("person", amount = 1)
  
  env <-
    simmer() %>%
    add_resource("person", capacity = 1) %>%
    add_generator("Task", person, function()
      rexp(1, lambda), mon = 2)
  
  # env %>% run(until = t_simul)
  
  envs <- lapply(1:n_simul, function(i) {
    env %>%
      run(until = t_simul) %>%
      wrap()
  })
  
  ## Change Variables before
  arri[[w]] <- get_mon_arrivals(envs, ongoing = TRUE)
  attr[[w]] <- get_mon_attributes(envs)
  
  # Merge
  total[[w]] <-
    inner_join(arri[[w]], attr[[w]][attr[[w]]$key == "urgency", c(2, 4, 5)], by = c("name", "replication"))
  total[[w]] <-
    total[[w]] %>%
    rename(urgency = value)
  total[[w]] <-
    total[[w]][order(total[[w]]$replication, total[[w]]$start_time, decreasing = FALSE), ]
  row.names(total[[w]]) <- NULL
  total[[w]] <-
    inner_join(total[[w]], attr[[w]][attr[[w]]$key == "importance", c(2, 4, 5)], by = c("name", "replication"))
  total[[w]] <-
    total[[w]] %>%
    rename(importance = value)
  total[[w]] <-
    total[[w]][order(total[[w]]$replication, total[[w]]$start_time, decreasing = FALSE), ]
  row.names(total[[w]]) <- NULL
  total[[w]]$waiting_time <-
    total[[w]]$end_time - total[[w]]$start_time - total[[w]]$activity_time

    # Take care of precision problems yielding negative wait times.
  if (nrow(total[[w]][total[[w]]$waiting_time < 0 &
                      !is.na(total[[w]]$waiting_time), ]) > 0) {
    total[[w]][total[[w]]$waiting_time < 0 &
                 !is.na(total[[w]]$waiting_time), ]$waiting_time <- 0
  }

  #Weibull distribution with monomial function
  alpha = (scale - scale * as.numeric(total[[w]]$urgency)) #for now
  beta = 1
  total[[w]]$prob_fail <-
    1 - exp(-1 * (total[[w]]$waiting_time / alpha) ^ (beta))

  # Get probability of survival
  total[[w]] <- total[[w]] %>%
    mutate(prob_continue = (1 - prob_fail)) %>%
    group_by(replication) %>%
    mutate(prob_continue = lag(cumprod(prob_continue), k=1, default=1))

  cat('Simulation', w, 'of', length(weights), '\n')
}

sigma_list <- lapply(X = total, function(X)   sd(X[!is.na(X$waiting_time), ]$waiting_time))
mu_list    <- lapply(X = total, function(X) mean(X[!is.na(X$waiting_time), ]$waiting_time))
lag_time <- lapply(X = total, function(X) X %>%
                     filter(!is.na(waiting_time)) %>%
                     group_by(replication) %>%
                     mutate(waiting_time_lag = lag(waiting_time, default = 0)) %>%
                     dplyr::select(waiting_time, waiting_time_lag) %>%
                     cor())
memory   <- lapply(X = lag_time, function(X) X[2,3])


# Burstiness -------------------------------------------------------------
burstiness <- data.frame(weights) %>%
  mutate(sigma = unlist(sigma_list)) %>%
  mutate(mu = unlist(mu_list)) %>%
  mutate(B = (sigma - mu) / (sigma + mu)) %>%
  mutate(M = unlist(memory))

# Probability of Survival -------------------------------------------------
prob_survival <- lapply(X = total,
                        function(X) X %>%
                          group_by(name) %>%
                          summarise(mean_survival = mean(prob_continue),
                                    mean_time = mean(end_time)) %>%
                          rename(task = name) %>%
                          mutate(task = readr::parse_number(task))
                          )
names(prob_survival) <- weights
survival <- prob_survival %>%
  bind_rows(.id = "weight")

```

## Dynamic Programming Simulation

In this analysis, we constructed a Markov Decision Process (MDP) model of the game, then used dynamic programming to solve the MDP and derive an optimal policy -- the best course of action at each state. To derive a dynamic programming strategy to optimally play the game, we must clearly define the state, action, and reward at each step in the game.

1.  **State**: The state of the game at any given time can be represented by the current tasks in the queue, each of which is characterized by its effort, importance (value), and urgency. Additionally, the state should also include the round number because the available tasks and their urgency can change from round to round.

2.  **Action**: An action in this game is the selection of a task from the queue.

3.  **Reward**: The reward is the profit (points) gained from completing a task, which is determined by its value (importance).

With these definitions, we can formulate the optimal policy of the game using dynamic programming. The goal is to maximize the total profit over the game.

We denote the state at round $i$ as $s_i$ and an action at round $i$ as $a_i$. The reward of taking action $a_i$ at state $s_i$ is denoted as $r(s_i, a_i)$. The state-transition function, which describes the new state after taking an action, is denoted as $T(s_i, a_i)$. Our aim is to find the policy $\pi^*$ that maximizes the total reward:

$$
 \pi^* = \arg\max_{\pi} \sum_{i=1}^{40} r(s_i, \pi(s_i))
$$

The Bellman equation for this game can be written as:

$$
V(s) = \max_{a} \left( r(s, a) + V(T(s, a)) \right)
$$

This equation states that the value of a state $s$ is the maximum over all actions $a$ of the immediate reward $r(s, a)$ plus the value of the state resulting from taking action $a$, $V(T(s, a))$.

The crux of this methodology revolves around the Value Iteration algorithm, which involves iteratively updating the value function (the expected cumulative reward from each state) until convergence. To find the optimal policy, we use backward induction; that is, we start at the end of the game and work backward, iteratively computing the value function for each state until we reach the start of the game. At each state, the optimal action is the one that maximizes the immediate reward plus the value of the next state.

Interestingly, after a sufficient number of iterations (over 100 trials), we observed a steady state in the value function, whereby the expected cumulative reward was nearly identical across all states. This convergence suggests that as we approach infinity, the long-term expected reward is almost the same, irrespective of the state under an optimal policy.

Notably, this does not imply that the policy for each state will be identical. However, as is common in many Markov Decision Processes, the task-based game has a level of inherent balance, where we have structured the potential outcomes of different actions to ensure a relatively even distribution of long-term rewards across various states.

Above all, these findings underline the complexity of decision-making processes and the intricate dynamics in this and other task-based games. In practice, the large number of possible states in this game (due to the different combinations of tasks and their characteristics) might make exact dynamic programming infeasible for humans. As such, approximation methods such as function approximation or reinforcement learning techniques are necessary.

```{python, eval = FALSE}
import pandas as pd
import ast

# Load the transition probabilities from the CSV file
transition_df = pd.read_csv('./Models/dyn_prog/transition_df.csv')
# Define the discount factor
gamma = 0.9
# Maximum number of rounds
num_rounds = 40
# Cost and Reward
costH = 0.5
costL = 0.1
rewardH = 2
rewardL = 1

def reward(state, action):
    # Split the state into tasks
    tasks = state.split(',')
    # The task is chosen based on the action
    if len(tasks) < 2 or tasks[action] == '<NA>':
      return None
    # Calculate Cost
    cost = costH if tasks[action][1] == 'H' else costL
    # Calculate the reward
    if tasks[action][0] == 'H':
      return rewardH - cost
    elif tasks[action][0] == 'L':
      return rewardL - cost
    else:
      return None

# Create empty dataframes to store the values and actions for each state and round
value_df = pd.DataFrame(index=transition_df['Unnamed: 0'], columns=range(1, num_rounds + 1))
policy_df = pd.DataFrame(index=transition_df['Unnamed: 0'], columns=range(1, num_rounds + 1))

# Fill in the last column of the value matrix with the reward for each state-action pair at the final time step
for state in transition_df['Unnamed: 0']:
    Q = []
    for action in [0, 1]:
        r = reward(state, action)
        if r is not None:  # If the action is valid
            Q.append(r)
        else:  # If the action is not valid
            Q.append(0)
    value_df.loc[state, num_rounds] = max(Q)
    policy_df.loc[state, num_rounds] = Q.index(max(Q))  # The action that yields the maximum reward

# Work backwards, iteratively filling in each column of the matrix
for round in reversed(range(1, num_rounds)):  # From (num_rounds - 1) to 1
    for state in transition_df['Unnamed: 0']:
        # Identify the index of the current state
        idx = transition_df.index[transition_df['Unnamed: 0'] == state][0]
        # Calculate the expected cumulative reward for each possible action
        Q = []
        for action in [0, 1]:
            r = reward(state, action)
            if r is not None:  # If the action is valid
                transition_probs = ast.literal_eval(transition_df.iloc[idx, action + 1])
                Q.append(r + gamma * sum(transition_probs.get(next_state, 0) * value_df.loc[next_state, round + 1]
                                         for next_state in transition_df['Unnamed: 0']))
            else:  # If the action is not valid
                Q.append(0)
        # Update the value function and the policy
        value_df.loc[state, round] = max(Q)
        policy_df.loc[state, round] = Q.index(max(Q))  # The action that yields the maximum expected cumulative reward

value_df.to_csv('./dyn_prog/value_df.csv')
policy_df.to_csv('./dyn_prog/policy_df.csv')

```

```{r dyn-pro-simulation, eval=FALSE, include=TRUE}

library(stringi)
library(stringr)

#Importance
imp <- c(1,2)
#Cost
cost1 = 0
cost2_grid <- seq(from = 0.1, to = 0.9, by = 0.05)
#Discounting
gamma_grid <- seq(from = 0.8, to = 1, by = 0.025)
#Choices
tasks <- c("HHU",
            "HH0",
            "HLU",
            "HL0",
            "LHU",
            "LH0",
            "LLU",
            "LL0")
tasks <- as.data.frame(tasks)
# Urgency Ratios
ratios <- c()

for (gamma in gamma_grid) {
  print(gamma)
  for (cost2 in cost2_grid) {
    # Add values
    tasks$value  <- c(imp[2]-cost2,
                      imp[2]-cost2,
                      imp[2]-cost1,
                      imp[2]-cost1,
                      imp[1]-cost2,
                      imp[1]-cost2,
                      imp[1]-cost1,
                      imp[1]-cost1)
    #Look up values
    r_choice <- tasks$value
    names(r_choice) <- tasks$tasks
    ## Use unname(r_choice["HH0"]) for example
    
    # States
    S <- as.data.frame(t(combn(tasks$tasks,2)))
    for (chr in tasks$tasks) {
      # Add states with two of the same task
      S <- rbind(S,c(chr,chr))
      # Add states with only one task transition to one task
      S <- rbind(S,c(chr,NA))
      # Add states with only one task transitioning to two tasks
      S <- rbind(S,c(chr,"TR"))
    }
    
    #Choice|States
    ## 1st column is choice.
    ## 1st+2nd columns are the state
    ch <- expand.grid(tasks$tasks,tasks$tasks)
    # Fix factor levels for next step
    levels(ch$Var2)
    levels(ch$Var2) = c("HHU", "HH0", "HLU", "HL0", "LHU", "LH0", "LLU", "LL0", "TR")
    for (chr in tasks$tasks) {
      ch <- rbind(ch,c(chr,NA))
      ch <- rbind(ch,c(chr,"TR"))
    }
    
    # Transition Probabilities
    choices <- paste(ch$Var1,ch$Var2,sep = "x")
    states <- paste(S$V1,S$V2,sep = "x")
    transitions <- expand.grid(choices,states)
    # Remaining task (last 3 characters) is in the next state, but no NA
    transitions$prob <- NA
    ## Non-urgent tasks:
    ## Note this is also transitioning to NA and TR states. Fix it in line 91 and __
    transitions[str_detect(str = str_sub(transitions$Var1,-3), pattern = "0"),]$prob <- 
      str_detect(str = transitions[str_detect(str = str_sub(transitions$Var1,-3), pattern = "0"),]$Var2,
                 pattern = str_sub(transitions[str_detect(str = str_sub(transitions$Var1,-3), pattern = "0"),]$Var1,-3))
    ## Urgent tasks: 
    ### If HXU -> LXU
    transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
                  str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "H"),]$prob <-
      str_detect(str = transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
                                     str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "H"),]$Var2,
                 pattern = paste("L",
                                 str_sub(transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
                                                       str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "H"),]$Var1,
                                         start = -2,
                                         end = -2),"U",sep = ""))
    ### If LXU -> NA
    ## first change all transitions to false
    transitions[str_detect(str = str_sub(transitions$Var2,-3), pattern = "NA"),]$prob <- FALSE
    # Now calculate other transitions
    transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
                  str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "L"),]$prob <-
      str_detect(str = transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
                                     str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "L"),]$Var2,
                 pattern = "NA")
    
    ## Single task with transition to single task:
    transitions[str_detect(str = transitions$Var1, pattern = "NA"),]$prob <-
      str_detect(str = transitions[str_detect(str = transitions$Var1, pattern = "NA"),]$Var2,
                 pattern = "TR")
    ## Single task with transition to single task:
    transitions[str_detect(str = transitions$Var1, pattern = "TR"),]$prob <- 0
    
    #Transforming them into probabilities by dividing by 8
    transitions$prob <- as.numeric(transitions$prob)
    transitions$prob <- transitions$prob / 8
    
    ## Single task with transition to single task:
    transitions[str_detect(str = transitions$Var1, pattern = "TR") &
                  str_length(transitions$Var2) == 7,]$prob <- 1/36
    
    ##################################################
    ################# Simulation
    ##################################################
    
    # Backwards induction
    ## Determine number of loops
    rounds = 20
    ## Create column with values of each choice for each round
    col_names <- paste("rd", c(1:rounds), sep = "")
    ch[col_names] <- NA
    ## Last round:
    ### fill in column in "ch" with the values
    for(choice in tasks$tasks) {
      ### first column is choice: find in tasks table the value of that choice
      ch[ch$Var1 == choice,rounds+2] <- tasks[tasks$tasks == choice,]$value
    }
    ### Multiply by discount factor^round
    ch[,rounds+2] <- ch[,rounds+2]*gamma^(rounds-1)
    
    
    ## Create state values for each round
    S[col_names] <- NA
    ### for each state in "S" choose the highest value in "ch" and create another column with the values
    best_option <- function(round, choice_matrix = ch, state_matrix = S, label_matrix = label){
      for(row in c(1:nrow(state_matrix))) {
        if (is.na(state_matrix[row,]$V2)) {
          state_matrix[row,round + 2] <- choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V1 &
                                                         is.na(choice_matrix$Var2),round +2]
          label_matrix[row,round + 2] <- as.character(choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V1 & 
                                                                      is.na(choice_matrix$Var2), 1])
        } else if (as.character(state_matrix[row,]$V2) == "TR") {
          state_matrix[row,round + 2] <- na.exclude(choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V1 &
                                                                    choice_matrix$Var2 == state_matrix[row,]$V2,round + 2])
          label_matrix[row,round + 2] <- as.character(choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V1 &
                                                                      is.na(choice_matrix$Var2), 1])
        } else {
          choice1 <- choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V1 &
                                     choice_matrix$Var2 == state_matrix[row,]$V2 &
                                     !is.na(choice_matrix$Var2) &
                                     as.character(choice_matrix$Var2) != "TR",round +2]
          choice2 <- choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V2 &
                                     choice_matrix$Var2 == state_matrix[row,]$V1 &
                                     !is.na(choice_matrix$Var2) &
                                     as.character(choice_matrix$Var2) != "TR",round +2]
          if (choice1 > choice2) {
            state_matrix[row,round + 2] <- choice1
            # ### save choices: change the suboptimal choices to NA
            # choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V2 &
            #                 choice_matrix$Var2 == state_matrix[row,]$V1 &
            #                 !is.na(choice_matrix$Var2) &
            #                 as.character(choice_matrix$Var2) != "TR",round +2] <- NA
            label_matrix[row,round + 2] <- as.character(na.exclude(choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V1 &
                                                                        choice_matrix$Var2 == state_matrix[row,]$V2, 1]))
          } else if (choice1 < choice2) {
            state_matrix[row,round + 2] <- choice2
            # ### save choices: change the suboptimal choices to NA
            # choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V1 &
            #                 choice_matrix$Var2 == state_matrix[row,]$V2 &
            #                 !is.na(choice_matrix$Var2) &
            #                 as.character(choice_matrix$Var2) != "TR",round +2] <- NA
            label_matrix[row,round + 2] <- as.character(na.exclude(choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V2 &
                                                                        choice_matrix$Var2 == state_matrix[row,]$V1, 1]))
          } else if (choice2 == choice1){
            state_matrix[row,round + 2] <- choice1
            label_matrix[row,round + 2] <- "either"
          }
        }
      }
      return(list(state_matrix,choice_matrix,label_matrix))
    }
    
    label <- S
    new_states_choices <- best_option(rounds)
    S <- new_states_choices[[1]]
    ch <- new_states_choices[[2]]
    label <- new_states_choices[[3]]
    ## second to last round to first round
    ### loop through the choices|states in "S"
    ### For each choice|state, calculate the the expected value
    
    # We need to change "transitions" for simplicity of search
    transitions$choice <- substr(transitions$Var1, 1, 3)
    transitions$non_choice <- substr(transitions$Var1, 5, 7)
    transitions[transitions$non_choice == "NA",]$non_choice <- NA
    transitions$state2_1 <- substr(transitions$Var2, 1, 3)
    transitions$state2_2 <- substr(transitions$Var2, 5, 7)
    transitions[transitions$state2_2 == "NA",]$state2_2 <- NA
    
    for(i in c(1:(rounds-1))){
      values <- S[,c(1,2,(rounds+3-i))]
      for(row in c(1:nrow(ch))){
        #### create probability vector P [44x1] from "transitions"
        if(!is.na(ch[row,2])) {
          prob_weight <- 
            transitions[ch[row,1] == transitions$choice &
                          ch[row,2] == transitions$non_choice &
                          !is.na(ch[row,2]) &
                          !is.na(transitions$non_choice),]
        } else if(is.na(ch[row,2])) {
          prob_weight <- 
            transitions[ch[row,1] == transitions$choice &
                          is.na(ch[row,2]) &
                          is.na(transitions$non_choice),]
        }
        
        #### Make sure "S" is in the same order [1x44]
        prob_weight <- merge(x = prob_weight,
                             y = values,
                             by.x = c("state2_1", "state2_2"),
                             by.y = c("V1", "V2"))
        prob_weight$weighted_value <- prob_weight$prob * values[,c(length(values))]
        ### Multiply by discount factor^round
        ch[row,rounds+2-i] <- gamma^(rounds-1-i)*tasks[tasks$tasks == ch[row,1],]$value + sum(prob_weight$weighted_value)
      }
      new_states_choices <- best_option(rounds-i)
      S <- new_states_choices[[1]]
      ch <- new_states_choices[[2]]
      label <- new_states_choices[[3]]
    }
    urgency <- apply(label[,-c(1:2)], 2, function(X) substr(X, nchar(X), nchar(X)))
    ratios <- append(ratios, table(urgency)["U"]/sum(table(urgency)))
  }
}

ratios_grid <- matrix(ratios,
                      nrow = length(gamma_grid),
                      ncol = length(cost2_grid),
                      dimnames = list(gamma_grid,
                                      cost2_grid))

### Export labels
write.csv(ratios_grid,"./urgency-ratio-grid.csv")

```

## Bayesian Model for Cost Estimation

### Model

```{stan cost-model, eval=FALSE, include=TRUE, output.var="my_model"}
data {
  int<lower=1> N;
  int<lower=1> T;
  int<lower=2> nOpt;
  int<lower=1, upper=T> Tsubj[N];
  int<lower=0, upper=nOpt> choice[N, T]; //left or right?
  int<lower=0, upper=80> opt_st[N, T]; //option-state: an easy way to map the choices for choice prob calculation
  int value_lookup[80];
  int state_lookup[52, nOpt];
  matrix<lower=0, upper = 1>[80, 52] prob_weight;
  int<lower=0, upper=80> counterpart[80];
  // real outcome[N, T];  // no lower and upper bounds
}
transformed data {
  vector[nOpt] initV;  // initial values for EV
  initV = rep_vector(0.0, nOpt);
}
parameters {
// Declare all parameters as vectors for vectorizing
  // Hyper(group)-parameters
  vector[2] mu_pr;
  vector<lower=0>[2] sigma;

  // Subject-level parameters (for transformation from hyper to subj parameter)
  vector[N] costL;  // cost_low
  vector[N] costH;    // cost_high
}
model {
  // Hyperparameters
  mu_pr  ~ normal(0, 5); //weakly informative priors
  sigma ~ gamma(2,0.1); //weakly informative priors

  // individual parameters
  for (i in 1:N) {
    //tau[i]   = Phi_approx(mu_pr[1]  + sigma[1]  * tau_pr[i]); //approx Normal CDF + noise
    costL[i] ~ normal(mu_pr[1], sigma[1]);
    costH[i] ~ normal(mu_pr[2], sigma[2]);
  }

  // subject loop and trial loop
  for (i in 1:N) {
    vector[nOpt] ev; // expected value
    vector[4] value; // vector of value option, lookup table
    matrix[80, Tsubj[i]] ch; 
    matrix[52, Tsubj[i]] st;
    int round_back; // backwards counter for induction
    real weighted_value;
    
    ev = initV;

    // Declaring values for each option, lookup table (make it loop later)
    value[1] = 2 - costH[i];
    value[2] = 1 - costH[i];
    value[3] = 1 - costL[i];
    value[4] = 2 - costL[i];


    // Backwards induction
    //  fill in column in "ch" with the values
    for(option in 1:80) {
      // first column is choice: find in tasks table the value of that choice
      // lookup is a vector that tells you which cost correspondends to each choice
      ch[option, Tsubj[i]] = value[value_lookup[option]];
    }
    //    Create state values for each round
    // state_lookup tells you which choice|state maps onto which state
    // for each state in "S" choose the highest value in "ch" and create another column with the values
    for(state in 1:52) {
      if (ch[state_lookup[state,1], Tsubj[i]] >= ch[state_lookup[state,2], Tsubj[i]]) {
        st[state, Tsubj[i]] = ch[state_lookup[state,1], Tsubj[i]];
      } else if (ch[state_lookup[state,1], Tsubj[i]] < ch[state_lookup[state,2], Tsubj[i]]) {
        st[state, Tsubj[i]] = ch[state_lookup[state,2], Tsubj[i]];
      }
    }
        // compute action probabilities
        ev[1] = ch[opt_st[i, Tsubj[i]], Tsubj[i]];
        ev[2] = ch[counterpart[opt_st[i, Tsubj[i]]], Tsubj[i]];
        choice[i, Tsubj[i]] ~ categorical_logit(ev);
        
        for (t in 1:(Tsubj[i]-1)) {
          round_back = Tsubj[i] - t;
          for(option in 1:80) {
            // use action probabilities
            weighted_value = dot_product(prob_weight[option], col(st, (round_back + 1)) );
            ch[option, round_back] = value[value_lookup[option]] + weighted_value;
          }
          for(state in 1:52) {
            if (ch[state_lookup[state,1], round_back] >= ch[state_lookup[state,2], round_back]) {
              st[state, round_back] = ch[state_lookup[state,1], round_back];
            } else if (ch[state_lookup[state,1], round_back] < ch[state_lookup[state,2], round_back]) {
              st[state, round_back] = ch[state_lookup[state,2], round_back];
            }
          }
          // compute action probabilities
          ev[1] = ch[opt_st[i, round_back], round_back];
          ev[2] = ch[counterpart[opt_st[i, round_back]], round_back];
          choice[i, round_back] ~ categorical_logit(ev);
        }
  }
  
}
```

### Model Data

```{r cost-model-data, eval=FALSE, include=TRUE}
# Data Wrangling ----------------------------------------------------------
load("Prolific-pilot1.Rdata")
data <- pilot1[!is.na(pilot1$participant),]
data <- data %>%
  group_by(participant) %>%
  mutate(COUNTER = row_number())
Tsubj <- data %>%
  group_by(participant) %>%
  summarize(n = n())

# Creating Choice set ----------------------------------------------------------
choices <- c("HHU", "HH0", "HLU", "HL0", "LHU", "LH0", "LLU", "LL0")
ch <- expand.grid(choices, choices)
# Fix factor levels for next step
levels(ch$Var2) = append(choices, "TR")
for (chr in choices) {
  ch <- rbind(ch,c(chr,NA))
  ch <- rbind(ch,c(chr,"TR"))
}

# Creating State set ----------------------------------------------------------
S <- as.data.frame(t(combn(choices,2)))
for (chr in choices) {
  # Add states with two of the same task
  S <- rbind(S,c(chr,chr))
  # Add states with only one task transition to one task
  S <- rbind(S,c(chr,NA))
  # Add states with only one task transitioning to two tasks
  S <- rbind(S,c(chr,"TR"))
}

# Create Transition Set ----------------------------------------------------------
# Transition Probabilities
choices <- paste(ch$Var1,ch$Var2,sep = "x")
states <- paste(S$V1,S$V2,sep = "x")
transitions <- expand.grid(choices,states)
# Remaining task (last 3 characters) is in the next state, but no NA
transitions$prob <- NA
## Non-urgent tasks:
transitions[str_detect(str = str_sub(transitions$Var1,-3), pattern = "0"),]$prob <- 
  str_detect(str = transitions[str_detect(str = str_sub(transitions$Var1,-3), pattern = "0"),]$Var2,
             pattern = str_sub(transitions[str_detect(str = str_sub(transitions$Var1,-3), pattern = "0"),]$Var1,-3))
## Urgent tasks: 
### If HXU -> LXU
transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
              str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "H"),]$prob <-
  str_detect(str = transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
                                 str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "H"),]$Var2,
             pattern = paste("L",
                             str_sub(transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
                                                   str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "H"),]$Var1,
                                     start = -2,
                                     end = -2),"U",sep = ""))
### If LXU -> NA
## first change all transitions to false
transitions[str_detect(str = str_sub(transitions$Var2,-3), pattern = "NA"),]$prob <- FALSE
# Now calculate other transitions
transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
              str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "L"),]$prob <-
  str_detect(str = transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
                                 str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "L"),]$Var2,
             pattern = "NA")

## Single task with transition to single task:
transitions[str_detect(str = transitions$Var1, pattern = "NA"),]$prob <-
  str_detect(str = transitions[str_detect(str = transitions$Var1, pattern = "NA"),]$Var2,
             pattern = "TR")
## Single task with transition to single task:
transitions[str_detect(str = transitions$Var1, pattern = "TR"),]$prob <- 0

#Transforming them into probabilities by dividing by 8
transitions$prob <- as.numeric(transitions$prob)
transitions$prob <- transitions$prob / 8

## Single task with transition to single task:
transitions[str_detect(str = transitions$Var1, pattern = "TR") &
              str_length(transitions$Var2) == 7,]$prob <- 1/36
# We need to change "transitions" for simplicity of search
transitions$choice <- substr(transitions$Var1, 1, 3)
transitions$non_choice <- substr(transitions$Var1, 5, 7)
transitions[transitions$non_choice == "NA",]$non_choice <- NA
transitions$state2_1 <- substr(transitions$Var2, 1, 3)
transitions$state2_2 <- substr(transitions$Var2, 5, 7)
transitions[transitions$state2_2 == "NA",]$state2_2 <- NA


# create choice[N,T] ----------------------------------------------------------
data$choice_bin <- 1
data[data$choice == "R",]$choice_bin <- 2
choice <- data %>%
  dplyr::select(participant, COUNTER, choice_bin) %>%
  group_by(COUNTER) %>%
  spread(COUNTER, choice_bin)
# Take NAs out
choice[is.na(choice)] <- 0


# Option-State ------------------------------------------------------------
## an easy way to map the choices for choice prob calculation
ch_opt_translation <- ch[,c(1:2)]
ch_opt_translation$index <- c(1:length(ch_opt_translation$Var1))
ch_opt_translation$i1 <- NA
ch_opt_translation$e1 <- NA
ch_opt_translation$i2 <- NA
ch_opt_translation$e2 <- NA

ch_opt_translation$u1 <- grepl("U", ch_opt_translation$Var1)
ch_opt_translation$u2 <- grepl("U", ch_opt_translation$Var2)
ch_opt_translation[is.na(ch_opt_translation$Var2), ]$u2 <- NA
ch_opt_translation$u1 <- as.numeric(ch_opt_translation$u1) + 1
ch_opt_translation$u2 <- as.numeric(ch_opt_translation$u2) + 1

ch_opt_translation$i1 <- ifelse(substring(ch_opt_translation$Var1, 1, 1) == "H", 2, 1)
ch_opt_translation$i2 <- ifelse(substring(ch_opt_translation$Var2, 1, 1) == "H", 2, 1)
ch_opt_translation[is.na(ch_opt_translation$Var2), ]$i2 <- NA

ch_opt_translation$e1 <- ifelse(substring(ch_opt_translation$Var1, 2, 2) == "H", 2, 1)
ch_opt_translation$e2 <- ifelse(substring(ch_opt_translation$Var2, 2, 2) == "H", 2, 1)
ch_opt_translation[is.na(ch_opt_translation$Var2), ]$e2 <- NA

ch_opt_translation[grepl("TR", ch_opt_translation$Var2), ]$i2 <- 
  ch_opt_translation[grepl("TR", ch_opt_translation$Var2), ]$i1
ch_opt_translation[grepl("TR", ch_opt_translation$Var2), ]$e2 <- 
  ch_opt_translation[grepl("TR", ch_opt_translation$Var2), ]$e1
ch_opt_translation[grepl("TR", ch_opt_translation$Var2), ]$u2 <- 
  ch_opt_translation[grepl("TR", ch_opt_translation$Var2), ]$u1

ch_opt_translation[grepl("TR", ch_opt_translation$Var2), ]$i1 <- NA
ch_opt_translation[grepl("TR", ch_opt_translation$Var2), ]$e1 <- NA
ch_opt_translation[grepl("TR", ch_opt_translation$Var2), ]$u1 <- NA

data <- merge(x = data,
              y = ch_opt_translation[,-c(1:2)],
              by = c("u1", "u2", "e1", "e2", "i1", "i2"))

opt_st <- data %>%
  dplyr::select(participant, COUNTER, index) %>%
  group_by(COUNTER) %>%
  spread(COUNTER, index)
# Take NAs out
opt_st[is.na(opt_st)] <- 0

ch_opt_translation$value <- 0
ch_opt_translation[grepl("HH", ch_opt_translation$Var1),]$value = 1
ch_opt_translation[grepl("LH", ch_opt_translation$Var1),]$value = 2
ch_opt_translation[grepl("LL", ch_opt_translation$Var1),]$value = 3
ch_opt_translation[grepl("HL", ch_opt_translation$Var1),]$value = 4


S$st_index <- c(1:nrow(S))
S <- merge(x = S,
           y = ch_opt_translation[,c(1:3)],
           by.x = c("V1", "V2"),
           by.y = c("Var1", "Var2"))
ch_opt_translation$index2 <- ch_opt_translation$index
S <- merge(x = S, 
           y = ch_opt_translation[,c(1:2,11)],
           by.x = c("V2", "V1"),
           by.y = c("Var1", "Var2"),
           all.x = TRUE)
state_lookup <- S %>%
  dplyr::select(st_index, index, index2)
# Take NAs out
state_lookup[is.na(state_lookup$index2),]$index2 <- state_lookup[is.na(state_lookup$index2),]$index
# Order state_lookup
state_lookup <- state_lookup %>%
  arrange(order_by = st_index)

prob_weight <- merge(x = transitions,
                      y = ch_opt_translation[,c(1:3)],
                      by.x = c("choice", "non_choice"),
                      by.y = c("Var1", "Var2"))
prob_weight <- merge(x = prob_weight,
                     y = ch_opt_translation[,c(1:2,11)],
                     by.x = c("state2_1", "state2_2"),
                     by.y = c("Var1", "Var2"))


# Map Choices to States ---------------------------------------------------
choice_state <- as.data.frame(c(1:80))
choice_state <- merge(x = choice_state,
                      y = state_lookup[,-c(3)],
                      by.x = c("c(1:80)"),
                      by.y = c("index"),
                      all.x = TRUE)
choice_state <- merge(x = choice_state,
                      y = state_lookup[,-c(2)],
                      by.x = c("c(1:80)"),
                      by.y = c("index2"),
                      all.x = TRUE)
choice_state$st_index <- choice_state$st_index.x
choice_state[is.na(choice_state$st_index.x),]$st_index <- choice_state[is.na(choice_state$st_index.x),]$st_index.y
choice_state <- choice_state %>%
  dplyr::select(`c(1:80)`, st_index)
prob_weight <- merge(x=prob_weight,
                     y=choice_state,
                     by.x = "index2",
                     by.y= "c(1:80)")
prob_weight <- prob_weight %>%
  dplyr::select(index, st_index, prob)

prob_weight <- prob_weight %>%
  group_by(index) %>%
  spread(st_index, prob)


# Counterpart choice|states -----------------------------------------------
counterpart <- merge(x = choice_state, y = state_lookup[,-c(1)], by.x = "c(1:80)", by.y = "index", all.x = TRUE)
counterpart <- merge(x = counterpart, y = state_lookup[,-c(1)], by.x = "c(1:80)", by.y = "index2", all.x = TRUE)
counterpart$index_ALL <- counterpart$index
counterpart[is.na(counterpart$index),]$index_ALL <- counterpart[is.na(counterpart$index),]$index2
counterpart <- counterpart %>%
  dplyr::select(index_ALL)

model_data <- list( N = length(unique(data$participant)), #number of part
                    T = max(data$COUNTER), # number of max rounds
                    nOpt = 2,
                    Tsubj = Tsubj$n, # number of round
                    choice = choice[,c(-1)],
                    opt_st = opt_st[,c(-1)],
                    value_lookup = ch_opt_translation$value,
                    state_lookup = state_lookup[,c(-1)],
                    prob_weight = prob_weight[,c(-1)],
                    counterpart = counterpart$index_ALL) # transition probabilities

```

### Estimation

```{r cost-model-estimation, eval=FALSE, include=TRUE}

load("prolific1StanData.Rdata")
# my_model <- stan_model(file = "recipes/hier-bayes-simple.stan", verbose = TRUE)
Prolific1_Stan_results <- sampling(object = my_model, data = model_data,
                                   iter = 1000,
                                   chains = 1,
                                   cores = 3)

```

## Factor Analysis for Experiment 1

@fig-mice offers a visual representation of the imputation process. The intermingling of different imputation streams indicates a successful multiple imputation process, suggesting that the chains have converged. Additionally, we expect no visible trends in the later iterations, indicating that the imputations have reached a stable solution.

``` {r}
#|label: fig-mice
#|fig-cap: "Visual representation of the MICE imputation process. The left plot shows the mean of the imputed values across iterations, while the right plot displays the corresponding standard deviations. The intermingling of different imputation streams suggests successful convergence of the chains."
#| layout-ncol: 3

plot(imputed_data)

```

Next, we conducted Factor Analysis on the complete datasets generated by the MICE procedure. The output below shows the factor loadings, which represent the correlations between the observed variables and the factors. High absolute values indicate a strong relationship with the factor. Next, we will examine the factor loadings in a more interpretable format by creating a loading plot. @fig-exp1-loadings displays the loadings of each variable on each factor, facilitating the interpretation of the factors. Variables with high loadings on the same factor are likely to be related to each other and represent the same underlying construct.

``` {r}
#|label: fig-exp1-loadings
#|fig-cap: "Heatmap of factor loadings for Experiment 1. Each row corresponds to a variable, and each column corresponds to a factor. The color of each cell indicates the loading of the variable on the factor, with red indicating high positive loadings, and white indicating negative loadings."

# Extract the loadings
loadings <- as.matrix(poverty3$loadings)
# Create the heatmap
heatmap(loadings)

```

## Correlations in Experiment 1 Variables

```{r}

cor(df[c("PA1", "PA2", "PA3", "zip_income", "zip_poverty_log",
         "SAI_pre", "SAI_post", "TAI_post",
         "Total_approvals", "Age")],
    method = "spearman", use = "pairwise.complete.obs")

```

# Appendix: Images

## The Eisenhower Matrix {#app-eisenhower}

"Who can define for us with accuracy the difference between the long and short term! Especially whenever our affairs seem to be in crisis, we are almost compelled to give our first attention to the urgent present rather than to the important future."

\-\-- Dwight D. Eisenhower, 1961 address to the Century Association

![Source: https://todoist.com/productivity-methods/eisenhower-matrix](images/eisenhower-matrix.png){width="5.36in"}

## Pilot Experiment Image

![Game interface for Pilot Experiment. Participants had a queue with two tasks on top of the screen and a series of icons they must press in order to complete a task. The clocks (hearts, in this version) and dollar signs on a task represent the urgency and importance of the task, respectively. The right side of the screen displays a rounds counter (top) and a points counter (bottom).](images/totalice.jpeg){#img-pilot-exp}

## Priority Queuing

A list can contain an arbitrary number of tasks and the priority of each task is an integer drawn from some distribution. The tasks are set to arrive with the rate $\lambda$ following a Poisson dynamics with exponential arrival time distribution and they are executed with rate $\mu$ by always choosing the one with the highest priority.

![Sample Queue](images/prioq-illustration.png){width="3.2in"}

# Appendix: Documentation

## Questionnaires

## IRB