---
title: "Poverty and Priority Queueing"
author: "Marcos Gallo and Kavya Rajagopalan"
date: "2023-07-10"
abstract: |
  Pre-existing literature suggests that relative material scarcity – particularly wealth inequality – is a significant contributing factor in dictating how people behave. We characterize irrational decision-making across impoverished groups by examining the effects of inefficiency in time and effort allocation. We experimentally model time allocation in low SES groups by administering an artificial priority queue where agents must attend to tasks with differing levels of effort, urgency and value. Observations suggest that individuals from low SES groups prioritize urgent tasks while agents from high SES groups prioritize high value tasks.
execute:
  echo: false
  warning: false
format: 
  pdf: 
    documentclass: report
    toc: true
    number-sections: true
    colorlinks: true
    code-line-numbers: true
    keep-tex: true
    include-in-header:
      - text: |
          \usepackage{dcolumn}
---

```{r init, warning=FALSE, include=FALSE}
library(viridis)
library(latticeExtra)
library(factoextra)
library(weights)
library(stargazer)
library(texreg)
library(gt)
library(rstan)
library(rhdf5)
library(stringi)
library(psych)
library(pglm)
library(tidymodels)
library(tidyverse)
library(reticulate)

# © 1998-2023 RANDOM.ORG
# 
# 496181801	
# Timestamp: 2023-08-02 17:58:21 UTC
set.seed(496181801)
random_py <- import("random")
random_py$seed(496181801)

# Helper Functions:
get_p_text <- function(p_value) {
  if (p_value < 0.001) {
    return("p < .001")
  } else {
    return(paste("p =", rd(p_value, 3)))
  }
}
get_regression_result <- function(model, coefficient_name) {
  estimate <- round(model$coefficients[coefficient_name], 3)
  p_value <- summary(model)$coefficients[coefficient_name, 4]
  p_text <- get_p_text(p_value)
  result <- paste("Estimate =", estimate, ",", p_text)
  return(result)
}

```

# Introduction

Poverty is a multifaceted issue that behavioral scientists have extensively studied. Their research has examined how individuals' decision-making processes are influenced by their surroundings, irrespective of their socioeconomic standing (Bertrand et al., 2004). These scientists maintain that all humans share a shared biology and psychology and that poverty can significantly impact both factors. Essentially, poverty can precipitate changes in an individual's environment, subsequently affecting their choices. For example, living in poverty often means having a limited set of options in life (from choosing what to have for dinner to which occupation to pursue), and it increases the number of demands in terms of time and mental resources (Banerjee & Duflo, 2012). This lack of control over choices leads to a chronic state of vigilance and stress (Chemin et al., 2013).

In this paper, we focus on the trade-offs between urgency and importance in day-to-day decisions. It is hypothesized that, in the mass of to-dos and responsibilities, those with limited resources have to leave specific tasks undone. Consequently, we argue that they may not have time to complete all tasks or the necessary money and, as a result, must decide what to prioritize in their lives. Although one could theoretically calculate the most optimal course of action, it is improbable that individuals would take this actuarial approach. Instead, we argue that they are more likely to use heuristics or intuition to decide what problem to address, where to spend money, and what to leave undone. Such heuristics, however, are prone to fail under particular circumstances.

We argue that, under the strain faced by the poor, a series of behaviors and physiological phenomena arise. Making "urgent versus important" trade-offs causes stress and anxiety levels to increase and shift attention towards specific features of a choice. We propose that an environment of poverty shifts the weight placed on the urgency of a task (e.g., estimating that urgent tasks will "come back to bite" much faster than others and estimating that nonurgent opportunities are unlikely to disappear or change). This urgency mindset may increase stress and anxiety levels, leading the poor to spend significant portions of their income on tobacco, alcohol, and lotteries (Banerjee & Duflo, 2007; Blalock et al., 2007; Haisley et al., 2008; World Health Organization, 2021). Individuals in low socio-economic groups tend to save too little (Shurtleff, 2009) frequently borrow at exorbitant interest rates (Banerjee & Duflo, 2007; Skiba & Tobacman, 2008), and limit preventive healthcare services (Lusardi et al., 2010).

## Poverty Traps

We argue that impoverished individuals are trapped in a cycle of urgency, neglecting non-urgent tasks, ultimately leading to increased urgency in the future. For example, not undergoing regular medical check-ups may increase susceptibility to unexpected illnesses. Our current discussion pertains to the theory of poverty traps and their implications on economies. This theory states that an economy can become entrenched in a self-perpetuating cycle of underdevelopment, resulting in a state of equilibrium where adverse outcomes prevail over repeated attempts at progress. Understanding the concept of poverty traps is crucial in comprehending the challenges developing economies face and devising effective strategies to overcome them.

Here, we analyze situations where low socioeconomic status (SES) individuals make suboptimal choices compared to high SES individuals to investigate the potential causal link between poverty trap outcomes and the behavior of low SES agents. Specifically, we compare the time allocation choices of low SES agents to understand the self-reinforcing nature of poverty traps better.

### Priority Queues, Urgency and Importance

Some scientists have proposed a "Scarcity" view of poverty (Mullainathan & Shafir, 2014), but their conclusions have not withstood the scrutiny of science, leaving the causes and mechanisms of these phenomena largely unexplained (O'Donnell et al., 2021). We seek a more rigorous understanding of how relative-poverty can be self-perpetuating through poor time allocation. We explain prioritization of day-to-day tasks as an attempt to balance two requirements: (1) maximize life satisfaction given one's limited resources, and (2) minimize the potentially harmful effects of leaving tasks undone change with time. We call the former requirement "importance" and the latter "urgency" (Bratterud et al., 2020).

<!-- Forest plot here  -->

The Eisenhower Matrix (see @sec-eisenhower for details), a simple tool for determining optimal long-term decisions, is a simplification of how individuals determine their queue for attending to daily tasks. This framework uses dimensions of urgency (time scarcity) and importance (expected value maximization) as primary motivations for which tasks require completion. We intend to characterize the mapping between urgency $U$ and importance $I$ , namely $\{ U,I \} \mapsto \mathbb{R}$. As discussed in @sec-poverty, the literature speculates the influence of effort costs in decision-making - thereby suggesting Eisenhower Matrices should be modified to account for the added parameter.

# Theory

In this section, we present a novel decision-making model that underpins various real-life activities, from mundane daily choices to high-stakes strategic decisions. When individuals face multiple action options, they select the one that maximizes perceived value or utility. Our model integrates urgency, importance, and value, drawing on principles from decision theory, the Eisenhower matrix, and Markov Decision Processes (MDPs) (Puterman, 1994; Eisenhower, 1961).

## Conceptual Framework

In our model, urgency refers to the time-sensitivity of a decision or the period until a choice is no longer viable. This concept captures the temporal aspect of decision-making, reflecting that opportunities for action often have a limited lifespan. For example, deciding to invest in a rapidly changing market or respond to a time-limited offer requires considering urgency. Importance is the value of a decision state, contingent on future states and transition probabilities. This concept captures the strategic aspect of decision-making, reflecting the reality that the consequences of a decision often depend on future events and conditions. For example, investing in education or training may be important because it affects future career opportunities and earning potential (Howard, 1960). Value is the present-discounted reward from choosing an action, incorporating the opportunity cost of a choice, which is the value of the best choice one must forego. This concept captures the economic aspect of decision-making, reflecting that resources such as time, money, and effort are limited and that choosing one action can often mean giving up the opportunity to choose another (Bellman, 1957). The optimal policy balances immediate rewards with future rewards, considering urgency, importance, and likelihood. It depends only on current, not past, states (Bellman, 1957).

### Model Components

The model comprises several components inspired by the structure of MDPs, a mathematical framework for modeling decision-making in situations where outcomes are partly random and partly under the control of a decision-maker (Howard, 1960).

**State Space**: The current situation or context. Each state is associated with a set of possible actions. The state space captures the situational aspect of decision-making, reflecting that the available choices often depend on the current circumstances. For example, deciding to invest in a particular market depends on the current market conditions (Sutton & Barto, 2018).

**Action Space**: The available actions in a given state. Each action leads to a transition to a new state. The action space captures the behavioral aspect of decision-making, reflecting the reality that different actions can lead to different outcomes. For example, the decision to invest in a risky asset can lead to a high return or a significant loss (Daw et al., 2005).

**Transition Probabilities**: The likelihood of transitioning from one state to another, given a particular action. Transition probabilities capture the inherent uncertainty and randomness in real-world decision-making scenarios. For example, the decision to invest in a risky asset involves uncertainty about the future state of the market (Daw et al., 2005).

**Rewards**: The outcomes or results of a particular action from a given state. Rewards can be 1) immediate or delayed, and 2) positive (benefits) or negative (costs). The concept of rewards captures the motivational aspect of decision-making, reflecting that the desire to achieve positive outcomes and avoid negative ones can often drive decisions (Sutton & Barto, 2018).

**Discount Factor**: Reduces the value of future rewards to reflect that individuals value immediate rewards more highly than future ones. The discount factor encapsulates the decision maker's time preference or discount rate. For example, investing in a long-term project involves discounting the future benefits to reflect their present value (Bellman, 1957).

**Policy**: This strategy defines which action to take in each state. The policy can be deterministic (always choosing the same action in a given state) or stochastic (choosing among several actions with specific probabilities). The concept of policy captures the strategic aspect of decision-making, reflecting that decisions often involve a sequence of actions over time (Puterman, 1994).

### Comparison to the Two-Step Task

The two-step task is a well-established paradigm in cognitive neuroscience used to assess two types of reinforcement learning: model-free and model-based learning. Model-free learning depends on the direct association between actions and their outcomes. In contrast, model-based learning involves planning and decision-making through a mental model of the task structure (Daw et al., 2005). The proposed decision-making model can be related to the two-step task, providing a richer understanding of the dynamics involved in these types of learning. In the two-step task, participants make two sequential decisions that navigate them through two "stages" defined by different stimuli. The first-stage choices lead to one of two second stages with varying probabilities, and each second-stage choice is associated with some probability of receiving a reward. The goal of the subject is to maximize rewards in the second stage, which requires continuous learning and adaptation to the changing reward probabilities.

For example, consider the first stage with an initial state that includes two choices: "buying a phone" or "taking a course." The transition probabilities are defined by the likelihood of moving to the second stage, given the first-stage choice. For instance, choosing "taking a course" could lead more often to a state where one gets a promotion (State 2a), while "buying a phone" could lead more often to a state where one does not get promoted and keeps the same job (State 2b). In the second stage, the state spaces include another choice, such as "buying a car." In State 2a (getting a promotion), the decision maker could choose "buying a phone" or "buying a car," where the car would be brand new and fancy, reflecting the increased financial resources in this state. In State 2b (keeping the same job), the decision maker could choose "taking a course" or "buying a car," where the car would be cheap and used, reflecting the lower financial resources in this state. In this context, both stages have rewards associated with the actions that are not a result of the transition to future states. Specifically, buying a phone would lead to immediate subjective value (e.g., the thrill of having a new gadget), and so would education (e.g., the fulfillment of getting a diploma or gaining knowledge). The value of each action, however, is the sum of its associated reward and the value of all future states weighted by their respective transition probabilities. The policy in this context would be the strategy that defines which action to take in each state. For instance, the decision maker might adopt a policy of always choosing the action with the highest immediate reward or adopt a more complex strategy that considers each action's urgency, importance, and value. Key in this decision is also the discount factor, which reflects the decision maker's time preference or discount rate. For instance, the decision maker might value the immediate pleasure of buying a phone more highly than the potential future benefit of a promotion (Daw et al., 2005).

```{mermaid}
flowchart TD
   subgraph "State s"
   A1[Buy Phone]
   A2[Take Course]
   end
   subgraph C[State s'2: Get Promotion]
   E[Buy Phone and Used Car \n or\n Take Course]
   end
   subgraph B[State s'1: Keep Job]
   D[Buy Phone \n or\n Buy Used Car]
   end
   A1 -->|70%| B
   A1 -.->|30%| C
   A2 -.->|30%| B
   A2 -->|70%| C
```

### Priority Queuing

In our two-step task example, we observed how the unchosen task was "transferred" to the next state. This characteristic is a crucial feature of a priority queueing model, which we will delve into to enrich our understanding of decision-making dynamics further.

Priority queueing models often represent ordinal choices of tasks attended to based on some subjective value or utility function. These models are prevalent in various real-world scenarios, such as triaging bays, which treat queues as a function of urgency and order of arrival, and donor matching programs, which facilitate queues based on a point system that weights time, severity, and likelihood of survival (CITE).

Cobham and Barabasi have developed two critical priority queueing models. Cobham's model treats a queue as an infinite list of tasks with varying task arrival times and execution rates. On the other hand, the Barabasi model treats the queue as a finite size list with waiting times ($\tau_w$). The mathematical expression for the waiting time distribution in the Barabasi model is as follows:

$$
P(\tau_w) = \left\{
            \begin{array}{ll}
            1 - \frac{1-p^2}{4p}\ln\frac{1+p}{1-p},\\
            \frac{1-p^2}{4p(\tau_w - 1)}[(\frac{1+p}{2})^{\tau_w-1} - (\frac{1-p}{2})^{\tau_w - 1}],
            \end{array}
            \right.
$$

Interestingly, as \$p \\rightarrow 0\$, this distribution reduces to an inverse Poisson distribution. This expression is independent of the priority distribution, suggesting that the alignment of task priorities has no role in the time for these respective tasks to be executed.

Despite their powerful predictions, these existing models for priority queues have limitations in their applications. The literature is scarce about priority queuing in marginalized groups and how priority queuing is rationalizable. Some literature describes priority queues as a double-sided matching market with queues that depend on priorities and impatient customers (Castro et al., 2020). In this literature, customers of high value are matched prior to those of low value. Likewise, impatient customers can leave the queue if they are not matched immediately with a customer of their priority. This behavior is representative of many real-life cases but does not align with the behavior that the extended literature from Role Strain suggests about the decision-making choices of individuals from low SES. There is an apparent disconnect between how the average individual prioritizes tasks and how individuals from low SES do.

In our model, we aim to bridge this gap by integrating the principles of priority queueing into the decision-making process. By considering each task's urgency, importance, and value, we can create a more nuanced and realistic representation of how individuals allocate their time and resources. This approach allows us to capture the complexities of decision-making in a way that traditional models cannot, providing a more comprehensive understanding of the dynamics involved in model-free and model-based learning.

In the next sections, we will explore how this integration of priority queueing into our model can provide new insights into the decision-making process, particularly in the context of individuals from low SES.

## Simulation

Priority queue models offer a tangible mechanism for capturing the choices and inter-event times that agents require when making decisions about daily tasks. Drawing on the existing literature surrounding poverty, we simulate an artificial priority queue using a priority function:

$$
\text{Priority} = \alpha U + (1- \alpha) I
$$ {#eq-prio}

where $U, I, \alpha$ represent "urgency," "importance," and the urgency weight, respectively.

Our first step is to run a discrete-event simulation (DES) to uncover the relationship between $\alpha$, the probability of survival, and burstiness measures. DES is a technique for modeling stochastic, dynamic, and discretely evolving systems, making it a powerful tool for understanding complex decision-making processes (Banks, J., Carson, J. S., Nelson, B. L., & Nicol, D. M. (2005). Discrete-Event System Simulation. Prentice Hall.). In this framework, we consider:

1.  An individual who is capable of completing any job,
2.  A ready supply of jobs with no prospect of any shortages,
3.  Jobs are allocated a priority when they arrive in the queue according to @eq-prio,
4.  The time taken to complete a job is variable but independent of the task.

We define the completion time for the different activities as random draws from an exponential distribution with $\lambda = 5$. Similarly, the interarrival times for tasks are from an exponential distribution of $\lambda = 5$. Each incoming task receives $U, I \sim \text{Unif}(0,1)$ and a priority according to @eq-prio. Tasks are completed in the order of priority.

Importantly, each task contains a survival rate as a function of its importance. The higher the urgency, the more likely the task will fail (or die off). This feature internalizes the fact that urgent tasks may bring imminent negative consequences. A Weibull distribution with a monomial function gives the survival probability of a task:

$$
\Pr (\text{survival}|\alpha = s(1+U),\beta=1) = 1 - e^{(-t/\alpha)^\beta}
$$

where $t$ is the wait time, and $s$ is a scaling parameter (in the following simulations, calibrated to 100). As such, each task contains a survival probability, which is then accumulated throughout the task, such that the cumulative survival rate of later tasks are smaller than those of earlier ones.

By simulating this queue, we can graph a heatmap with the relationship of the weight of urgency on the priority function (\$\\alpha\$) and cumulative survival rate:

```{r}
#| cache: true
#| label: fig-simmer-simulation
#| fig-cap: "Probability of Survival by Urgency Weight"

urgency_survival_grid <- read_csv("Models/DES/urgency-survival-grid.csv") %>%
  rename(time = mean_time) %>%
  filter(!is.na(mean_survival)) %>%
  filter(time < 20) # Anything greater is close to 0

levelplot(mean_survival ~ time * weight, urgency_survival_grid, 
          panel = panel.levelplot.points, cex = 0
    ) + 
    latticeExtra::layer(panel.2dsmoother(..., n = 200))

```

@fig-simmer-simulation shows that those with higher urgency weights are more likely to survive longer in the queue. This finding suggests that the weight of urgency in the priority function plays a significant role in determining the survival probability of tasks in the queue. This finding underscores the importance of considering both urgency and importance when prioritizing tasks, particularly in contexts where survival rates are critical, such as in decision-making scenarios faced by individuals living in poverty.

## Integrating Our Model with Poverty {#sec-poverty}

Integrating our model with poverty is crucial in understanding its complex dynamics and effects on various aspects of life. Poverty is not just a state of financial deprivation but a multifaceted issue that affects health, education, and overall quality of life (Barrett et al., 2016). Our model aims to capture the combined effect of these complexities.

We integrate poverty by considering it a multidimensional variable that influences and is influenced by various factors: 1) Poverty can affect health outcomes by limiting access to healthcare services and nutritious food. In turn, poor health can exacerbate poverty by reducing a person's ability to work and earn income; 2) Social factors can be determinants of poverty. These include education, employment, and social support, which can significantly influence a person's likelihood of falling into poverty; 3) Poverty is not a fixed state but a condition that changes with time and circumstances. People can move in and out of poverty over time. Though past research has explored the dynamics of these three phenomena, we offer a novel integration of these physical, mental, social, and temporal determinants into our priority queueing model.

### Temporal Discounting

Temporal discounting, as a behavioral economic concept, plays a pivotal role in our model, particularly in poverty. It refers to the well-established tendency to value immediate rewards at the expense of future outcomes (Frederick et al., 2002). This bias is often associated with lower wealth. It is more pronounced in populations with lower socioeconomic status (SES) (Ruggeri et al., 2022, The globalizability of temporal discounting. Nature Human Behaviour).

In our model, we incorporate temporal discounting as a critical factor influencing the decision-making process of individuals in poverty. The model allows for flexibility in the rate of temporal discounting, and individuals with lower SES are likely to have higher rates. In the context of poverty, temporal discounting can exacerbate financial difficulties. For instance, individuals facing financial strain may opt for immediate, smaller rewards instead of larger, delayed ones, potentially perpetuating a cycle of poverty (Haushofer & Fehr, 2014, On the psychology of poverty. Science).

To illustrate this, consider the decision-making process in our model. The decision-maker, who is in a state of poverty, is faced with two choices: "Work an extra shift" or "Attend a free community college class." The former offers an immediate reward, while the latter promises a future benefit. According to previous findings, some decision-makers in low SES are likely to choose the immediate reward due to the higher rate of temporal discounting. In many cases, the immediate need for financial resources outweighs the potential future benefits of attending a class. Our model captures this behavioral preference through a discount factor, denoted by $\gamma$.

However, this decision-making process is dynamic. It evolves as the decision-maker's circumstances change and as they gain more information about the potential future benefits of their actions. For instance, if the decision-maker learns that attending a class could significantly increase their future income, they might be more inclined to choose this option, even if it means forgoing the immediate reward of working an extra shift. This ability to foresee or predict future states is central to our model, and the following section will address it.

### Foreseeing Future States

Individuals with lower SES often face uncertainty and instability, which can cloud the decision-making process, making it difficult to foresee the long-term consequences of their actions (Mullainathan & Shafir, 2013). This uncertainty is not merely a passive process but an active one. A study by Peters and Büchel (2010) found that the ability to vividly imagine future events can reduce temporal discounting.

Individuals likely learn to imagine future events in their social environments. Notably, community trust plays a significant role in this temporal discounting. Research by Farah and Hook (2017) suggests that SES significantly predicts high temporal discounting, particularly in environments characterized by low community trust (Farah & Hook, 2017, Trust and the poverty trap. Proceedings of the National Academy of Sciences). This finding implies that trust within a community can serve as a buffer against temporal discounting, encouraging individuals to make more beneficial decisions in the long term. Perhaps one channel through which this modulation occurs is learning from one's peers' experiences and expanding their set of imagined possible states, particularly for actions with small immediate rewards.

McIvor and Paton (2007) present an interesting example of social influences in future state prediction. Specifically, they look at preparedness for natural hazards and show that people are more likely to take precautions against earthquakes if they are part of a community that encourages safety measures and if they believe that taking action will have a positive impact on their safety. This finding suggests that the relationship between individuals and their community, including their trust in community institutions, can significantly influence their ability to visualize and predict future states (McIvor and Paton, 2007, Preparing for natural hazards: normative and attitudinal influences).

### Transition Probabilities

Transition probabilities, which determine the likelihood of moving from one state to another, play a crucial role in our model. These probabilities influence individuals' choices based on their actions' potential outcomes, and correctly estimating them is essential to maximizing value.

In the context of decision-making strategies, psychologists have identified two primary approaches: model-free and model-based strategies. Model-free strategies do not rely on transition probabilities but evaluate actions based solely on their reward history (Daw et al., 2005). On the other hand, model-based strategies rely on transition probabilities, using a cognitive model of potential actions and their consequences to make goal-directed choices (Daw et al., 2005). The balance between these two strategies can be fluid and contextually sensitive, with the reliance on a given strategy depending on the cognitive and affective demands placed on the individual (Otto, Gershman, et al., 2013, The curse of planning: dissecting multiple reinforcement-learning systems by taxing the central executive; Otto, Raio, Chiang, Phelps, & Daw, 2013, Working-memory capacity protects model-based learning from stress. ).

Previous research has found that factors such as stress and education levels can affect the proportion of model-free and model-based strategies used in decision-making. Research suggests stress can also impact decision-making, leading to a greater reliance on model-free strategies (Schwabe & Wolf, 2013, tress and multiple memory systems: from 'thinking' to 'doing'). Furthermore, education levels can influence the ability to use model-based strategies, with higher education levels associated with greater use (Worthy et al., 2011, Heterogeneity of strategy use in the Iowa gambling task: A comparison of win-stay/lose-shift and reinforcement learning models).

### Urgency

Our model is beneficial for analyzing the decisions of individuals in low-SES (Socioeconomic Status) environments. Here, we build on the two-stage decision-making model by incorporating urgency. In the first stage of our model, the decision-maker, an individual encounters two choices: "Work an extra shift" or "Attend a free community college class." The choice of "Work an extra shift" predominantly leads to a state where the individual has extra money (State 2a), while "Attend a free community college class" more frequently leads to a state where the individual gains new skills (State 2b). The urgency component is crucial in this stage. The opportunity to work an extra shift is fleeting, available only on the current day. If not seized, this opportunity will expire, and the potential for additional income will be lost. Conversely, the community college class, part of a recurring weekly course, presents a less urgent choice. The individual could attend the class the following week, but missing classes could lead to a cumulative knowledge gap, jeopardizing the overall benefit of the course. In the second stage, the state space expands to include another choice. In State 2a (having extra money), the individual could choose between "Buy groceries" or "Pay utility bills." In State 2b (gaining new skills), the individual could opt to "Apply for a better job" or "Start a small business." Urgency is also a pivotal factor in the second stage. The utility bill payment is due imminently, and failure to pay will discontinue essential services. On the other hand, buying groceries, while a recurring necessity, may not have the same urgency. However, a prolonged delay in this action could lead to health and well-being implications, underscoring its medium-term urgency.

To illustrate the role of urgency in decision-making, we will use a mathematical representation of our model. We will consider a simplified version of the two-stage decision-making scenario described above, focusing on the first stage, where the decision-maker must choose between "Work an extra shift" or "Attend a free community college class."

Let us denote the state of the decision-maker by $s$ and the set of available actions by $A(s) = \{\text{``Work an extra shift"}, \text{``Attend a class"}\}$. The urgency of action $a \in A(s)$ is the time limit $T_a$, after which the action is no longer available.

The decision-maker's policy $\pi$ determines the action to take in each state. The policy is a function of the current state and time, $\pi(s, t)$, and it changes over time as the urgency of the actions changes.

The value $V(s, t)$ of a state $s$ at time $t$ is the expected future reward when following policy $\pi$, discounted over time:

$$V(s, t) = \mathbb{E}_{\pi}\left[R(s_t, a_t) + \gamma \sum_{s' \in S} P(s' | s_t, a_t) V(s', t+1)\right],$$

where $R(s_t, a_t)$ is the immediate reward from taking action $a_t$ in state $s_t$, $P(s' | s_t, a_t)$ is the transition probability from state $s_t$ to state $s'$ given action $a_t$, and $\gamma \in [0, 1]$ is the discount factor that determines the present value of future rewards.

The urgency of an action affects the value of a state by limiting the time available to take the action. As the deadline $T_a$ approaches, the decision-maker's available time budget decreases, constraining the set of feasible actions.

Now, consider the case where "Work an extra shift" is an "immediate-reward task" with a high reward of $R_{\text{work}} = 100$ and a short deadline of $T_{\text{work}} = 1$ day. If the decision-maker does not work the extra shift within one day, they will miss the opportunity to earn additional income. However, this action does not significantly change the future state values, as working an extra shift does not lead to a permanent increase in income.

On the other hand, "Attend a class" is a "future-reward task" with a lower immediate reward of $R_{\text{class}} = 10$ and a longer deadline of $T_{\text{class}} = 7$ days. If the decision-maker does not attend the class within a week, they will miss the opportunity to gain new skills, which could lead to better job opportunities and higher future state values.

The optimal policy $\pi^*$ balances the immediate rewards with the future rewards, considering the actions' urgency and potential future benefits. It is given by:

$$\pi^*(s, t) = \arg\max_{a \in A(s)} Q(s, a, t),$$

where $Q(s, a, t)$ is the action-value function that represents the expected future reward from taking action $a$ in state $s$ at time $t$:

$$Q(s, a, t) = R(s, a) + \gamma \sum_{s'} P(s' | s, a) V(s', t+1),$$

where $P(s' | s, a)$ is the transition probability from state $s$ to state $s'$ given action $a$.

In this case, if the decision-maker follows the optimal policy, they will choose "Work an extra shift" on the first day due to its high immediate reward and urgency and then "Attend a class" on the subsequent days to maximize the potential future benefits. This example illustrates how the urgency of tasks and the distinction between immediate and future rewards can influence the optimal decision-making policy. By incorporating urgency into the decision-making model, we can capture the temporal dynamics of real-life decisions and provide a more accurate representation of the decision-making process.

### Suboptimal Time Allocation

Inefficient time allocation of daily tasks is another factor that can contribute to the persistence of poverty. Individuals make a sequence of decisions and bargains to reduce the strain of their daily demands and roles in a process similar to an economic decision: Allocating limited resources such as energy, time, emotions, and goods in different ways (Goode, 1960). For individuals from a higher SES, delegating these roles becomes far more manageable, and the bandwidth to tackle other tasks increases significantly. The converse is true, however: the poorer one is, the more uncontrolled demand for time and money.

A recent study by Jachimowicz et al. (2022) provides a compelling illustration of this phenomenon. The authors found that financial scarcity is associated with greater distress intensity in everyday life. They propose that financial resources allow individuals to reduce the distressing impact of everyday hassles, increasing one's life satisfaction. This research suggests that financial scarcity shrinks the sense that one can use economic resources to reduce the adverse impact of daily hassles. While money may not necessarily buy happiness, it reduces the intensity of stressors experienced in daily life---and thereby increases life satisfaction.

<!-- Add scatter plot from Jachimowicz -->

In the context of our model, suboptimal time allocation can exacerbate the effects of poverty, leading to a cycle of immediate-reward task selection and persistent financial scarcity. The immediate reward of completing a task and reducing the day's demands can outweigh the potential future benefits of tasks that require more time and effort. This feature is particularly true for individuals facing financial scarcity who may not have the luxury of investing time in tasks with delayed rewards.

The ability to delegate tasks significantly alleviates this burden. Delegation allows individuals to offload tasks to others, freeing up their time and mental resources. This advantage is especially beneficial for urgent tasks, which can consume a disproportionate amount of time and attention. However, the ability to delegate is often a privilege reserved for those with sufficient financial resources. For individuals facing financial scarcity, the cost of delegation may be prohibitive.

By incorporating these dynamics into our model, we can better understand the decision-making processes of individuals in different socioeconomic circumstances.

### Role Strain

Introduced by sociologist William Goode in 1960, the concept of role strain motivates our theoretical framework. Goode proposed that individuals, faced with an impossibility of satisfying all role demands, engage in role decisions and bargains to modulate these demands. This process necessitates allocating limited resources such as time, emotions, and goods across various role obligations. The ultimate goal is to minimize perceived role strain, defined as the cognitive and emotional exertion involved in fulfilling duties (Goode, 1960).

Role strain is particularly salient among individuals experiencing poverty, who often grapple with an elevated effort dimension or the subjective value ascribed to task completion. Morris and Coley's 2004 study on role strain correlates among mothers revealed many factors that amplify "strain" in this demographic, many of which are income-related (Morris & Coley, 2004). A separate study on family caregivers of adult cancer patients in Kenya further exemplifies this phenomenon. The researchers discovered that these caregivers, typically under financial strain, experienced significant role strain due to the simultaneous management of multiple responsibilities (Mugenda et al., 2020). These findings underscore the disproportionate burden of role strain borne by those in poverty, who must navigate a labyrinth of tasks and roles with scarce resources.

Adding tasks to already demanding circumstances intensifies role strain, while providing social support to assist with tasks can mitigate it (Lewis, 1989 <https://www.jstor.org/stable/2784697).> A proposed cause of poverty traps is the tendency of impoverished individuals to overcommit to high-urgency tasks, thereby neglecting or under-committing to high-effort or high-importance tasks.

Goode's theory differentiates between role conflict, where two roles present mutually exclusive demands, and role overload, where an individual lacks the resources to meet the demands of multiple roles. The latter is particularly pertinent to our research objectives. Role overload arises when an individual is tasked with fulfilling multiple roles concurrently and struggles to meet these roles' demands. For instance, a full-time student may concurrently struggle to care for young children (Nickerson, C. (2023) <https://www.simplypsychology.org/what-is-role-strain-in-sociology.html).>

Our model seeks to elucidate how task overload influences decision-making processes and outcomes, contributing to our understanding of poverty dynamics.

### Scarcity

The intricate interplay between poverty and cognitive function is critical to socioeconomic studies. Individuals from lower socioeconomic strata often grapple with a dearth of resources, significantly influencing their behavioral patterns and cognitive abilities. This observation has sparked investigations into the so-called "scarcity mindset," a psychological state hypothesized to precipitate three primary cognitive effects: attentional drift, pronounced trade-off thinking, and diminished mental bandwidth (de Bruijn & Antonides, 2022). These cognitive shifts, in turn, can elucidate common behavioral characteristics observed among those of low socioeconomic standing, including overborrowing, more consistent consumption decisions, and increased time discounting and risk aversion (de Bruijn & Antonides, 2022).

For instance, experiments designed to induce a scarcity mindset by deliberately limiting resources revealed that participants demonstrated heightened focus on tasks due to the limited opportunities for success (Shah et al., 2012; Shah et al., 2019). While this increased focus improved efficiency and accuracy in task completion, it also increased borrowing and elevated stress levels, making tasks increasingly taxing and requiring more attention. However, other studies suggest that further evidence is required to substantiate these conclusions (de Bruijn & Antonides, 2022).

Moreover, the assertion that poverty reduces mental bandwidth and increases time discounting and risk aversion requires further empirical support (O'Donnell et al., 2021). Current studies only partially align with empirical data and need more precision for a comprehensive understanding (de Bruijn & Antonides, 2022). Notably, a replication study by Shah et al. (2019) examined how different forms of scarcity affect attention and borrowing behavior, finding no evidence that scarcity on one task leads to cognitive fatigue on subsequent tasks, thereby contradicting the results from Shah et al. (2012).

In a more recent study, Madsen et al. (2022) conducted a field experiment using Danish unemployed social assistance recipients to test the psychological consequences of scarcity. The researchers randomly assigned survey recipients to three groups: (a) those surveyed before receiving social assistance benefits, (b) those surveyed after receiving them, and (c) those surveyed in the middle of the month. Interestingly, they found no impact of the scarcity manipulation (those surveyed before payment) on the mindsets of social welfare recipients. However, they did find that subjective scarcity, or "the feeling of having too little," correlated positively with an increased focus on problem-solving but negatively with psychological well-being, mastery, and job search self-efficacy.

The relationship between poverty and cognitive function is complex and multifaceted. While scarcity can lead to heightened focus and efficiency in task completion, it also induces a scarcity mindset that can lead to suboptimal decisions and behaviors. Our theory builds on this literature and suggests that people must balance their current and future expenses when they have limited budgets and uncertain incomes. This strain can be challenging and requires attention, executive control, and working memory, leaving fewer cognitive resources for other less urgent tasks. As such, we seek to understand the mechanisms underlying these effects and how they may perpetuate poverty.

## Affective States

The present study proposes that the behavioral deviations observed in individuals living in poverty, specifically the overweighting of urgency, are mediated by affective states such as stress and anxiety. This proposition is rooted in the understanding that stress and anxiety can significantly influence decision-making processes. For instance, a meta-analysis by Starcke and Brand (2016) found that stress generally increases risk-taking.

Indeed, individuals of low socioeconomic status (SES) often report feeling overwhelmed, which can exacerbate stress and anxiety. A study by Williams (2018) on populations of color, who often experience low SES, found that race-related stressors can significantly affect mental health, leading to higher levels of psychological distress. Similarly, a study by Heers and Lipps (2022) found that almost one fifth of parents reported feeling overwhelmed by homeschooling obligations during the Covid-19 pandemic, with women, mid-aged and lower-educated individuals, as well as those with young children and a lower income, being particularly affected. This feeling of being overwhelmed did not cause changes in life satisfaction, stress, and negative affect, but it did lead to a decrease in positive affect.

The intricate relationship between poverty and mental health has been the subject of extensive research, with numerous studies suggesting a bidirectional link between the two. Poverty can exacerbate mental health issues due to the stress and strain of living in financial hardship. In contrast, mental health issues can lead to poverty due to reduced productivity and employment opportunities (Lund et al., 2010). Ridley et al. (2020) further corroborated this relationship, highlighting the detrimental impact of mental illness on economic outcomes.

As mentioned, the stress and tension arising from role strain are central to our hypothesis. Morris and Coley (2004) identified several factors that increase role strain among mothers, including low income, lack of social support, low education, lack of health insurance, and reliance on government welfare.

Similarly, Stack and Meredith (2018) found that single parents are at high risk of financial hardship, leading to poor mental health and low psychological well-being. Single parents often experience higher levels of chronic stress, loneliness, and depression, despite making extensive efforts to meet their financial obligations.

Thus, our proposed model suggests two channels through which role strain may increase the urgency bias. The first channel posits that the subjective experience of strain, which can be exacerbated by factors such as low income, lack of social support, and reliance on government welfare, can lead to an urgency bias in decision-making. The second channel suggests that the stress and anxiety resulting from role strain can also lead to an urgency bias.

```{mermaid}
%%| fig-width: 5
flowchart LR
  A[Income] --> B{Role Strain}
  C[Social Support] --> B
  D[Education] --> B
  E[Health Insurance] --> B
  F[Gov't Welfare] --> B
  B --> G(Subjective Ratings of Strain)
  B --> H(Stress and Anxiety)
  G --> I(Urgency Bias)
  H --> I
```

<!-- # Literature Review -->

## Research Questions

1.  How do urgency and importance influence task selection, and which cognitive processes predominantly drive these effects?

2.  How does Socioeconomic Status (SES) affect task prioritization, and how does role strain mediate this relationship?

3.  Which primary affective mechanisms lead to inefficient time allocation, and how do these mechanisms interplay with cognitive and external factors?

# Pilot Experiment

## Methodology

Our experimental design simulates the environment of an ice cream parlor using an interactive online game. The game was developed in PsychoPy version 2023.1.3 and hosted on the Pavlovia platform. Participants played the role of ice cream parlor owners whose goal was to maximize profit by completing tasks with varying characteristics.

### Structure

In the game interface, participants saw a queue of tasks representing ice cream orders on the sides of the screen. Each task varied according to three characteristics: effort, importance, and urgency. These characteristics corresponded to icons on each task image to aid the participants' decision-making process, as depicted in @fig-choice.

![Example of two tasks with differing levels of Importance (Value), Effort, and Urgency.](images/tasks_example.png){#fig-choice}

1\. Effort: We operationalized effort through the number of clicks required to complete an order. More complex orders required more elements on the ice cream, some of which were relatively difficult to discern (e.g., the different types of sprinkles). We deem tasks with more elements, or hard-to-discern elements, more effortful.

2\. Importance (value): We equate importance with subjective value, represented by dollar signs on the image. A single dollar sign indicated low importance (yielding one point), while two dollar signs indicated high importance (yielding two points). The points were the participants' earnings, and each point was worth \$0.05. The total earnings, a proxy for the participant's performance, were displayed at the top of the screen.

3\. Urgency: We used clock icons on each image to convey the degree of urgency of a task. Two clock icons denoted a high-urgency order, while one clock icon represented a low-urgency order. High-urgency tasks lost value (dollar signs) if participants did not complete them in a given round (e.g., an urgent task worth 2 points would become an urgent task worth 1 point in the next round, and an urgent task worth 1 point would lose all of its value). If a high-urgency task lost all its value, it would disappear from the queue, and the participant was "punished" by having only one order in the queue for the following two rounds. Conversely, low-urgency tasks stayed in the queue until selected and completed.

In each round, participants saw the screen shown in @fig-pilot-exp. They were instructed to select a task from the queue (left or right) and click on the matching ice cream icons in the center of the screen to complete it. If they made a mistake, they could use the trash can icon to discard the current order and start over. The game continued for a total of 20 orders. Participants were not restricted to a specific order of task completion; they could choose any task from the queue at any time. This open-choice design allowed us to observe and analyze the decision-making and prioritization strategies employed by the participants. Note that we incentivized players in the game by offering a prize of up to $\$1.00$, contingent on the total number of points players accumulated throughout the game.

<!-- Add Fiver image of the experiment progress -->

### Simulation

We devised a theoretical model for how we expect rational decision-making to manifest in our priority queuing experiment such that frequency of deviations from rationality can be monitored. To formalize the optimal, or rational, set of behavior for maximizing rewards over long-term exposure in a queue, we developed a closed-form model. We hypothesize that this decision-making process reduces to a simple subjective-value function, where every individual determines the priority or preference $\succeq_q$ by the subjective value utility representation. We thus developed a stochastic model, as follows:

$$
\begin{aligned} 
V(s) &= \max\limits_{a}(r(s,a) + \gamma\sum\limits_{S}P(s,a, s')V(s'))\\
    S &= \{HHU \times HHU, HHU \times HH0, LHU \times LHU, …\}\\
    r(a,s) &= i_a - c_a\\
    R &= {r(HHU, HHV \times HHU) = 1 - c_H, …}\\
    V(s_{final}) &= \max\limits_{a}(r(s_{final}, a))
\end{aligned}
$$ {#eq-model}

In @eq-model the agent calculates the value of state $s' \in S$ (which is the next state, i.e., next period). $i$ is the reward (in dollars) for completing a task, $c_i$ is the effort cost (estimated in dollar unites), and $r(a,s)$ is the net payoff of completing action $a$ at state $s$. $P$ is the probability of transitioning from state $s$ to another state $(s')$, given that our agents takes action $a$ in state $s$. $V(s')$ is the value of that new state. We subsequently sum these results over all the possible future states. Note we use $\gamma$ as our discount factor. In our normative model, we set the discounting factor to be 1, given the tasks are very close to each other in time. Note that this model only has two cost parameters $c=\{c_L, c_H\}$.

We build upon this by then generating an optimal protocol for identifying the best set of choices at any stage for maximizing long-term outcomes. Using dynamic programming, a recursive method of taking the outcomes of subgames and applying it to the entire scheme, we identify which tasks should be chosen at any given stage of the 2-task queue. Given this framework, we can graph the ratio of urgent choices at each given state, as a function of the cost parameter $c_H$ and the discount factor (here $c_L = 0$ for all cases).

```{r}
#| label: fig-dynaprog-simulation
#| fig-cap: "Percentage of Urgent Choices"

urgency_ratio_grid <- read_csv("Models/pilot/pilot-simulation-grid.csv")
urgency_ratio_grid <- urgency_ratio_grid %>%
  rename(gamma = `...1`) %>%
  pivot_longer(!gamma, names_to = "cost", values_to = "urgent") %>%
  mutate(cost = as.numeric(cost))

levelplot(urgent ~ cost * gamma, urgency_ratio_grid, 
          panel = panel.levelplot.points, cex = 0
    ) + 
    latticeExtra::layer(panel.2dsmoother(..., n = 200))

```

@fig-dynaprog-simulation shows that the optimal percentage of urgent choices varies by around 0.10, with lower probabilities centered around low cost parameters and high discount factors.

## Hypotheses

1.  Urgency Bias in Decision-Making:
    -   **H1**: A pronounced urgency bias will manifest predominantly among individuals from socioeconomically disadvantaged backgrounds and those exhibiting elevated anxiety metrics in task selection paradigms. This bias will accompany a discernible inclination towards tasks labeled as "urgent" over those deemed "important."
2.  Influence of Urgency Bias on Performance Outcomes:
    -   **H2**: An overemphasis on urgent tasks, as opposed to tasks of inherent importance, will correlate with suboptimal performance outcomes, suggesting a potential cognitive cost associated with such prioritization.
3.  Temporal Dynamics of Decision-Making:
    -   **H3**: A heightened selection frequency of urgent tasks will be concomitant with expedited reaction times, potentially indicative of decision-making under perceived scarcity or stress conditions.
4.  Socioeconomic and Psychological Modulators of Decision Accuracy:
    -   **H4**: Individuals with lower socioeconomic status or heightened anxiety will exhibit differential accuracy profiles in trade-off decisions, particularly when navigating the dichotomy between tasks of high urgency but low importance and those of low urgency but high importance. This pattern may underscore a heightened susceptibility to urgency-driven decision-making biases within these cohorts.

## Data

We conducted our experiment separately on MTurk and Prolific, acquiring N = 22 and N = 53 participants, respectively. We treated these samples as independent replications in some sections while pooling the results in others.

```{r load-pilot}
joint_pilot <- read_csv(file = "data/Pilot/joint_pilot.csv")
qualtrics <- read_csv("data/Pilot/Qualtrics.csv")
load("./Models/pilot/prolific1StanData.Rdata")
load("./Models/pilot/MTurk_sample_nolimit2.Rdata")
```

```{r}
#| label: wrangle-stai-demo

qualtrics <- qualtrics[-c(1:2),]
vars <- c("Q36", "Q37", "Q39", "Q40", "Q42", "Q45", "Q46", "Q47", "Q50", "Q51",
          "Q34", "Q35", "Q38", "Q41", "Q43", "Q44", "Q48", "Q49", "Q52", "Q53...54",
          "Q26", "Q27", "Q32")
qualtrics <- qualtrics %>%
  mutate(across(all_of(vars), as.numeric))
qualtrics <- qualtrics %>%
  mutate(
    stai = (Q36 + Q37 + Q39 + Q40 + Q42 + Q45 + Q46 + Q47 + Q50 + Q51 +
      5*10 - Q34 - Q35 - Q38 - Q41 - Q43 - Q44 - Q48 - Q49 - Q52 - Q53...54),
    age = 2021 - Q26
  ) %>%
  rename(
    income = Q32,
    education = Q27
  )

# Cleaning joint_pilot:
joint_pilot <- joint_pilot %>%
  group_by(participant, block) %>%
  filter(n() >= 10) %>% ungroup() %>%
  left_join(qualtrics, by = c("participant" = "PROLIFIC_PID"))

```

```{r}
#| label: data-wrangling-pilot

joint_pilot %>%
  group_by(platform) %>%
  mutate(
    high_income = 
      case_when(as.numeric(income) >= median(as.numeric(income), na.rm = TRUE) ~ 1,
                as.numeric(income)  < median(as.numeric(income), na.rm = TRUE) ~ 0),
    high_anxiety = 
      case_when(stai >= median(stai, na.rm = TRUE) ~ 1,
                stai  < median(stai, na.rm = TRUE) ~ 0)
  ) %>%
  mutate(
    high_income = factor(high_income,
                         ordered = TRUE,
                         labels = c("Low Income", "High Income")),
    high_anxiety = factor(high_anxiety,
                          ordered = TRUE,
                          labels = c("Low Anxiety", "High Anxiety")),
    male = if_else(Q30 == "1", 1, 0)
  ) %>%
  # Extract the indexes which differ for each variable: 
  mutate(
    heart = (u1 != u2), # <-- index @ which diff urgency
    dollar = (i1 != i2), # <-- index @ which diff importance
    effort = (e1 != e2), # <-- index @ which diff effort
    left_choice = (choice == "L"), # < --- index when left is chosen
    right_choice = (choice == "R"), # <--- index when right is chosen
    split = ((u1 != u2) & (i1 != i2) & (u1 != i1)), # <--- "hard" decision
    ui_leftsplit = left_choice*split, # <--- "hard" decision AND left is chosen
    ui_rightsplit = right_choice*split
  ) %>% 
  # Find the means of the values:
  mutate(
    huli = case_when(split == 0 ~ NA,
                     ui_leftsplit  == 1 & u1 == 2 ~ 1,
                     ui_rightsplit == 1 & u2 == 2 ~ 1,
                     ui_leftsplit  == 1 & u1 == 1 ~ 0,
                     ui_rightsplit == 1 & u2 == 1 ~ 0),
    luhi = case_when(split == 0 ~ NA,
                     ui_leftsplit  == 1 & i1 == 2 ~ 1,
                     ui_rightsplit == 1 & i2 == 2 ~ 1,
                     ui_leftsplit  == 1 & i1 == 1 ~ 0,
                     ui_rightsplit == 1 & i2 == 1 ~ 0)
  ) -> joint_pilot

joint_pilot$income <- ordered(joint_pilot$income)
joint_pilot$education <- ordered(joint_pilot$education)

```

```{r}
#| label: processing-data
participants_df <- aggregate(points ~ participant, data = joint_pilot, FUN = mean)
demograph <- merge(y = qualtrics,
                  x = participants_df,
                  by.y = "PROLIFIC_PID",
                  by.x = "participant")
ip2zip <- read_csv("data/ZIPcode/ip2zip.csv")
demograph <- merge(y = demograph,
                   x = ip2zip,
                   by.y = "IPAddress",
                   by.x = "IP")
### HERE:
poverty <- read_csv("data/ZIPcode/ACSST5Y2019.S1701_data_with_overlays_2021-12-21T174024.csv")
poverty <- poverty %>%
  dplyr::select(NAME,S1701_C03_001E) %>%
  mutate(ZIP = as.numeric(str_sub(NAME, start = -5))) %>%
  dplyr::select(-NAME)
demograph <- demograph %>%
  left_join(poverty, by = "ZIP")

income <- read_csv("data/ZIPcode/ACSST5Y2019.S1903_data_with_overlays_2021-11-16T180635.csv")
income <- income %>%
  dplyr::select(NAME,S1903_C03_001E) %>%
  mutate(ZIP = as.numeric(str_sub(NAME, start= -5))) %>%
  dplyr::select(-NAME)
demograph <- demograph %>%
  dplyr::select(-"IP") %>% ## Remove IP for privacy and cleaning
  left_join(income, by = "ZIP") %>%
  mutate(
    S1701_C03_001E = as.numeric(S1701_C03_001E),
    S1903_C03_001E = as.numeric(S1903_C03_001E)
  )

rm(ip2zip, income, poverty)

```

```{r}
#| label: accuracy-code
# Extracting parameter values
ShinyStan_2 <- summary(MTurk_sample_nolimit2)$summary
costs <- data.frame(matrix(nrow = 56))
costs$cL <- ShinyStan_2[c(5:60),1]
costs$cH <- ShinyStan_2[c(61:116),1]
costs <- costs[,-c(1)]

# With estimated parameters, find optimal choice
ev <- c(0,0)
value <- c(0,0,0,0)
#Tsubj <- Tsubj$n
value_lookup = model_data$value_lookup
counterpart <- model_data$counterpart
choice_best <- as.data.frame(matrix(0, 56, 40))
Tsubj <- model_data$Tsubj
state_lookup <- model_data$state_lookup
prob_weight <- model_data$prob_weight
opt_st <- model_data$opt_st
#opt_st <- opt_st[,-c(1)]
for (i in c(1:model_data$N)) {
  ev <- c(0,0)
  ch <- matrix(0, 80, Tsubj[i])
  st <- matrix(0, nrow = 52, ncol = Tsubj[i])
  
  # Declaring values for each option, lookup table (make it loop later)
  value[1] = 2 - costs[i,2];
  value[2] = 1 - costs[i,2];
  value[3] = 1 - costs[i,1];
  value[4] = 2 - costs[i,1];
  for(option in c(1:80)) {
    ch[option, Tsubj[i]] = value[value_lookup[option]]
  }
  for(state in c(1:52)) {
    if (ch[state_lookup[state,1], Tsubj[i]] >= ch[state_lookup[state,2], Tsubj[i]]) {
      st[state, Tsubj[i]] = ch[state_lookup[state,1], Tsubj[i]]
    } else if (ch[state_lookup[state,1], Tsubj[i]] < ch[state_lookup[state,2], Tsubj[i]]) {
      st[state, Tsubj[i]] = ch[state_lookup[state,2], Tsubj[i]]
    }
  }
  ev[1] = ch[as.numeric(opt_st[i, Tsubj[i]]), Tsubj[i]]
  ev[2] = ch[counterpart[as.numeric(opt_st[i, Tsubj[i]])], Tsubj[i]]
  if (ev[1] >= ev[2]) {
    choice_best[i, Tsubj[i]] = 1
  } else {
    choice_best[i, Tsubj[i]] = 2
  }
  
  if (!Tsubj[i] == 1) {
    
    for (t in c(1:(Tsubj[i]-1))) {
      round_back = Tsubj[i] - t
      for(option in c(1:80)) {
        weighted_value = as.numeric((prob_weight[option,])) %*% st[,(round_back + 1)]
        ch[option, round_back] = value[value_lookup[option]] + weighted_value
      }
      for(state in c(1:52)) {
        if (ch[state_lookup[state,1], round_back] >= ch[state_lookup[state,2], round_back]) {
          st[state, round_back] = ch[state_lookup[state,1], round_back]
        } else if (ch[state_lookup[state,1], round_back] < ch[state_lookup[state,2], round_back]) {
          st[state, round_back] = ch[state_lookup[state,2], round_back]
        }
      }
    }
    for (t in c(1:(Tsubj[i]-1))) {
      ev[1] = ch[as.numeric(opt_st[i, t]), t]
      ev[2] = ch[counterpart[as.numeric(opt_st[i, t])], t]
      if (ev[1] >= ev[2]) {
        choice_best[i, t] = 1
      } else {
        choice_best[i, t] = 2
      }
    }
  }
}

#####  Accuracy of all trials
# Ignores people with less than 10 trials:
choice <- model_data$choice
choice_best <- choice_best[Tsubj > 10,c(1:36)]
choice1 <- choice[Tsubj > 10,-c(1)]
choice1[choice1 == 0] <- NA
choice2 <- choice_best
choice2[choice2 == 0] <- NA
comparison <- (choice[Tsubj > 10,] == choice_best)
comparison[is.na(choice2)] <- NA
Accuracy <- rowMeans(comparison, na.rm=T)
Accuracy <- cbind(Accuracy, as.character(demograph[Tsubj > 10,]$participant))
Accuracy <- merge(x = Accuracy, y = demograph, by.x = "V2", by.y = "participant")
Accuracy$Accuracy <- as.numeric(Accuracy$Accuracy)

comparisonLONG <- as.data.frame(comparison) %>%
  cbind(as.character(demograph[Tsubj > 10,]$participant)) %>%
  rename(participant = `as.character(demograph[Tsubj > 10, ]$participant)`) %>%
  pivot_longer(cols = c(1:36), values_drop_na = TRUE, names_to = "round", values_to = "Optimal") %>%
  mutate(round = as.numeric(round))

## Adding poverty measure
joint_pilot <- joint_pilot %>% 
  left_join(demograph[,c(2,10:11)], by = "participant")

joint_pilot <- demograph %>%
  dplyr::select("participant","S1701_C03_001E","S1903_C03_001E") %>%
  right_join(joint_pilot,by = "participant") %>%
  left_join(comparisonLONG, by = c("participant", "round")) %>%
  ungroup() %>%
  mutate(poverty_zip = as.vector(scale(as.numeric(S1701_C03_001E))),
         median_income_zip = log(as.numeric(S1903_C03_001E)))

joint_pilot$income <- factor(joint_pilot$income, 
                            levels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12),
                            labels = c("< $10,000", "$10,000 to $19,999", "$20,000 to $29,999", 
                                       "$30,000 to $39,999", "$40,000 to $49,999", "$50,000 to $59,999", 
                                       "$60,000 to $69,999", "$70,000 to $79,999", "$80,000 to $89,999", 
                                       "$90,000 to $99,999", "$100,000 to $149,999", "> $150,000"),
                            ordered = TRUE)
joint_pilot$education <- factor(joint_pilot$education, 
                               levels = c(1, 2, 3, 4, 5, 6, 7, 8),
                               labels = c("Less than high school degree", 
                                          "High school graduate", 
                                          "Some college but no degree", 
                                          "Associate degree", 
                                          "Bachelor's degree", 
                                          "Master's degree", 
                                          "Doctoral degree", 
                                          "Professional degree (JD, MD)"),
                               ordered = TRUE)


trade_off_accuracy <- joint_pilot %>%
  group_by(participant) %>% 
  filter(length(RT) >= 10) %>%
  filter(u1 != u2, i1 != i2, i1 != u1) %>%
  mutate(Urgency = ifelse(u1 == 2 & choice == "L", 1,
                          ifelse(u2 == 2 & choice == "R", 1, 0 )))
```

### Demographics

For both Mturk and Prolific, we distinguish high-low income and high-low anxiety by a median split. The high income mean is about 70k, while the low income mean is around 30k $(p<0.001)$. Likewise, the high anxiety mean score is 56.29, while low anxiety mean score is 37.17 $(p<0.001)$.

```{r}
#| label: tbl-pilot-demographics
#| tbl-cap: "Demographic and Psychological Characteristics of Participants from MTurk and Prolific Platforms"

# Function to aggregate data for a given platform
get_platform_data <- function(data, platform_name) {
  data %>%
    filter(platform == platform_name) %>%
    summarise(
      Age_Min = min(age, na.rm = TRUE),
      Age_25th = quantile(age, 0.25, na.rm = TRUE),
      Age_Median = median(age, na.rm = TRUE),
      Age_Mean = round(mean(age, na.rm = TRUE), 1),
      Age_75th = quantile(age, 0.75, na.rm = TRUE),
      Age_Max = max(age, na.rm = TRUE),
      Income_Min = levels(income)[min(as.numeric(income), na.rm = TRUE)],
      Income_25th = levels(income)[quantile(as.numeric(income), 0.25, na.rm = TRUE)],
      Income_Median = levels(income)[median(as.numeric(income), na.rm = TRUE)],
      Income_75th = levels(income)[quantile(as.numeric(income), 0.75, na.rm = TRUE)],
      Income_Max = levels(income)[max(as.numeric(income), na.rm = TRUE)],
      Education_Min = levels(education)[min(as.numeric(education), na.rm = TRUE)],
      Education_25th = levels(education)[quantile(as.numeric(education), 0.25, na.rm = TRUE)],
      Education_Median = levels(education)[median(as.numeric(education), na.rm = TRUE)],
      Education_75th = levels(education)[quantile(as.numeric(education), 0.75, na.rm = TRUE)],
      Education_Max = levels(education)[max(as.numeric(education), na.rm = TRUE)],
      STAI_Min = min(stai, na.rm = TRUE),
      STAI_25th = quantile(stai, 0.25, na.rm = TRUE),
      STAI_Median = median(stai, na.rm = TRUE),
      STAI_Mean = round(mean(stai, na.rm = TRUE), 1),
      STAI_75th = quantile(stai, 0.75, na.rm = TRUE),
      STAI_Max = max(stai, na.rm = TRUE)
    ) %>%
    gather(key = "Variable", value = "Value") %>%
    separate(Variable, into = c("Variable", "Statistic"), sep = "_") %>%
    spread(key = "Statistic", value = "Value")
}

# Calculate unique participants for each platform
mturk_n <- length(unique(joint_pilot$participant[joint_pilot$platform == "MTurk"]))
prolific_n <- length(unique(joint_pilot$participant[joint_pilot$platform == "Prolific"]))

# Get data for both platforms
mturk_data <- get_platform_data(joint_pilot, "MTurk")
prolific_data <- get_platform_data(joint_pilot, "Prolific")

# Combine the two data frames for the table
combined_data <- bind_rows(mturk_data, prolific_data)

# Add a new column for Platform with the sample size
combined_data$Platform <- c(rep(paste0("MTurk (N = ", mturk_n, ")"), 4),
                            rep(paste0("Prolific (N = ", prolific_n, ")"),4))

# Replace NAs with empty values
combined_data[is.na(combined_data)] <- ""

# Create the table using the gt package
gt_table <- combined_data %>%
  gt(rowname_col = "Variable", groupname_col = "Platform") %>%
  tab_header(
    title = "Demographics"
  ) %>%
  cols_label(
    Min = "Min",
    `25th` = "1st Qu.",
    Median = "Median",
    Mean = "Mean",
    `75th` = "3rd Qu.",
    Max = "Max"
  ) %>%
  cols_move_to_start(columns = c("Min", "25th", "Median", "Mean", "75th", "Max"))

# Print the table
gt_table

```

### Measures of Poverty

Although income-based measures have long been the standard for assessing poverty, studies have since determined that purchasing power and standard of living are not accurately measured by such a metric (CITE). Rather, relative deprivation and state-trait anxiety measures are often more accurate empirical measurements of an individual's socioeconomic status (SES).

#### Self-Reported Income

Though the simplest measure to collect, self-reported incomes has a number of limitations. Participants may have the incentive not to divulge their true income levels. This bias can occur in both directions depending on the context and demand effects (e.g., a participant may want to appear richer or poorer than they actually are). Further, because exact income, when combined with other demographic measures, could potentially be used to identify participants, it is customary to elicit income brackets (vs. absolute income levels). This limitation may also reduce power and granularity in the our analysis.

#### ZIP code Measures

To supplement the self-reported income data and account for any potential measurement errors, we employed additional economic indicators based on participants' ZIP codes. The Internet Protocol (IP) addresses collected automatically by Qualtrics were used to determine the ZIP code of each participant's location. From these ZIP codes, we extracted relevant economic data, including median income and poverty measures, which provided a broader context for each participant's socioeconomic status.

The poverty measures in our analysis come from the American Community Survey (ACS) conducted by the U.S. Census Bureau. The ACS determines poverty status based on a set of income thresholds that vary by family size and composition. It provides a comprehensive and nuanced understanding of poverty by incorporating the complexity of family structures and income levels into its poverty thresholds.

The median income data we used is also sourced from the ACS. This data reflects the median income distribution across all households and families within each ZIP code, including those with no income. As a result, it provides a robust measure of the overall economic status of the communities in which our participants reside.

For a more detailed understanding of these measures, please refer to the ACS Subject Definitions document available at [this link](https://www2.census.gov/programs-surveys/acs/tech_docs/subject_definitions/2021_ACSSubjectDefinitions.pdf).

#### Composite Measure (PCA)

Poverty, a complex and multifaceted phenomenon, extends beyond mere monetary deprivation, encompassing physical, mental, and emotional dimensions that intricately shape an individual's well-being (Sen, 1999). Due to this complexity, our study employs Principal Component Analysis (PCA) to distill a poverty construct from a series of questions probing various facets of deprivation. This multidimensional perspective on poverty illuminates the complex interplay between mental health, self-perception, and financial status, uncovering underlying patterns that resonate with broader socioeconomic trends and psychological insights.

```{r}
#| label: pcascree-code
#| include: false

library(sinkr)
# Interpolating missing gaps using DINEOF
qualtrics[,c(55:141)] <- sapply(qualtrics[,c(55:141)],as.numeric)
qualtrics.prepca <- 
  qualtrics[,c(55:141)][,(apply(qualtrics[,c(55:141)], 2, var, na.rm=TRUE) != 0) &
                          !is.na(apply(qualtrics[,c(55:141)], 2, var, na.rm=TRUE))] %>%
  # Adding PROLIFIC_PID column and filtering
  add_column(PROLIFIC_PID = qualtrics$PROLIFIC_PID) %>%
  # filter(!is.na(PROLIFIC_PID)) %>%
  filter(rowSums(is.na(.)) < (ncol(.) - 1)) # Exclude PROLIFIC_PID column
interpolated_data <- dineof(qualtrics.prepca %>%
                              select(!"PROLIFIC_PID") %>% as.matrix)
```

```{r}
#| label: fig-pcascree
#| fig-cap: "Scree plot illustrating the explained variance of the principal components." 
  
# Performing PCA
qualtrics.pca <- prcomp(interpolated_data$Xa, center = TRUE, scale = TRUE)

### Scree plot
fviz_eig(qualtrics.pca, geom = "line", main = "")
# Results for Variables
qualtrics.var <- get_pca_var(qualtrics.pca)
# Results for individuals
qualtrics.ind <- get_pca_ind(qualtrics.pca)
deprivation <- as.data.frame(qualtrics.ind$coord[,c(1:3)])   # Coordinates
deprivation$PROLIFIC_PID <- qualtrics.prepca$PROLIFIC_PID

joint_pilot <- joint_pilot %>%
  left_join(deprivation, by = c("participant" = "PROLIFIC_PID")) %>%
  select(participant, points, RT, round, block, i1, e1, i2, e2, u1, u2,
         platform, education, income, stai, male, age, high_income, high_anxiety,
         left_choice, right_choice, split, huli, luhi, Optimal, poverty_zip,
         median_income_zip, Dim.1, Dim.2, Dim.3)

```

The questions, detailed in @sec-questionnaires, were crafted to explore physical, mental, and monetary deprivation. The responses underwent PCA, resulting in a data matrix of 87 variables, each representing a distinct deprivation aspect. @fig-pcascree shows a Scree plot, a graphical representation of the eigenvalues, which guided the selection of the top two components, together explaining `r round(get_eig(qualtrics.pca)[2,3],2)`% of the total variance.

```{r}
#| label: tbl-pilot-pca
#| tbl-cap: "Results From a Principal Component Analysis of the Questionnaire"

# 1. Identify top 5 questions for each of the first two PCs based on magnitude
top_questions_PC1 <- order(abs(qualtrics.var$coord[, 1]), decreasing = TRUE)[1:5]
top_questions_PC2 <- order(abs(qualtrics.var$coord[, 2]), decreasing = TRUE)[1:5]

# names(qualtrics.prepca)[top_questions_PC1]
# names(qualtrics.prepca)[top_questions_PC2]
# From codebook:
top_questions <- c("How would you rate your mental health over the past 4 weeks?",
                   "Over the past 2 weeks, how often have you felt little interest or pleasure in doing things?",
                   "Over the past 2 weeks, how often have you felt down, depressed, or hopeless?",
                   "I am not happy about achieving something good in the last 4 weeks.",
                   "I am happy with the house I live in.",
                   "How important are the following aspects of your life? [I need to be mentally healthy]",
                   "How important are the following: [How you feel about yourself]",
                   "How important are the following: [Your mental state of being]",
                   "How important are the following aspects of your life? [Having a good house to stay in]",
                   "How important are the following: [Your physical state of being]")

# 2. Extract the loadings for these questions for both PCs
table_data <- data.frame(
  QuestionText = top_questions,
  `PC1` = qualtrics.var$coord[c(top_questions_PC1, top_questions_PC2), 1],
  `PC2` = qualtrics.var$coord[c(top_questions_PC1, top_questions_PC2), 2]
)

# 3. Build the table
# Create the table with row groups and additional column header
# Add a grouping column for row groups
table_data$Group <- c(rep("Component 1: Depression", 5),
                      rep("Component 2: Concern for Mental Health", 5))

# Create the table
table_output <- gt(table_data, groupname_col = "Group") %>%
  cols_label(
    QuestionText = "",
    `PC1` = "PC 1",
    `PC2` = "PC 2"
  ) %>%
  fmt_number(
    columns = 2:3,
    decimals = 2
  ) %>%
  tab_spanner(
    label = "Loadings",
    columns = 2:3
  )


table_output

```

@tbl-pilot-pca shows the first principal component, which we termed "Depression," accounting for `r round(get_eig(qualtrics.pca)[1,2],2)`% of the total variance. It was a combination of high loadings on questions related to mental health and feelings of depression and hopelessness. This dimension aligns with existing literature emphasizing the mental health aspect of poverty, linking financial deprivation to feelings of depression and hopelessness (Lund et al., 2010). The second principal component, labeled "Concern for Mental Health," explained `r round(get_eig(qualtrics.pca)[2,2],2)`% of the total variance. It consisted mainly of questions about the importance of mental and physical well-being. Interestingly, this dimension reflects a growing awareness and concern for mental health, a trend observed in previous studies (Patel et al., 2018).

```{r}
#| label: fig-pcacorrelations
#| layout-ncol: 2
#| fig-cap: "Spearman Correlations of Principal Components. *** (p < .001), ** (p < .01), * (p < .05), † (p < .1)."
#| fig-subcap:
#|   - "Correlation between income and Component 1"
#|   - "Correlation between income and Component 2" 
#|   - "Correlation between state anxiety and Component 1"
#|   - "Correlation between state anxiety and Component 2"

# Function to create the plot
create_plot <- function(x_var, y_var,
                        x_label, y_label, x_breaks, x_labels,
                        x_coord, y_coord, x_angle) {
  spearman_cor <- cor.test(x_var, y_var, method = "spearman")
  significance <- ifelse(spearman_cor$p.value < 0.001, "***",
                  ifelse(spearman_cor$p.value < 0.01, "**",
                  ifelse(spearman_cor$p.value < 0.05, "*",
                  ifelse(spearman_cor$p.value < 0.1, "†", ""))))
  correlation_text <- paste("r(", length(na.omit(y_var)), ") =",
                            rd(spearman_cor$estimate, digits = 2), significance)
  ggplot(pca_plot_pilot, aes(x = x_var, y = y_var)) +
    geom_point(color = "steelblue", shape = 16, size = 3, fill = "white") +
    geom_smooth(method = "loess", se = TRUE, color = "red") +
    labs(x = x_label, y = y_label) +
    scale_x_continuous(breaks = x_breaks, labels = x_labels) +
    theme_minimal() +
    theme(plot.title = element_text(size = 18, hjust = 0.5, face = "bold", color = "steelblue"),
          axis.text.x = element_text(angle = x_angle, hjust = 1, vjust = 1,
                                     size = 12, face = "plain", color = "black"),
          axis.text.y = element_text(size = 12, face = "plain", color = "black"),
          axis.title = element_text(size = 14, face = "bold", color = "black"),
          panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
          panel.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), "cm"),
          plot.background = element_rect(fill = "white"), legend.position = "none") +
    annotate(geom = "label", x = x_coord, y = y_coord, label = correlation_text, size = 4)
}

# Define breaks and labels for income
income_breaks <- c(1, 2, seq(3.5, 10.5, by = 2), 11, 12)
income_labels <- c("< $10,000", "$10,000 to $19,999", "$20,000 to $39,999",
                   "$40,000 to $59,999", "$60,000 to $79,999", "$80,000 to $99,999",
                   "$100,000 to $149,999", "> $150,000")

# Create plots
pca_plot_pilot <- joint_pilot %>%
  mutate(income = as.numeric(income),
         stai = as.numeric(stai)) %>%
  filter(!is.na(Dim.1)) %>%
  group_by(participant) %>%
  summarise(income = mean(income), stai = mean(stai), 
            Dim.1 = mean(Dim.1), Dim.2 = mean(Dim.2))
create_plot(pca_plot_pilot$income, pca_plot_pilot$Dim.1, "Income", "Component 1",
            income_breaks, income_labels, 4, -6, 45)
create_plot(pca_plot_pilot$income, pca_plot_pilot$Dim.2, "Income", "Component 2",
            income_breaks, income_labels, 4, -4, 45)
create_plot(pca_plot_pilot$stai, pca_plot_pilot$Dim.1, "State Anxiety", "Component 1",
            waiver(), waiver(), 30, -4.5, 0)
create_plot(pca_plot_pilot$stai, pca_plot_pilot$Dim.2, "State Anxiety", "Component 2",
            waiver(), waiver(), 30, -4.5, 0)

```

Subsequently, we examined the correlations between the principal components and other variables using Spearman's rank correlation (Hauke & Kossowski, 2011). As depicted in @fig-pcacorrelations, these correlations reveal a nuanced relationship between income, anxiety, and the identified dimensions of poverty. Notably, the negative correlation between state anxiety and Component 1 underscores the link between mental health and poverty (Lorant et al., 2003). It is worth noting that physical and monetary deprivation questions did not yield sufficient variance in this analysis.

## Results

The dataset for our pilot experiment encompassed multiple choice variables, such as "Important," "Hard," and "Urgent" tasks, as well as participant demographic information, including the STAI score, income level, and platform. In this section, we will dissect the underlying patterns in choice behavior, delve into the trade-off decisions between urgency and importance, corroborate these observations through proportion tests, and scrutinize the effects of these behavioral biases on accuracy. This comprehensive examination elucidates how socioeconomic and psychological factors may influence task prioritization.

### Task Performance

```{r data for totalpoints}
#| eval: false
write_csv(joint_pilot, file = "data/Pilot/df.csv")
```

```{r}
#| label: task performance data prep

joint_pilot <- joint_pilot %>%
  mutate(chosen_i = if_else(left_choice, i1, i2) - 1,
         chosen_e = if_else(left_choice, e1, e2) - 1,
         chosen_u = if_else(left_choice, u1, u2) - 1,
         not_chosen_i = if_else(left_choice, i2, i1) - 1,
         not_chosen_e = if_else(left_choice, e2, e1) - 1,
         not_chosen_u = if_else(left_choice, u2, u1) - 1)

# Calculate total points per participant
points_per_participant <- joint_pilot %>%
  group_by(participant) %>%
  summarise(total_points = max(points),
            stai = first(stai),
            high_income = first(high_income),
            platform = first(platform))

# Calculate the percentage of times when the urgent, important and effortful options were chosen
choice_percentages <- joint_pilot %>%
  mutate(
    urgent_chosen = ifelse(chosen_u > not_chosen_u, 1, 0),
    important_chosen = ifelse(chosen_i > not_chosen_i, 1, 0),
    effort_chosen = ifelse(chosen_e > not_chosen_e, 1, 0)
  ) %>%
  group_by(participant) %>%
  summarise(perc_urgent_chosen = mean(urgent_chosen, na.rm = TRUE),
            perc_important_chosen = mean(important_chosen, na.rm = TRUE),
            perc_effort_chosen = mean(effort_chosen, na.rm = TRUE))

performance <- inner_join(points_per_participant, choice_percentages, by = "participant")

# Run regression
regression_model <- lm(total_points ~ perc_important_chosen + 
                         perc_effort_chosen + perc_urgent_chosen +
                         stai + high_income + platform, data = performance)

# summary_stats <- summary(regression_model)

reduced_model <- lm(total_points ~ perc_important_chosen +
                      perc_effort_chosen + perc_urgent_chosen,
                    data = performance)

```

We compiled data on each participant's selection and non-selection of each type of task (Important, Hard, and Urgent), then computed the frequency with which each participant picked a particular task type when given an option. @tbl-totalpoints indicates that the decision to complete Important tasks significantly affected the total points a participant amassed (Estimate = `r get_regression_result(regression_model, "perc_important_chosen")`). Specifically, a ten percentage-point rise in the ratio of selected Important tasks (two points, as opposed to one point) resulted in an increase of `r round(regression_model$coefficients["perc_important_chosen"]/10, 1)` points in the overall score. However, the percentage of times a participant chose Hard or Urgent tasks did not significantly explain the total points accumulated (`r get_regression_result(regression_model, "perc_effort_chosen")` for Hard tasks; `r get_regression_result(regression_model, "perc_urgent_chosen")` for Urgent tasks).

We also included demographic variables and participant characteristics (STAI score, income level, and platform) as control variables in the regression model, but none showed a significant relationship with total points.

The model accounted for approximately `r round(summary(regression_model)$r.squared*100, 2)`% of the variance in total points (Adjusted R-squared = `r round(summary(regression_model)$adj.r.squared, 3)`), with an overall significant model fit (F(6,68) = 2.877, p \< .05).

```{r, results='asis'}
#| label: tbl-totalpoints
#| tbl-cap: "Regression analysis of total points on participants' choice behavior and demographic variables"
#| tbl-subcap: "The predictors include the percentage of choices where Important, Hard, and Urgent tasks were chosen, participants' STAI score, income level (High vs. Low), and the platform on which the experiment was conducted (Prolific vs. Mturk)."

texreg(list(reduced_model, regression_model),
       custom.coef.map = list("perc_important_chosen" = "Percentage of Important task chosen",
                              "perc_effort_chosen" = "Percentage of Hard task chosen",
                              "perc_urgent_chosen" = "Percentage of Urgent task chosen",
                              "stai" = "Anxiety Score",
                              "high_income.L" = "Low Income",
                              "platformProlific" = "Platform: Prolific (vs. Mturk)"),
       stars = c(0.05, 0.01, 0.001),
       custom.header = list("Total Points" = 1:2))

```

### Trade-off Decisions

Trade-off decisions, particularly those involving urgency and importance, are pivotal in understanding human behavior in task prioritization. Our analysis honed in on the individual's choice of "challenging" tasks, specifically between high-urgency vs. low-importance or low-importance vs. high-urgency tasks. These choices unravel a multifaceted interplay between anxiety, income, and the perceived value of tasks.

```{r}
#| label: fig-tradeoff-results
#| fig-cap: "Choice frequency of urgent/not important tasks by median split groups"
#| fig-subcap:
#|   - "Choice frequency of urgent/not important tasks by income"
#|   - "Choice frequency of urgent/not important tasks by anxiety"
#| layout-ncol: 2

joint_pilot %>%
  group_by(platform, high_income) %>%
  filter(!is.na(high_income)) %>%
  summarise(choose_urg = sum(huli, na.rm = TRUE),
            total = sum(!is.na(huli)),
            mean_huli  = mean(huli, na.rm = TRUE)) %>%
  mutate(se = sqrt((mean_huli * (1 - mean_huli)) / total)) %>%
  
  ggplot(aes(platform, mean_huli, fill = high_income),
         alpha = 0.7) + 
  geom_col(position = "dodge") +
  scale_fill_brewer() +
  labs(x = "Choice Proportion", y = NULL) +
  theme_minimal() +
  theme(legend.position = "bottom",
        legend.title = element_blank()) +
  geom_errorbar(aes(ymin = mean_huli - se, ymax = mean_huli + se),
                width=0.4,
                alpha=0.9,
                position = position_dodge(0.9)) + 
  geom_hline(yintercept=0.5, linetype=2)


joint_pilot %>%
  group_by(platform, high_anxiety) %>%
  filter(!is.na(high_anxiety)) %>%
  summarise(choose_urg = sum(huli, na.rm = TRUE),
            total = sum(!is.na(huli)),
            mean_huli  = mean(huli, na.rm = TRUE)) %>%
  mutate(se = sqrt((mean_huli * (1-mean_huli)) / total)) %>%
  
  ggplot(aes(platform, mean_huli, fill = high_anxiety),
         alpha=0.7) + 
  geom_col(position = "dodge") +
  scale_fill_brewer() +
  labs(x = NULL, y = NULL) +
  theme_minimal() +
  theme(legend.position = "bottom",
        legend.title = element_blank()) +
  geom_errorbar(aes(ymin = mean_huli - se, ymax = mean_huli + se),
                width=0.4,
                alpha=0.9,
                position = position_dodge(0.9)) + 
  geom_hline(yintercept=0.5, linetype=2)


```

```{r}
#| label: proportion-tests

joint_pilot %>%
  mutate(huli = factor(huli,
                       ordered = FALSE,
                       levels = c(1,0),
                       labels = c("High Urgency, Low Importance",
                                  "Low Urgency, High Importance"))) %>%
  prop_test(formula = huli ~ high_income,
            alternative = "greater",
            order = c("Low Income", "High Income")) -> pooled_income_test

joint_pilot %>% 
  mutate(huli = factor(huli,
                       ordered = FALSE,
                       levels = c(1,0),
                       labels = c("High Urgency, Low Importance",
                                  "Low Urgency, High Importance"))) %>%
  prop_test(formula = huli ~ high_anxiety,
            alternative = "less",
            order = c("Low Anxiety", "High Anxiety")) -> pooled_anxiety_test

joint_pilot %>%
  filter(high_income == "Low Income") %>%
  mutate(huli = factor(huli,
                       ordered = FALSE,
                       levels = c(1,0),
                       labels = c("High Urgency, Low Importance",
                                  "Low Urgency, High Importance"))) %>%
  prop_test(formula = huli ~ NULL,
            success = "High Urgency, Low Importance",
            p = 0.5,
            alternative = "greater") -> low_income_test

joint_pilot %>%
  filter(high_anxiety == "High Anxiety") %>%
  mutate(huli = factor(huli,
                       ordered = FALSE,
                       levels = c(1,0),
                       labels = c("High Urgency, Low Importance",
                                  "Low Urgency, High Importance"))) %>%
  prop_test(formula = huli ~ NULL,
            success = "High Urgency, Low Importance",
            p = 0.5,
            alternative = "greater") -> high_anxiety_test

```

The graphs in @fig-tradeoff-results illustrate the choice frequency of urgent versus non-urgent tasks across different platforms, segmented by income and anxiety levels. The error bars denote the standard error of the mean.

1.  **Income Graph**: Individuals with low income tend to opt for urgent tasks more frequently than those with high income. The choice frequency is on the y-axis, and the platforms are on the x-axis. The dashed line at y=0.5 symbolizes an equal preference for urgent and non-urgent tasks. A pooled income test, employing a chi-squared proportion test with both Mturk and Prolific participants, assessed the differences in urgency preference between low- and high-income groups. The result was not statistically significant (`r get_p_text(pooled_income_test$p_value)`). However, a specific test for low-income individuals, using a one-sample proportion test, revealed a significant preference for high-urgency, low-importance tasks (`r get_p_text(low_income_test$p_value)`).

2.  **Anxiety Graph**: Individuals with high anxiety levels are more inclined to choose urgent tasks. The layout and interpretation are analogous to the income graph. The pooled anxiety test, also utilizing a chi-squared proportion test, did not detect a significant difference between low- and high-anxiety groups (`r get_p_text(pooled_anxiety_test$p_value)`). However, a specific test for high-anxiety individuals, employing the same one-sample proportion test as income, significantly demonstrated a preference for high-urgency, low-importance tasks (`r get_p_text(high_anxiety_test$p_value)`).

### General Urgency Bias

We also explore a more comprehensive urgency bias spanning various decision types and demographic groups. As delineated in @tbl-urgencypoverty, a notable pattern emerges: individuals within the low-income brackets and those with smaller state anxiety scores exhibited an increased propensity to opt for urgent tasks. This finding contrasts the trends in @fig-tradeoff-results, where neither income nor state anxiety significantly influenced the task preferences of Prolific participants. 

Furthermore, our regression analyses unveil a subtle dynamic between state anxiety and self-reported income. This interaction, albeit modest in magnitude, wields a discernible influence on the proclivity to prioritize an urgent task. In other words, transitioning from one income bracket to the next diminishes the odds of selecting an urgent task by roughly a quarter. An increase of the State Anxiety Score by 10 points (equivalent to approximately one standard deviation) correlates with a 40% decrease in the odds. When we factor in the interaction between these variables, a combined shift in income bracket and a 10-point surge in anxiety culminates in a 50% reduction in the odds, as opposed to the anticipated 55% when disregarding the interaction.

Beyond these primary determinants, other indicators, including ZIP poverty, ZIP income levels, and our principal components, did not significantly explain the probability of opting for an urgent task. This result underscores the importance of leveraging reliable data when delving into the subtleties of such biases.

```{r, results='asis'}
#| label: tbl-urgencypoverty
#| tbl-cap: "Urgency Bias Regression Models"
#| tbl-subcap: "Logistic regression models assessing the likelihood of selecting an urgent task, with individual and round-specific random effects. Covariates include age, education, points, attributes of the chosen and unchosen tasks, and the round number. Coefficients denote the log odds shift in opting for an urgent task corresponding to a unit alteration in the predictor. Analysis data confined to Prolific participants."

two_options <- joint_pilot %>%
  filter(!is.na(participant), !is.na(round), platform != "MTurk") %>%
  mutate(income = as.numeric(income),
         logRT = log(as.numeric(RT)),
         platform = factor(platform)) %>%
  filter(logRT != Inf & logRT != -Inf) %>%
  group_by(participant, block) %>%
  mutate(max_round_in_block = max(round)) %>% ungroup() %>%
  group_by(participant) %>% arrange(block) %>%
  mutate(first_block_rounds = first(max_round_in_block),
         round = round + first_block_rounds * (block - 1)) %>% # Only works for 1 or 2 rounds
  select(-max_round_in_block, -first_block_rounds)
two_options <- pdata.frame(two_options, index = c("participant", "round"))

# Function to fit the model
fit_model <- function(formula, data) {
  pglm(formula = formula,
       data = data,
       effect = "twoways",
       family = binomial('logit'),
       model = "random")
}
# Function to calculate observations
get_gof_rows <- function(model) {
  obs_trials <- model$model %>%
    group_by(pick(2:5)) %>%
    summarise(trials = n()) %>% ungroup() %>%
    summarise(max = max(trials), min = min(trials), mean = mean(trials))
   obs_participants <- model$model %>%
    group_by(pick(2:5)) %>%
    mutate(id = row_number()) %>% ungroup() %>%
    summarise(N = max(id))
  Participants <- obs_participants$N
  Trials <- paste0(obs_trials$min, "-", obs_trials$max, " (M = ", round(obs_trials$mean,1),")")
  BIC <- AIC(model, k = log(nrow(model$model)))
  return(list(Participants = Participants, Trials = Trials, BIC = BIC))
}

# Define formulas
formulas <- list(
  chosen_u ~ Dim.1*Dim.2 + age + male + points +
    chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u,
  
  chosen_u ~ income*stai + age + male + points +
    chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u,
  
  chosen_u ~ poverty_zip*stai + age + male + points +
    chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u,
  
  chosen_u ~ median_income_zip*stai + age + male + points +
    chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u
)

# Fit models
models <- lapply(formulas, fit_model, data = two_options)

# Generate the table
gof_list <- lapply(models, get_gof_rows)
final_gof_list <- list(
  Participants = sapply(gof_list, `[[`, "Participants"),
  Trials = sapply(gof_list, `[[`, "Trials"),
  BIC = sapply(gof_list, `[[`, "BIC")
)

# Define custom coefficient names
custom_coef <- list("Dim.1" = "PC 1",
                    "Dim.2" = "PC 2",
                    "income" = "Income",
                    "stai" = "Anxiety",
                    "poverty_zip" = "ZIP Poverty Level",
                    "median_income_zip" = "ZIP Median Income",
                    "income:stai" = "Anxiety Interaction",
                    "poverty_zip:stai" = "Anxiety Interaction",
                    "median_income_zip:stai" = "Anxiety Interaction")

texreg(lapply(models, function(x) {texreg::extract(x, include.aic = FALSE,
                                                   include.loglik = FALSE)}),
       custom.model.names = c("(1)","(2)","(3)","(4)"),
       custom.header = list("Prob(Chosen Task Urgency = High)" = 1:4),
       stars = c(0.001, 0.01, 0.05, 0.1),
       custom.coef.map = custom_coef,
       custom.gof.rows = final_gof_list)

```

<!-- ### Reaction Time -->

```{r, results='asis'}
#| eval: false
#| label: tbl-reactiontime
#| tbl-cap: "Regression analysis of reaction time (RT) on participants' PCs and anxiety measures."

# Function to fit the model
fit_model <- function(formula, data) {
  pglm(formula = formula,
       data = data,
       effect = "twoways",
       family = gaussian,
       model = "random")
}

# Define formulas
formulas <- list(
  logRT ~ Dim.1*Dim.2 + age + male + points +
    chosen_i + chosen_e + chosen_u + not_chosen_i + not_chosen_e + not_chosen_u,
  
  logRT ~ income*stai + age + male + points +
    chosen_i + chosen_e + chosen_u + not_chosen_i + not_chosen_e + not_chosen_u,
  
  logRT ~ poverty_zip*stai + age + male + points +
    chosen_i + chosen_e + chosen_u + not_chosen_i + not_chosen_e + not_chosen_u,
  
  logRT ~ median_income_zip*stai + age + male + points +
    chosen_i + chosen_e + chosen_u + not_chosen_i + not_chosen_e + not_chosen_u
)

# Fit models
models <- lapply(formulas, fit_model, data = two_options) #Defined in previous block

# Generate the table
gof_list <- lapply(models, get_gof_rows)
final_gof_list <- list(
  Participants = sapply(gof_list, `[[`, "Participants"),
  Trials = sapply(gof_list, `[[`, "Trials"),
  BIC = sapply(gof_list, `[[`, "BIC")
)

# Define custom coefficient names
custom_coef <- list("Dim.1" = "PC 1",
                    "Dim.2" = "PC 2",
                    "income" = "Income",
                    "stai" = "Anxiety",
                    "poverty_zip" = "ZIP Poverty Level",
                    "median_income_zip" = "ZIP Median Income",
                    "income:stai" = "Anxiety Interaction",
                    "poverty_zip:stai" = "Anxiety Interaction",
                    "median_income_zip:stai" = "Anxiety Interaction")

texreg(lapply(models, function(x) {texreg::extract(x, include.aic = FALSE, include.loglik = FALSE)}),
       custom.model.names = c("(1)","(2)","(3)","(4)"),
       custom.header = list("Reaction Time" = 1:4),
       stars = c(0.001, 0.01, 0.05, 0.1),
       custom.coef.map = custom_coef,
       custom.gof.rows = final_gof_list)

```

### Accuracy {#sec-pilotaccuracy}

The alignment of individual choices with an optimal or rational protocol offers a compelling lens through which to gauge the efficacy of those decisions. In this section, we compare participants' choices against a benchmark: an optimal protocol derived using a hierarchical Bayesian model of a dynamic programming strategy.

To achieve this, we first constructed a hierarchical Bayesian model that captures individual and group-level decision-making variability. The hierarchical structure allows for the pooling of information across participants, thereby enhancing the robustness of our inferences. Within this model, the dynamic programming strategy is the mathematical tool determining the optimal decision sequence that maximizes expected utility over time. In this framework, we deduced each participant's cost parameters, operating under the premise of a known reward structure and transition probabilities. The histogram in @fig-costs graphically delineates the inferred costs for each participant. These costs, categorized as 'low' or 'high,' quantify the equivalent exertion in point units for tasks demanding varying effort levels. The derived parameters correspond to the values that maximize the likelihood of the observed data on the postulated dynamic programming model.

Following the estimation of the parameters, we employed a backward induction approach to identify the optimal selection for each state based on the inferred costs. We aimed to assess the accuracy of the participants' decisions by comparing them with the anticipated outcomes predicted by the optimal protocol from the dynamic programming model.

```{r}
#| label: fig-costs
#| fig-cap: "Histogram of Estimated Costs per Participant"

dat <- data.frame(dens = c(costs$cH, costs$cL), 
                  lines = rep(c("cH", "cL"), each = nrow(costs)))

ggplot(dat, aes(x = dens, fill = lines)) + 
  geom_density(alpha = 0.5) +
  scale_fill_manual(
    name = "Cost",
    values = c("cH" = "blue", "cL" = "red"),
    labels = c("High", "Low")
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 10),
    axis.title.x = element_blank(),
    axis.title.y = element_text(size = 12, face = "bold"),
    axis.text = element_text(size = 10)
  ) +
  labs(
    y = "Density"
  )

```

```{r}
#| label: fig-accuracy-results
#| fig-cap: "Participant Accuracy by Income and Anxiety"
#| fig-subcap:
#|   - "Prolific, Income"
#|   - "Prolific, Anxiety"
#| layout-ncol: 2

# Create a custom theme for enhanced aesthetics
custom_theme <- theme_minimal() +
  theme(plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
        plot.subtitle = element_text(size = 14, face = "italic", hjust = 0.5),
        axis.title.x = element_text(size = 12, face = "bold"),
        axis.title.y = element_text(size = 12, face = "bold"),
        axis.text = element_text(size = 10),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        legend.position = "none")

# Plot no 1 : Participant Accuracy by Income
ggplot(Accuracy, aes(x = income, y = Accuracy)) +
  geom_point(color = "steelblue", size = 3) +
  stat_smooth(method = loess, color = "red", size = 1) +
  geom_label(x = 6, y = 0.8,
             label = paste("Correlation:",
                           round(cor(Accuracy$Accuracy, Accuracy$income), 2)),
             fill = "white", color = "black", label.padding = unit(0.35, "lines")) +
  labs(x = "Income", y = "Accuracy",
       title = "Participant Accuracy by Income",
       subtitle = "Prolific, Income") +
  custom_theme

# Plot no 2: Participant Accuracy by STAI (State-Trait Anxiety Inventory)
ggplot(Accuracy, aes(x = stai, y = Accuracy)) +
  geom_point(color = "steelblue", size = 3) +
  stat_smooth(method = loess, color = "red", size = 1) +
  geom_label(x = 30, y = 0.8,
             label = paste("Correlation:",
                           round(cor(Accuracy$stai, Accuracy$Accuracy), 2)),
             fill = "white", color = "black", label.padding = unit(0.35, "lines")) +
  labs(x = "SAI (State Anxiety Inventory)", y = "Accuracy",
       title = "Participant Accuracy by State Anxiety",
       subtitle = "Prolific, Anxiety") +
  custom_theme

```

@fig-accuracy-results offers a granular view of participant accuracy, segmented by income and anxiety levels. Each data point, represented as a dot, encapsulates a participant's performance, with the y-axis signifying the percentage of correct choices made during the experiment.

@tbl-accuracy presents the regression analyses of accuracy on potentially influential variables such as income and anxiety. The State Anxiety Score emerges as a significant influencer among many predictors. Specifically, a surge of 10 points in this score is associated with a 40% decrease in the odds of opting for the optimal task.

```{r, results='asis'}
#| label: tbl-accuracy
#| tbl-cap: "Regression analysis of accuracy on participants' choice behavior and demographic variables"
#| tbl-subcap: "Logistic regression models assessing the likelihood of selecting the optimal task, with individual and round-specific random effects. Covariates include age, education, points, attributes of the chosen and unchosen tasks, and the round number. Coefficients denote the log odds shift in opting for the optimal task corresponding to a unit alteration in the predictor. Analysis data confined to Prolific participants."

# Fit the models
accuracy_models <- list(
    accuracy_pca = pglm(formula = Optimal ~ Dim.1*Dim.2  +
                      age + male + points +
                      chosen_i + chosen_e + chosen_u +
                      not_chosen_i + not_chosen_e + not_chosen_u,
             data = two_options,
             effect = "twoways",
             model = "random",
             family = binomial('logit')),
  accuracy_income = pglm(formula = Optimal ~ income*stai +
                         age + male + points +
                         chosen_i + chosen_e + chosen_u +
                         not_chosen_i + not_chosen_e + not_chosen_u,
             data = two_options,
             effect = "twoways",
             model = "random",
             family = binomial('logit')),
  accuracy_zipdeprivation = pglm(formula = Optimal ~ poverty_zip*stai +
                      age + male + points +
                      chosen_i + chosen_e + chosen_u +
                      not_chosen_i + not_chosen_e + not_chosen_u,
             data = two_options,
             effect = "twoways",
             model = "random",
             family = binomial('logit')),
  accuracy_zipincome = pglm(formula = Optimal ~ median_income_zip*stai  +
                      age + male + points +
                      chosen_i + chosen_e + chosen_u +
                      not_chosen_i + not_chosen_e + not_chosen_u,
             data = two_options,
             effect = "twoways",
             model = "random",
             family = binomial('logit'))
)

# Function to calculate observations
get_gof_rows <- function(model) {
  obs_trials <- model$model %>%
    group_by(pick(2:5)) %>%
    summarise(trials = n()) %>% ungroup() %>%
    summarise(max = max(trials), min = min(trials), mean = mean(trials))
  obs_participants <- model$model %>%
    group_by(pick(2:5)) %>%
    mutate(id = row_number()) %>% ungroup() %>%
    summarise(N = max(id))
  Participants <- obs_participants$N
  Trials <- paste0(obs_trials$min, "-", obs_trials$max, " (M = ", round(obs_trials$mean,1),")")
  BIC <- AIC(model, k = log(nrow(model$model)))
  return(list(Participants = Participants, Trials = Trials, BIC = BIC))
}

# Generate the table
gof_list <- lapply(accuracy_models, get_gof_rows)
final_gof_list <- list(
  Participants = sapply(gof_list, `[[`, "Participants"),
  Trials = sapply(gof_list, `[[`, "Trials"),
  BIC = sapply(gof_list, `[[`, "BIC")
)

# Define custom coefficient names
custom_coef <- list("Dim.1" = "PC 1",
                    "Dim.2" = "PC 2",
                    "income" = "Income",
                    "stai" = "Anxiety",
                    "poverty_zip" = "ZIP Poverty Level",
                    "median_income_zip" = "ZIP Median Income",
                    "income:stai" = "Anxiety Interaction",
                    "poverty_zip:stai" = "Anxiety Interaction",
                    "median_income_zip:stai" = "Anxiety Interaction")

texreg(lapply(accuracy_models, function(x) {
  texreg::extract(x, include.aic = FALSE, include.loglik = FALSE)
  }),
  custom.model.names = c("(1)","(2)","(3)","(4)"),
  custom.header = list("Accuracy" = 1:4),
  stars = c(0.001, 0.01, 0.05, 0.1),
  custom.coef.map = custom_coef,
  custom.gof.rows = final_gof_list)

```

## Summary

# Experiment 1

## Methodology

Experiment 1 was developed in PsychoPy version 2023.1.3 and hosted on the Pavlovia platform.

### Structure

In line with the pilot study, the game interface for Experiment 1 presented participants with a queue of tasks, each varying in effort, importance, and urgency. As previously depicted in @fig-choice, we visually represented these characteristics with corresponding icons on each task image.

1.  Effort: As in the pilot study, we operationalized effort through the number of clicks required to complete an order, with more complex orders demanding more effort.

2.  Importance (value): The representation of importance remained consistent with the pilot study, with dollar signs indicating the subjective value of a task. However, with each point now worth \$0.05, participants now earn up to \$4.00 based on their total points.

3.  Urgency: The urgency of tasks was conveyed similarly to the pilot study, with clock icons indicating the degree of urgency. However, low-urgency tasks now remained in the queue for four rounds before being replaced, and, unlike high-urgency tasks, there was no penalty if low-urgency tasks disappeared after four rounds.

In each round, participants saw the screen shown in @fig-exp. They were instructed to select a task from the queue (left or right) and click on the matching ice cream icons in the center of the screen to complete it. The game continued for 40 orders, doubling the length of the pilot study to provide a more robust measure of participant behavior. As in the pilot study, participants were not restricted to a specific order of task completion, allowing for an open-choice design that facilitated the observation and analysis of decision-making and prioritization strategies. The potential earnings increased to a maximum of $\$4.00$, contingent on the total number of points accumulated throughout the game, to further incentivize participation.

Experiment 1 introduced a critical modification to the task queue logic, distinguishing it from the pilot study. As previously noted, specific task scenarios in the game posed more complex decision-making challenges, where the optimal course of action was not immediately apparent (e.g., choosing between a high-importance, low-urgency task, and a high-urgency, low-importance task). Due to the uniform task sampling employed in our pilot study, these "hard choices" were infrequently encountered.

Experiment 1 addressed this limitation by adjusting the task queue logic. Specifically, if the remaining task in the queue was of high importance and low urgency, there was a 50% chance that the subsequent task would be of high urgency and low importance, and vice versa. This element of randomness introduced an additional layer of unpredictability into the task queue, thereby enhancing the realism and complexity of the decision-making process for participants. This significant redesign from the pilot study increased the frequency of "hard choices," enabling us to delve deeper into analyzing participants' decision-making and prioritization strategies under these more challenging circumstances.

![Game interface for Experiment 1. Participants have a queue, with a task on each side, and a series of icons they must press in order to complete a task. The clocks and dollar signs on a task represent the urgency and importance of the task, respectively. The top of the screen displays a points counter and a rounds counter.](images/exp_example.png){#fig-exp}

<!-- ## Power Analysis -->

<!-- ### Behavioral Measures -->

<!-- ### Perceived Effort -->

## Hypotheses

```{r load-data-and-analysis, message=FALSE, warning=FALSE}
library(mice)
library(caret)

# Load the data
load(file = "data/Exp1/df.Rdata")

df$Q23 <- factor(df$Q23,
                 levels = c("Less than $10,000",
                            "$10,000 - $15,000",
                            "$15,001 - $25,000",
                            "$25,001 - $50,000",
                            "$50,001 - $75,000",
                            "$75,001 - $100,000",
                            "$100,001 - $150,000",
                            "More than $150,000"))
df$Q24 <- factor(df$Q24, ordered = FALSE)
df$Q49_1 <- factor(df$Q49_1,
                   levels = c("Never True",
                              "Sometimes",
                              "Often"))
df$Q49_2 <- factor(df$Q49_2,
                   levels = c("Never True",
                              "Sometimes",
                              "Often"))
df$Q49_3 <- factor(df$Q49_3,
                   levels = c("Never True",
                              "Sometimes",
                              "Often"))
df$Q51 <- factor(df$Q51,
                 levels = c("Never",
                            "Some months, but not every month",
                            "Only 1 or 2 months",
                            "Almost every month"))
df$Q54 <- factor(df$Q54,
                 levels = c("Never",
                            "Some months, but not every month",
                            "Only 1 or 2 months",
                            "Almost every month"))
df$Q56_1 <- factor(df$Q56_1,
                   levels = c("Never true",
                              "Sometimes true",
                              "Often true"))
df$Q56_2 <- factor(df$Q56_2,
                   levels = c("Never true",
                              "Sometimes true",
                              "Often true"))
df$Q56_3 <- factor(df$Q56_3,
                   levels = c("Never true",
                              "Sometimes true",
                              "Often true"))


# Clean column names
names(df) <- gsub("\\s", "_", names(df))  # Replace spaces with underscores
names(df) <- gsub("\\(|\\)", "", names(df))  # Remove parentheses

# Define the mapping from ordinal to numeric values
binary_vars <- c("Q33_1", "Q33_2", "Q33_3", "Q33_4", "Q33_5", "Q33_6", "Q36",
                 "Q46_1", "Q46_2", "Q46_3", "Q46_4", "Q46_5", "Q46_6", "Q46_7", 
                 "Q47_1", "Q47_2", "Q47_3", "Q47_4", "Q47_5", "Q47_6", "Q47_7", "Q47_8", "Q47_9",
                 "Q48_1", "Q48_2", "Q48_3", "Q48_4", "Q48_5", "Q48_6", "Q48_7",
                 "Q50", "Q52", "Q53", "Q55", "Q57", "Q58", "Q59", "Student_status")
df[binary_vars] <- lapply(df[binary_vars],
                          function(x) as.numeric(as.character(x) == "Yes"))

# Infer Variables from Survey logic
df$Q51[df$Q50 == 0] <- "Never"
df$Q54[df$Q53 == 0] <- "Never"
df$Q56_1[df$Q55 == 0] <- "Never true"
df$Q56_2[df$Q55 == 0] <- "Never true"
df$Q56_3[df$Q55 == 0] <- "Never true"
df$Q57[df$Q55 == 0] <- 0
df$Q36[df$Q33_1 == 0] <- 0

# Remove columns that are all NA
df <- df[, colSums(is.na(df)) != nrow(df)]
# Detect and remove zero-variance predictors
nzv <- nearZeroVar(df[,-129], saveMetrics = TRUE)
# Remove the variables with zero variance from the data
df <- df[, c(!nzv$zeroVar, TRUE)]

# Perform multiple imputation
## Create df without the trial info:
df_mice <- df %>% select(!CSV_Data)
## Set up the predictorMatrix
df_mice <- df_mice[,-c(1:5,73:113,114)]
predictorMatrix <- make.predictorMatrix(df_mice)

# ## Compute the maximum percentage of missing values
# max_missing_percentage <- round(max(colMeans(is.na(df_mice))) * 100)
# imputed_data <- mice(df_mice, m = max_missing_percentage,
#                      method = 'rf', maxit = 30,
#                      predictorMatrix = predictorMatrix)
# 
# save(imputed_data, file = "data/Exp1/imputed_data.Rdata")
load(file = "data/Exp1/imputed_data.Rdata")

# Calculate STAI
df <- df %>%
  mutate(across(c(paste0("Q", 3:22),
                  paste0("Q", 77:96),
                  paste0("Q", 99:118)), as.numeric))
df <- df %>%
  mutate(across(c("Q3", "Q4", "Q7", "Q10", "Q12", "Q13", "Q17", "Q18", "Q21",
                  "Q22", "Q77", "Q78", "Q81", "Q84", "Q86", "Q87", "Q91", "Q92",
                  "Q95", "Q96"), function(x) 5 - x),
         across(c("Q99", "Q101", "Q104", "Q105", "Q108",
                  "Q111", "Q112", "Q114", "Q117"), function(x) 5 - x),
         SAI_pre = rowSums(select(df, Q3:Q22), na.rm = TRUE),
         SAI_post = rowSums(select(df, Q77:Q96), na.rm = TRUE),
         TAI_post = rowSums(select(df, Q99:Q118), na.rm = TRUE))

# Transform all to numeric
completed_data <- complete(imputed_data, 1) %>%
  mutate(Q23 = as.numeric(Q23),
         ResidenceValue = as.numeric(ResidenceValue),
         Q49_1 = as.numeric(Q49_1),
         Q49_2 = as.numeric(Q49_2),
         Q49_3 = as.numeric(Q49_3),
         Q51 = as.numeric(Q51),
         Q53 = as.numeric(Q53),
         Q54 = as.numeric(Q54),
         Q56_1 = as.numeric(Q56_1),
         Q56_2 = as.numeric(Q56_2),
         Female = ifelse(Sex == "Female", 1, 0)) %>%
  select(!Sex)
# For 'work_type'
work_type <- model.matrix(~Q24-1, data = completed_data)
# For 'Ethnicity_simplified'
ethnicity_dummies <- model.matrix(~Ethnicity_simplified-1, data = completed_data)
# For 'Country_of_birth'
country_dummies <- model.matrix(~Country_of_birth-1, data = completed_data)
completed_data <- completed_data %>%
  bind_cols(ethnicity_dummies[,-c(ncol(ethnicity_dummies))], # Baseline: White
            country_dummies[,-c(ncol(country_dummies))], # Baseline: US
            work_type[,-c(ncol(work_type))]) %>% # Baseline: Salaried
  mutate(AnnualSalary = log1p(AnnualSalary)) %>%
  select(!c(Q24, Ethnicity_simplified, Country_of_birth))

# Factor Analysis
poverty1 <- fa(completed_data[,c(21:78)], nfactors = 1, n.rotations = 50,
              rotate = "oblimin", fm = "pa", scores = "tenBerge")
poverty2 <- fa(completed_data[,c(21:78)], nfactors = 2, n.rotations = 50,
              rotate = "oblimin", fm = "pa", scores = "tenBerge")
poverty3 <- fa(completed_data[,c(21:78)], nfactors = 3, n.rotations = 50,
              rotate = "oblimin", fm = "pa", scores = "tenBerge")
poverty4 <- fa(completed_data[,c(21:78)], nfactors = 4, n.rotations = 50,
              rotate = "oblimin", fm = "pa", scores = "tenBerge")
poverty5 <- fa(completed_data[,c(21:78)], nfactors = 5, n.rotations = 50,
              rotate = "oblimin", fm = "pa", scores = "tenBerge")

factor_scores <- factor.scores(completed_data[,c(21:78)], poverty3)

# Data for Analysis
variables <- names(df[,c(1:5,28,114:118,121:124)])
df <- df %>%
  select(variables) %>%
  bind_cols(factor_scores$scores)

```

## Data

Our experiment was conducted on the Prolific platform. In total, we acquired data from N = `r length(unique(df$participant))` participants, each of whom completed the modified experimental paradigm and revised questionnaires designed to explore the relationships between financial status, anxiety, and decision-making under uncertainty. Note that due to an error with Qualtrics, `r length(unique(df[is.na(df$SAI_post),]$participant))` individuals did not complete the final STAI questionnaire, so analyses that are dependent on the post-experiment anxiety measures will not include these participants.

### Demographics

Our experiment involved participants with various income levels and anxiety scores. @tbl-exp1-demographics displays the summary statistics for the available demographic variables for this cohort.

```{r}
#| label: tbl-exp1-demographics
#| tbl-cap: "Demographic and Psychological Characteristics of Prolific Participants from Experiment 1. SAI refers to the State Anxiety Index administered before the game."

# Function to aggregate data for a given platform
get_platform_data <- function(data) {
  data %>%
    summarise(
      Age_Min = min(Age, na.rm = TRUE),
      Age_25th = quantile(Age, 0.25, na.rm = TRUE),
      Age_Median = median(Age, na.rm = TRUE),
      Age_Mean = round(mean(Age, na.rm = TRUE), 1),
      Age_75th = quantile(Age, 0.75, na.rm = TRUE),
      Age_Max = max(Age, na.rm = TRUE),
      Income_Min = min(AnnualSalary, na.rm = TRUE),
      Income_25th = quantile(AnnualSalary, 0.25, na.rm = TRUE),
      Income_Median = median(AnnualSalary, na.rm = TRUE),
      Income_Mean = round(mean(AnnualSalary, na.rm = TRUE), 1),
      Income_75th = quantile(AnnualSalary, 0.75, na.rm = TRUE),
      Income_Max = max(AnnualSalary, na.rm = TRUE),
      SAI_Min = min(SAI_pre, na.rm = TRUE),
      SAI_25th = quantile(SAI_pre, 0.25, na.rm = TRUE),
      SAI_Median = median(SAI_pre, na.rm = TRUE),
      SAI_Mean = round(mean(SAI_pre, na.rm = TRUE), 1),
      SAI_75th = quantile(SAI_pre, 0.75, na.rm = TRUE),
      SAI_Max = max(SAI_pre, na.rm = TRUE)
    ) %>%
    gather(key = "Variable", value = "Value") %>%
    separate(Variable, into = c("Variable", "Statistic"), sep = "_") %>%
    spread(key = "Statistic", value = "Value")
}


combined_data <- get_platform_data(df)
# Replace NAs with empty values
combined_data[is.na(combined_data)] <- ""

# Create the table using the gt package
gt_table <- combined_data %>%
  gt(rowname_col = "Variable") %>%
  tab_header(
    title = "Demographics"
  ) %>%
  cols_label(
    Min = "Min",
    `25th` = "1st Qu.",
    Median = "Median",
    Mean = "Mean",
    `75th` = "3rd Qu.",
    Max = "Max"
  ) %>%
  fmt_number(rows = 2, decimals = 2) %>% 
  cols_move_to_start(columns = c("Min", "25th", "Median", "Mean", "75th", "Max"))

# Print the table
gt_table

```

@tbl-exp1-demo summarizes the demographics of the participants across the median-split groups. Regarding income, we observed a significant difference between high-income and low-income participants (p = 0.05). The mean income for the high-income group was approximately \$146,012.57, while for the low-income group, it was around \$17,571.42. This substantial income disparity within our sample reflects the economic diversity of the participants, ranging from those experiencing financial hardship to those with more substantial financial resources. For anxiety scores, as measured by the State-Trait Anxiety Inventory (STAI), we observed stark differences between the high- and low-anxiety groups, both pre- and post-experiment. Before the experiment, the mean State Anxiety score for the high-anxiety group was 48.38, compared to 39.97 for the low-anxiety group (p \< 0.001). Similar patterns were observed post-experiment, with a mean State Anxiety score of 48.81 for the high anxiety group and 38.23 for the low anxiety group (p \< 0.001). The Trait Anxiety scores followed a similar pattern, with a mean of 48.65 for the high-anxiety group and 39.43 for the low-anxiety group (p \< 0.001).

```{r}
#| label: tbl-exp1-demo
#| tbl-cap: "Descriptive statistics for income and anxiety scores"
#| tbl-subcap: "Mean values are provided for high- and low-income groups and high- and low-anxiety groups. The p-values from t-tests comparing high and low groups are also included."

df <- df %>%
  mutate(SAI_post = case_when(SAI_post == 0 ~ NA,
                              .default = SAI_post),
         TAI_post = case_when(TAI_post == 0 ~ NA,
                              .default = TAI_post))

# Calculate the median of AnnualSalary and Anxiety scores
median_salary <- median(df$AnnualSalary, na.rm = TRUE)
median_SAI_pre <- median(df$SAI_pre, na.rm = TRUE)
median_SAI_post <- median(df$SAI_post, na.rm = TRUE)
median_TAI_post <- median(df$TAI_post, na.rm = TRUE)

# Create two new columns to distinguish high-low income and high-low anxiety
df$IncomeGroup <- ifelse(df$AnnualSalary > median_salary, 'High', 'Low')
df$AnxietyGroup_SAI_pre <- ifelse(df$SAI_pre > median_SAI_pre, 'High', 'Low')
df$AnxietyGroup_SAI_post <- ifelse(df$SAI_post > median_SAI_post, 'High',
                                   ifelse(!is.na(df$SAI_post),'Low',NA))
df$AnxietyGroup_TAI_post <- ifelse(df$TAI_post > median_TAI_post, 'High',
                                   ifelse(!is.na(df$TAI_post),'Low',NA))

# Perform t-tests to compare means of high and low income groups and high and low anxiety groups
t_test_income <- t.test(df$AnnualSalary[df$IncomeGroup == 'High'], df$AnnualSalary[df$IncomeGroup == 'Low'])
t_test_anxiety_SAI_pre <- t.test(df$SAI_pre[df$AnxietyGroup_SAI_pre == 'High'], df$SAI_pre[df$AnxietyGroup_SAI_pre == 'Low'])
t_test_anxiety_SAI_post <- t.test(df$SAI_post[df$AnxietyGroup_SAI_post == 'High'], df$SAI_post[df$AnxietyGroup_SAI_post == 'Low'])
t_test_anxiety_TAI_post <- t.test(df$TAI_post[df$AnxietyGroup_TAI_post == 'High'], df$TAI_post[df$AnxietyGroup_TAI_post == 'Low'])

# Calculate mean of each group
mean_high_income <- mean(df$AnnualSalary[df$IncomeGroup == 'High'], na.rm = TRUE)
mean_low_income <- mean(df$AnnualSalary[df$IncomeGroup == 'Low'], na.rm = TRUE)
mean_high_anxiety_SAI_pre <- mean(df$SAI_pre[df$AnxietyGroup_SAI_pre == 'High'], na.rm = TRUE)
mean_low_anxiety_SAI_pre <- mean(df$SAI_pre[df$AnxietyGroup_SAI_pre == 'Low'], na.rm = TRUE)
mean_high_anxiety_SAI_post <- mean(df$SAI_post[df$AnxietyGroup_SAI_post == 'High'], na.rm = TRUE)
mean_low_anxiety_SAI_post <- mean(df$SAI_post[df$AnxietyGroup_SAI_post == 'Low'], na.rm = TRUE)
mean_high_anxiety_TAI_post <- mean(df$TAI_post[df$AnxietyGroup_TAI_post == 'High'], na.rm = TRUE)
mean_low_anxiety_TAI_post <- mean(df$TAI_post[df$AnxietyGroup_TAI_post == 'Low'], na.rm = TRUE)

# Reshape the results data frame
results_reshaped <- data.frame(
  Group = c("Income", "State Anxiety (pre-experiment)", "State Anxiety (post-experiment)", "Trait Anxiety"),
  Mean_High = c(mean_high_income, mean_high_anxiety_SAI_pre, mean_high_anxiety_SAI_post, mean_high_anxiety_TAI_post),
  Mean_Low = c(mean_low_income, mean_low_anxiety_SAI_pre, mean_low_anxiety_SAI_post, mean_low_anxiety_TAI_post),
  p_value = c(t_test_income$p.value, t_test_anxiety_SAI_pre$p.value, t_test_anxiety_SAI_post$p.value, t_test_anxiety_TAI_post$p.value)
)

# Format the table
gt(results_reshaped) %>%
  fmt_number(columns = c(Mean_High, Mean_Low), decimals = 2) %>%
  fmt_scientific(columns = c(p_value), decimals = 3, drop_trailing_zeros = FALSE) %>%
  tab_style(style = cell_borders(sides = "bottom"), locations = cells_body(rows = 4)) %>%
  cols_label(
    Group = "Group",
    Mean_High = "Mean High",
    Mean_Low = "Mean Low",
    p_value = "p-value"
  )

```

### Comprehensive Poverty Measures

To develop a more nuanced measure of poverty, we revisited our questionnaire to address variance issues. We contemplated expanding our sample to include more lower-income individuals or introducing new questions to elicit more variance. Our current iteration of comprehensive measurements is available in @sec-questionnaires.

We employed Factor Analysis, a statistical technique widely used to identify underlying relationships between measured variables. This method is particularly advantageous when dealing with scale compatibility issues, reducing many variables into fewer factors, and assisting in data interpretation, especially in large datasets.

Before proceeding with the Factor Analysis, we addressed the issue of missing data in our dataset, as it can significantly skew the results. We opted to use Multiple Imputation by Chained Equations (MICE), an approach that fills in missing values multiple times to create several complete datasets. The number of imputations was set to the overall percentage of missing cases in the dataset, ensuring a robust and comprehensive imputation strategy. We chose the Random Forest (rf) method for our imputations. Random Forest is a flexible, non-parametric method that can handle complex interactions and non-linear relationships between variables, making it suitable for datasets with complex structures and patterns, like ours.

Following this, we conducted a Factor Analysis on the complete datasets generated by the MICE procedure. This analysis aimed to uncover latent variables, or factors, that explain the variability among observed, correlated variables. This method is particularly useful in understanding the structure of correlations among the variables. For this specific analysis, we selected a subset of the survey data, including responses to questions regarding household conditions, work conditions, and food deprivation. We performed the factor analysis using principal axis factoring, a method of extraction primarily used when the analysis aims to identify latent constructs underlying the variables. It is a commonly used extraction method for psychological and social data. We also employed an oblique rotation method to facilitate the interpretation of the factors. Such a method simplifies and clarifies the data structure and allows for the factors to be correlated, which is a more relaxed and often more realistic assumption. Lastly, we used a correlation-preserving scoring method (TenBerge), which provides unbiased estimates of the factor scores.

@fig-new-pov-scree displays the scree plot, a graphical representation of the proportion explained variance for each factor in an exploratory factor analysis. It helps in determining the number of factors to retain in the analysis. The x-axis represents the number of factors, and the y-axis represents the proportion explained variance. The point at which the slope of the curve is leveling off (the "elbow") indicates the number of factors to retain. Although the elbow is a standard guideline, the decision to choose the number of factors should also consider the interpretability of the factors and the theoretical understanding of the measured constructs. In our case, the elbow in the scree plot suggested that two factors might be sufficient. However, upon further analysis, we found that a three-factor model provided a more meaningful and comprehensive understanding of poverty.

```{r}
#| label: fig-new-pov-scree
#| fig-cap: "Scree Plot for Factor Analysis. The graph delineates the proportion of variance explained by factor analysis models with 1 to 5 factors. Each line represents a distinct model, with the number of factors on the x-axis and the proportion of explained variance on the y-axis. Notably, the variance explained tends to plateau as the number of factors increases. Data imputation and transformation were executed before the factor analysis to refine the dataset for optimal factor extraction."

# Create a data frame with the proportion explained variance for each model
explained_variance <- data.frame(
  Factor = c(1, 2, 3, 4, 5),
  Model1 = c(poverty1$Vaccounted["Proportion Var",], NA, NA, NA, NA),
  Model2 = c(poverty2$Vaccounted["Proportion Var",], NA, NA, NA),
  Model3 = c(poverty3$Vaccounted["Proportion Var",], NA, NA),
  Model4 = c(poverty4$Vaccounted["Proportion Var",], NA),
  Model5 = c(poverty5$Vaccounted["Proportion Var",])
)

# Reshape the data frame to a long format
explained_variance_long <- gather(explained_variance, Model, Variance, -Factor)

# Plot the data
ggplot(explained_variance_long, aes(x = Factor, y = Variance, color = Model)) +
  geom_line() +
  geom_point() +
  labs(x = "Factor", y = "Proportion Explained Variance") +
  theme_minimal()


```

More specifically, the two-factor model included "Financial Hardship" and "Employment and Economic Status" factors, which, while simpler, did not capture the full complexity of our data. The four-factor model added two additional factors. The third factor was a "Housing Status" factor, and the fourth was the "physical condition of the home ."It included variables related to a leaking roof, broken windows, exposed electrical wires, and a malfunctioning stove or refrigerator. However, the four-factor model did not significantly improve model fit. After careful consideration and analysis, we have opted for the three-factor model as the most appropriate means of capturing the complexity of poverty in our data. This model balances complexity and interpretability, allowing for a comprehensive understanding of poverty's main dimensions while remaining concise and comprehensible. The three distinct factors that comprise this model---financial hardship, employment and economic status, and housing status---align with the multidimensional nature of poverty, which extends beyond mere income deprivation to encompass various other aspects of life.

Our three-factor model fits our data moderately well. The root mean square of residuals (RMSR), which measures the average residual correlation among variables, was 0.08, indicating a moderate fit. The Tucker-Lewis Index (TLI) was 0.475, below the desired threshold of 0.90, also suggesting only a moderate model fit. The root mean square error of approximation (RMSEA), which measures the discrepancy between the observed covariance matrix and the model covariance matrix per degree of freedom, was 0.073, with 90% confidence intervals between 0.069 and 0.08. This value suggests a reasonable error of approximation.

@tbl-exp1-pca displays the derived factors and their highest loadings. We interpret each factor as the following constructs:

1.  **Factor 1 (Factor 1)**: This factor had high loadings primarily on the 'Q48' series and 'Q50' questions, which indicate experiences of financial hardship and food insecurity within the past 12 months. We labeled Factor 1 as a "Food Deprivation" factor.

2.  **Factor 2 (Factor 2)**: The highest loadings on this factor were hours worked weekly and the participant's annual salary, suggesting that this factor might be related to the work and economic conditions of the respondents. There was a slight positive correlation between this factor and Factor 1. Given the nature of the variables that load heavily on this factor, we interpreted it as an "Employment and Economic Stability" factor.

3.  **Factor 3 (Factor 3)**: This factor had the highest loadings on questions related to home ownership. Thus, we interpret Factor 3 as a "Housing Deprivation" factor. This factor had a slight negative correlation with Factor 1.

```{r}
#| label: tbl-exp1-pca
#| tbl-cap: "Results from a Factor Analysis of our deprivation questionnaire"
#| tbl-subcap: "The extraction method was principal axis factoring with an oblique rotation with a minimizing criterion. Answers are coded such that higher values signify higher agreement with the given statements."

# 1. Identify top 5 questions for each of the first two PCs based on magnitude
top_questions_factor1 <- order(abs(poverty3$loadings[, 1]), decreasing = TRUE)[1:4]
top_questions_factor2 <- order(abs(poverty3$loadings[, 2]), decreasing = TRUE)[1:4]
top_questions_factor3 <- order(abs(poverty3$loadings[, 3]), decreasing = TRUE)[1:4]

# rownames(poverty3$loadings)[top_questions_factor1]
# rownames(poverty3$loadings)[top_questions_factor2]
# rownames(poverty3$loadings)[top_questions_factor3]
# From codebook:
top_questions <- c("In the last 12 months, were you ever hungry, but didn't eat, because there wasn't enough money for food?",
                   "In the last 12 months, how often did you or other adults in the household ever cut the size of your 
meals or skip meals because there wasn't enough food?",
                   "In the last 12 months, did you need food but couldn't afford to buy it or couldn't afford to go out to get it?",
                   "In the last 12 months, did you ever eat less than you felt you should because there wasn't 
enough money for food?",
                   "What was your approximate total family income last year?",
                   "Do you have a car, truck or other vehicle?",
                   "Are you neither salaried on your job nor paid by the hour?",
                   "Do you have a loan from a bank/credit union, such as for a car?",
                   "Are any of the following conditions present in your home? [A toilet, hot water heater, or other plumbing that doesn't work?]",
                   "Are any of the following conditions present in your home? [Exposed electrical wires?]",
                   "Are any of the following conditions present in your home? [Broken windows?]",
                   "Are any of the following conditions present in your home? [A furnace, boiler, or heating system that you can't count on?]")

# 2. Extract the loadings for these questions for both PCs
table_data <- data.frame(
  QuestionText = top_questions,
  `Factor1` = poverty3$loadings[c(top_questions_factor1, top_questions_factor2, top_questions_factor3), 1],
  `Factor2` = poverty3$loadings[c(top_questions_factor1, top_questions_factor2, top_questions_factor3), 2],
  `Factor3` = poverty3$loadings[c(top_questions_factor1, top_questions_factor2, top_questions_factor3), 3]
)

# 3. Build the table
# Create the table with row groups and additional column header
# Add a grouping column for row groups
table_data$Group <- c(rep("Factor 1: Food Deprivation", 4),
                      rep("Factor 2: Employment and Economic Stability", 4),
                      rep("Factor 3: Housing Deprivation", 4))

# Create the table
table_output <- gt(table_data, groupname_col = "Group") %>%
  cols_label(
    QuestionText = "",
    `Factor1` = "Factor 1",
    `Factor2` = "Factor 2",
    `Factor3` = "Factor 3"
  ) %>%
  fmt_number(
    columns = 2:4,
    decimals = 2
  ) %>%
  tab_spanner(
    label = "Loadings",
    columns = 2:4
  )


table_output

```


### Zip Code Poverty Measures

Similar to our pilot study, we validated participants' income reports by analyzing economic data from their ZIP codes. We used the American Community Survey to obtain poverty and median income measures, allowing us to analyze the impact of geographic and community-level factors on individual experiences of poverty.

```{r}
#| label: fig-exp1-zip-poverty
#| fig-cap: "Income and Poverty Levels by ZIP Code"

# Load the ip to zip code data
ip2zip <- read_csv("data/ZIPcode/ip2zip_exp1.csv") %>%
  distinct()

# Merge the demographics data with the ip to zip code data
df <- df %>%
  left_join(ip2zip, by = c("IPAddress" = "IP"))

# Load the poverty data
poverty <- read_csv("data/ZIPcode/ACSST5Y2019.S1701_data_with_overlays_2021-12-21T174024.csv")

# Process the poverty data
poverty <- poverty %>%
  dplyr::select(NAME, S1701_C03_001E) %>%
  mutate(ZIP = as.numeric(str_sub(NAME, start= -5))) %>%
  dplyr::select(-NAME)

# Merge the demographics data with the poverty data
df <- df %>%
  left_join(poverty, by = "ZIP")

# Load the income data
income <- read_csv("data/ZIPcode/ACSST5Y2019.S1903_data_with_overlays_2021-11-16T180635.csv")

# Process the income data
income <- income %>%
  dplyr::select(NAME, S1903_C03_001E) %>%
  mutate(ZIP = as.numeric(str_sub(NAME, start= -5))) %>%
  dplyr::select(-NAME)

# Merge the demographics data with the income data and remove the IP column for privacy
df <- df %>%
  dplyr::select(-c("IPAddress")) %>%
  left_join(income, by = "ZIP") %>%
  mutate(
    zip_poverty = as.numeric(S1701_C03_001E),
    zip_income = as.numeric(S1903_C03_001E)
  ) %>%
  select(!c(S1701_C03_001E, S1903_C03_001E))

# Add a new column for the transformed poverty level
df$zip_poverty_log <- log1p(df$zip_poverty)
# Define the colors and breakpoints
colors <- c("blue","blue","white", "red","red")
breaks <- quantile(df$zip_poverty_log, probs = c(0, 0.5, 1), na.rm = TRUE)
# Create a color gradient function
color_gradient <- colorRampPalette(colors)
# Get the US map data
us_map <- map_data("state")
# Generate the plot
ggplot() +
  # Draw the map
  geom_polygon(data = us_map, aes(x = long, y = lat, group = group), fill = "white", color = "black") +
  # Add the points
  geom_point(data = df[!is.na(df$zip_poverty),],
             aes(x = Long, y = Lat, size = zip_income, color = zip_poverty_log)) +
  # Define the color scale
  scale_color_gradientn(colors = color_gradient(100), 
                        breaks = breaks, 
                        labels = round(expm1(breaks), 2),
                        guide = "colorbar") +
  # Define the size scale
  scale_size_continuous(range = c(1, 5)) +
  # Add labels for the color and size scales
  labs(color = "Poverty Level", size = "Median Income") +
  # Set the plot theme
  theme_minimal() +
  # Remove the grid lines
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.text = element_blank(), 
        axis.ticks = element_blank(),
        # Move the legends to the bottom
        legend.position = "bottom") +
  # Remove the axis labels
  labs(x = "", y = "") +
  # Adjust the legends
  guides(color = guide_colorbar(title.position = "top", title.hjust = 0.5),
         size = guide_legend(title.position = "top", title.hjust = 0.5))

```

## Results

### Task Performance

We analyzed participants' task selection patterns, focusing on Important, Hard, and Urgent tasks, and computed the frequency of each task type selection for every participant. As shown in @tbl-exp1-totalpoints, the proportion of Important tasks selected had a significant positive association with the total points accrued by participants. Specifically, for every ten percentage point increase in the selection of Important tasks, participants' total scores increased by approximately 1.6 points (Estimate = 18.086, p \< .01). In contrast, the selection frequencies of Hard and Urgent tasks did not significantly predict the total points (Estimate for Hard tasks = 7.442, p \> .05; Estimate for Urgent tasks = -20.245, p \< .001). Control variables, including demographic factors, STAI scores, income levels, and platform, were incorporated into the regression model. However, none of these variables significantly correlated with the total points. The regression model explained about 20.24% of the variance in total points, with an Adjusted R-squared value of 0.448 in the primary model. The model's overall fit was statistically significant (F(4,85) = 19.047, p \< .001).

```{r, results='asis'}
#| label: tbl-exp1-totalpoints
#| tbl-cap: "Regression analysis of total points on participants' task choice behavior and personal characteristics"
#| tbl-subcap: "The predictors include the percentage of choices where Important, Hard, and Urgent tasks were chosen, participants' pre- and post-experiment STAI scores, and three poverty-related factors."

# Define a function to create the chosen and not_chosen variables
create_choice_vars <- function(game_data) {
  game_data <- game_data %>%
    mutate(chosen_i = ifelse(choice == 1, i1, i2),
           chosen_e = ifelse(choice == 1, e1, e2),
           chosen_u = ifelse(choice == 1, u1, u2),
           not_chosen_i = ifelse(choice == 1, i2, i1),
           not_chosen_e = ifelse(choice == 1, e2, e1),
           not_chosen_u = ifelse(choice == 1, u2, u1))
  
  return(game_data)
}

# Define a function to compute choice percentages
compute_choice_percentages <- function(game_data) {
  game_data %>%
    mutate(
      urgent_chosen = ifelse(chosen_u > not_chosen_u, 1, 0),
      important_chosen = ifelse(chosen_i > not_chosen_i, 1, 0),
      effort_chosen = ifelse(chosen_e > not_chosen_e, 1, 0)
    ) %>%
    group_by(participant) %>%
    summarise(perc_urgent_chosen = mean(urgent_chosen, na.rm = TRUE),
              perc_important_chosen = mean(important_chosen, na.rm = TRUE),
              perc_effort_chosen = mean(effort_chosen, na.rm = TRUE))
}

# Define a function to compute total points for a participant
compute_total_points <- function(game_data) {
  game_data %>%
    group_by(participant) %>%
    summarise(total_points = max(points))
}

# Filter out rows where CSV_Data is NULL
df <- df %>% filter(!sapply(CSV_Data, is.null))

# Apply the function to each game data nested in the CSV_Data column
df$CSV_Data <- map(df$CSV_Data, create_choice_vars)

# Apply this function to each participant's game data
choice_percentages_list <- map(df$CSV_Data, compute_choice_percentages)
# Combine all the results into a single data frame
choice_percentages_df <- bind_rows(choice_percentages_list)

# Apply this function to each participant's game data
total_points_list <- map(df$CSV_Data, compute_total_points)
# Combine all the results into a single data frame
total_points_df <- bind_rows(total_points_list)
# Join the total_points_df with choice_percentages_df
performance <- inner_join(total_points_df %>% ungroup(),
                          choice_percentages_df %>% ungroup(),
                          by = "participant") %>%
  group_by(participant) %>%
  summarize(
    total_points = mean(total_points),
    perc_urgent_chosen = mean(perc_urgent_chosen),
    perc_important_chosen = mean(perc_important_chosen),
    perc_effort_chosen = mean(perc_effort_chosen)
  )

# Join the performance data frame with the main data frame
df <- inner_join(df, performance, by = c("PROLIFIC_PID" = "participant"))

# Run regression
# reg_total1 <- lm(total_points ~ perc_important_chosen + 
#                          perc_effort_chosen + perc_urgent_chosen,
#                        data = df)
reg_total1 <- lm(total_points ~ SAI_pre +
                   perc_important_chosen + 
                   perc_effort_chosen +
                   perc_urgent_chosen,
                       data = df)
reg_total2 <- lm(total_points ~ PA1 + PA2 + PA3 +
                   perc_important_chosen + 
                   perc_effort_chosen +
                   perc_urgent_chosen,
                       data = df)
reg_total3 <- lm(total_points ~ SAI_pre +
                         PA1 + PA2 + PA3 +
                   perc_important_chosen + 
                   perc_effort_chosen +
                   perc_urgent_chosen,
                       data = df)

stargazer(reg_total1, reg_total2, reg_total3,
          type = "latex", 
          header = FALSE, 
          align = TRUE,
          covariate.labels = c("SAI (Pre)",
                               "Factor 1",
                               "Factor 2",
                               "Factor 3",
                               "Important tasks chosen",
                               "Hard tasks chosen",
                               "Urgent tasks chosen"),
          dep.var.labels = c("Total Points"),
          star.cutoffs = c(.05, .01, .001), 
          star.char = c("*", "**", "***"),
          column.sep.width = "10pt")

```

### Trade-off Decisions

We subsequently examined participants' task selection during trade-off scenarios, as delineated in the pilot experiment. We aimed to identify potential behavioral variances driven by socioeconomic and psychological determinants by evaluating these averages. @fig-exp1-tradeoff delineates the choice proportions influenced by income and anxiety levels.

In Panel (a), participants were categorized into either High or Low factor groups. Factor 1's choice proportions stood at 55.8% for the High group and 54.4% for the Low group. Factor 2 exhibited proportions of 54.7% (High) and 55.5% (Low), while for Factor 3, the figures were 55.3% (High) and 54.9% (Low). Notably, the disparities in choice proportions across these categories were marginal and lacked statistical significance, implying that income tiers had a limited impact on task selection behaviors.

Panel (b) delves into participants' anxiety levels pre and post the experiment. For post-experiment state anxiety, the High group manifested a choice proportion of 57.6%, in contrast to the Low group's 54.1%. Pre-experiment state anxiety revealed 56.7% (High) and 53.5% (Low). Meanwhile, trait anxiety evaluations yielded 56.3% (High) and 55.1% (Low). These distinctions, too, were statistically non-significant.

```{r}
#| label: fig-exp1-tradeoff
#| fig-cap: "Choice proportions by income and anxiety"
#| fig-subcap:
#|   - "Income"
#|   - "Anxiety"
#| layout-ncol: 2

# Define a function to create the huli variable
create_huli_var <- function(game_data) {
  game_data <- game_data %>%
    mutate(tradeoff = ifelse(u1 > u2
                         & i1 < i2, 1,
                         ifelse(u1 < u2
                                & i1 > i2, 1,
                                ifelse(is.na(i1) | is.na(i2), 0,
                                       0))),
           urgent_choice = case_when(tradeoff == 0 ~ NA,
                                     chosen_u == 1 ~ 1,
                                     chosen_u == 0 ~ 0))
  
  return(game_data)
}

# Apply the function to each game data nested in the CSV_Data column
df$CSV_Data <- map(df$CSV_Data, create_huli_var)

# Apply this function to each participant's game data
tradeoff_list <- map(df$CSV_Data, function(x) {
  x %>%
    group_by(participant) %>%
    filter(!is.na(urgent_choice)) %>%
    summarize(urgent_proportion = mean(urgent_choice))
})
# Combine all the results into a single data frame
tradeoff_df <- bind_rows(tradeoff_list) %>%
  group_by(participant) %>%
  summarize(urgent_proportion = mean(urgent_proportion))

# Join the tradeoff_df with the main data frame
df <- inner_join(df, tradeoff_df, by = c("PROLIFIC_PID" = "participant"))

median_PA1 <- median(df$PA1, na.rm = TRUE)
median_PA2 <- median(df$PA2, na.rm = TRUE)
median_PA3 <- median(df$PA3, na.rm = TRUE)
# Create two new columns to distinguish high-low income and high-low anxiety
df$PAGroup1 <- ifelse(df$PA1 < median_PA1, 'High', 'Low')
df$PAGroup2 <- ifelse(df$PA2 > median_PA2, 'High', 'Low')
df$PAGroup3 <- ifelse(df$PA3 < median_PA3, 'High', 'Low')

# Pivot the data to longer format
df_long <- df %>%
  pivot_longer(cols = starts_with("PAGroup"),
               names_to = "PovertyFactor",
               values_to = "PovertyGroup")

# Group by PovertyFactor and PovertyGroup, and create the plot
df_long %>%
  group_by(PovertyFactor, PovertyGroup) %>%
  filter(!is.na(PovertyGroup)) %>%
  summarise(total = sum(!is.na(urgent_proportion)),
            mean_huli  = mean(urgent_proportion, na.rm = TRUE)) %>%
  mutate(se = sqrt((mean_huli * (1 - mean_huli)) / total)) %>%
  
  ggplot(aes(PovertyFactor, mean_huli, fill = as.factor(PovertyGroup)),
         alpha = 0.7) + 
  geom_col(position = "dodge") +
  labs(title = "Choice Frequency of Urgent vs Non-urgent Tasks",
       x = "",
       y = "Frequency of urgent/not important choices",
       fill = "Stability") +
  scale_x_discrete(labels = c("PAGroup1" = "Food Stability",
                              "PAGroup2" = "Employment Stability",
                              "PAGroup3" = "Housing Stability")) +
  scale_fill_brewer() +
  theme_minimal() +
  geom_errorbar(aes(ymin = mean_huli - se, ymax = mean_huli + se),
                width = 0.4,
                alpha = 0.9,
                position = position_dodge(0.9)) + 
  geom_hline(yintercept = 0.5, linetype = 2)


# Pivot the data to longer format
df_long <- df %>%
  pivot_longer(cols = starts_with("AnxietyGroup"),
               names_to = "AnxietyType",
               values_to = "AnxietyGroup")
# Group by AnxietyType and AnxietyGroup, and create the plot
df_long %>%
  group_by(AnxietyType, AnxietyGroup) %>%
  filter(!is.na(AnxietyGroup)) %>%
  summarise(total = sum(!is.na(urgent_proportion)),
            mean_huli  = mean(urgent_proportion, na.rm = TRUE)) %>%
  mutate(se = sqrt((mean_huli * (1 - mean_huli)) / total)) %>%
  
  ggplot(aes(AnxietyType, mean_huli, fill = AnxietyGroup),
         alpha = 0.7) + 
  geom_col(position = "dodge") +
  labs(x = "",
       y = "Frequency of urgent/not important choices",
       fill = "Anxiety Level") +
  scale_x_discrete(labels = c("AnxietyGroup_SAI_pre" = "State Anxiety Pre",
                              "AnxietyGroup_SAI_post" = "State Anxiety Post",
                              "AnxietyGroup_TAI_post" = "Trait Anxiety Post")) +
  scale_fill_brewer() +
  theme_minimal() +
  geom_errorbar(aes(ymin = mean_huli - se, ymax = mean_huli + se),
                width = 0.4,
                alpha = 0.9,
                position = position_dodge(0.9)) + 
  geom_hline(yintercept = 0.5, linetype = 2)

```

### General Urgency Bias

```{r merge datasets Exp1}

# Function to add participant-level data to each trial dataframe
add_participant_data <- function(trial_data) {
  trial_data %>%
    left_join(participant_data, by = c('participant' = 'PROLIFIC_PID'))
}

# Convert df (excluding column 14) to a data frame and ensure participant ID is unique
participant_data <- df[,-c(11)] %>%
  group_by(PROLIFIC_PID) %>%
  summarise(across(where(~ !is.numeric(.)), ~ first(na.omit(.))), 
            across(where(is.numeric), ~ mean(., na.rm = TRUE)))

# Use lapply to add participant data to each data frame in df$CSV_Data
df_list <- lapply(df$CSV_Data, add_participant_data)

# Combine the data frames in df_list
df_combined <- bind_rows(df_list) %>%
  group_by(participant) %>%
  mutate(block = ceiling(row_number() / 40),  # Identifies the block number for each trial
         round = row_number() - 40 * (block - 1))  # Reset the round number for each block

# write_csv(df_combined, file = "data/Exp1/df.csv")

```

This section investigates the urgency bias or the tendency for individuals to prioritize urgent tasks over others. @tbl-exp1-urgencypoverty displays our analysis of the interplay between this bias and various socioeconomic parameters to elucidate their contributory roles.

Model 1 assesses the influence of deprivation across three critical life domains. The data reveals a significant negative relationship between food deprivation and urgency bias, suggesting that individuals facing food scarcity may be less likely to prioritize urgent tasks. However, neither job stability nor housing deprivation significantly impacted this bias.

Models 2 and 3 explore the associations between area-level median income and poverty levels with urgency bias, respectively. The results indicate a marginally significant positive relationship between median income and urgency bias. Conversely, a notable negative correlation between area-level poverty and the bias arises, suggesting that individuals from higher poverty regions may exhibit a reduced urgency bias.

Model 4 delves into the potential influence of pre-experiment anxiety levels on the urgency bias. The findings do not establish a significant relationship, suggesting pre-experiment anxiety levels do not significantly sway an individual's urgency bias.

We accounted for control variables in all models, including the total number of Prolific approvals (reflecting platform experience), gender, age, and attributes related to the selected and unselected tasks.

```{r, results='asis'}
#| label: tbl-exp1-urgencypoverty
#| tbl-cap: "Urgency Bias Regression Models"
#| tbl-subcap: "Logistic regression models assessing the likelihood of selecting an urgent task, with individual and round-specific random effects. Covariates include age, education, points, attributes of the chosen and unchosen tasks, and the round number. Coefficients denote the log odds shift in opting for an urgent task corresponding to a unit alteration in the predictor. State Anxiety (SAI) data limited to pre-experiment questionnaire."

# df_combined <- read_csv("data/Exp1/df.csv")
df_combined <- df_combined %>%
  mutate(round = round + 40 * (block - 1),
         complete = if_else(is.na(SAI_post), 0, 1),
         zip_income_log = log1p(zip_income))
df_combined <- pdata.frame(df_combined, index = c("participant", "round"))

# Function to fit the model
fit_model <- function(formula, data) {
  pglm(formula = formula,
       data = data,
       effect = "twoways",
       family = binomial('logit'),
       model = "random")
}
# Function to calculate observations
get_gof_rows <- function(model) {
  values <- model$model %>%
    group_by(pick(2, Total_approvals)) %>%
    summarise(blocks = max(block), total = n(), trials = n() / max(block)) %>%
    ungroup() %>%
    summarise(N = n(), max = max(trials), min = min(trials), mean = mean(trials))
  Participants <- values$N
  Trials <- paste0(values$min, "-", values$max, " (M = ", round(values$mean,1),")")
  BIC <- AIC(model, k = log(nrow(model$model)))
  return(list(Participants = Participants, Trials = Trials, BIC = BIC))
}

# Define formulas
formulas <- list(
  chosen_u ~ PA1 + PA2 + PA3 + block + complete +
    Total_approvals + RoundLeft + Age + Sex + points +
    chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u,
  chosen_u ~ zip_income_log + block + complete +
    Total_approvals + RoundLeft + Age + Sex + points +
    chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u,
  chosen_u ~ zip_poverty + block + complete +
    Total_approvals + RoundLeft + Age + Sex + points +
    chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u,
  chosen_u ~ SAI_pre + block + complete +
    Total_approvals + RoundLeft + Age + Sex + points +
    chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u
)
# Fit models
models <- lapply(formulas, fit_model, data = df_combined)

# Generate the table
gof_list <- lapply(models, get_gof_rows)
final_gof_list <- list(
  Participants = sapply(gof_list, `[[`, "Participants"),
  Trials = sapply(gof_list, `[[`, "Trials"),
  BIC = sapply(gof_list, `[[`, "BIC")
)
custom_coef <- list("PA1" = "Food Deprivation",
                    "PA2" = "Job Stability",
                    "PA3" = "Housing Deprivation",
                    "zip_income_log" = "Log(ZIP Median Income)",
                    "zip_poverty" = "ZIP Poverty Level",
                    "SAI_pre" = "State Anxiety")
texreg(lapply(models, function(x) {
  texreg::extract(x, include.aic = FALSE, include.loglik = FALSE)
  }),
  custom.model.names = c("(1)","(2)","(3)","(4)"),
  custom.header = list("Prob(Chosen Task Urgency = High)" = 1:4),
  stars = c(0.001, 0.01, 0.05, 0.1),
  custom.coef.map = custom_coef,
  custom.gof.rows = final_gof_list)

```

### Accuracy

In this section, we extend the methodology introduced in @sec-pilotaccuracy to evaluate how closely participants' task choices align with the optimal decision-making protocol we previously established.

```{r}
#| label: exp1-accuracy-code

exp1_stan <- readRDS("~/poverty-priority-queue/Models/dyn_prog/hierarchical-results.RDS")
# Extracting parameter values
samples <- exp1_stan$draws()
params <- summary(samples)

# Extracting costH values by matching variable names
costH_names <- grep("^costH\\[[0-9]+\\]$", params$variable, value = TRUE)
costH_values <- params[params$variable %in% costH_names, 2]

data_list <- list()
# Read each dataset and store it in the list
data_list$K <- h5read(file = "./Models/dyn_prog/data.h5", name = "K")
data_list$N <- h5read(file = "./Models/dyn_prog/data.h5", name = "N")
data_list$P <- h5read(file = "./Models/dyn_prog/data.h5", name = "P")
data_list$T <- h5read(file = "./Models/dyn_prog/data.h5", name = "T")
data_list$choice <- t(h5read(file = "./Models/dyn_prog/data.h5", name = "choice"))
data_list$effort <- t(h5read(file = "./Models/dyn_prog/data.h5", name = "effort"))
data_list$participants <- h5read(file = "./Models/dyn_prog/data.h5", name = "participants")
data_list$reward <- t(h5read(file = "./Models/dyn_prog/data.h5", name = "reward"))
data_list$state <- t(h5read(file = "./Models/dyn_prog/data.h5", name = "state"))
data_list$transition_probs <- h5read(file = "./Models/dyn_prog/data.h5", name = "transition_probs")
data_list$transition_probs <- aperm(data_list$transition_probs, c(3, 1, 2))
data_list$grainsize <- round(data_list$N/4)
data_list$slices_n <- seq_len(data_list$N)

# Mapping the STAN variables to the new ones
choice_best <- matrix(0, data_list$N, data_list$T)

for (i in c(1:data_list$N)) {
  EVs <- array(0, dim = c(2, data_list$T, data_list$K))
  common_cost <- as.numeric(costH_values[data_list$participants[i],])
  
  # Calculate the EV for the last round
  EVs[1, T, ] <- data_list$reward[, 1] - data_list$effort[, 1] * common_cost
  EVs[2, T, ] <- data_list$reward[, 2] - data_list$effort[, 2] * common_cost
  
  # Loop through the time and states, calculating the EVs for each choice
  for (t in 1:(data_list$T - 1)) {
    EVs[1, data_list$T - t,] <-
      data_list$transition_probs[1] %*% EVs[1, data_list$T - t + 1, ] + data_list$reward[, 1] - data_list$effort[, 1] * common_cost
    EVs[2, data_list$T - t,] <-
      data_list$transition_probs[2] %*% EVs[2, data_list$T - t + 1, ] + data_list$reward[, 2] - data_list$effort[, 2] * common_cost
  }
  
  for (t in 1:data_list$T) {
    s <- data_list$state[i, t] # Current state
    ev1 <- EVs[1, t, s] # EV for choice 1
    ev2 <- EVs[2, t, s] # EV for choice 2
    
    # Determine the best choice
    choice_best[i, t] <- ifelse(ev1 > ev2, 1,
                                ifelse(ev1 < ev2, 2,
                                       ifelse(ev1 == ev2, 0, NA)))
  }
}

#####  Accuracy of all trials
comparison <- (data_list$choice == choice_best | choice_best == 0)
Accuracy <- as.data.frame(rowMeans(comparison, na.rm=T))
Accuracy <- cbind(Accuracy, data_list$participants)
## Get participant ID
# Read the HDF5 file
participant_ids <- h5read('Models/dyn_prog/participant_mapping.h5', 'participant_ids')
indices <- h5read('Models/dyn_prog/participant_mapping.h5', 'indices')
# Convert the participant_ids to characters if they are stored as bytes
# participant_ids <- sapply(participant_ids, function(x) rawToChar(as.raw(x)))
# Create a data frame from the HDF5 data
participant_mapping <- data.frame(participant = participant_ids,
                                  cost = costH_values$mean,
                                  index = indices)

```

```{r}
#| label: fig-exp1costs
#| fig-cap: "Histogram of Means of Estimated Costs Parameters per Participant, with the mean of the hyperparameter  depicted. Note that the lower cost was assumed to be 0."

# Compute the mean of the hyperparameter (mu_cost)
mean_hyper_cost <- params$mean[2]

# Create a density plot for the individual participant parameters (cost)
ggplot(costH_values, aes(x = mean)) +
  geom_density(alpha = 0.5, fill = "steelblue") +
  geom_segment(aes(x = mean_hyper_cost, y = 0,
                   xend = mean_hyper_cost,
                   yend = max(density(costH_values$mean)$y)),
               color = "black", linetype = "dashed", size = 0.5) +
  theme_minimal() +
  custom_theme +
  labs(
    y = "Density",
    title = "Density of Individual Parameters with Means"
  ) +
  annotate("text", x = mean_hyper_cost, y = 0,
           label = expression(hat(mu)["cost"]),
           vjust = 0.6, color = "black", parse = TRUE)

```

```{r}
#| label: fig-exp1-accuracy-results
#| fig-cap: "Participant Accuracy by Factor 1 and Anxiety"
#| fig-subcap:
#|   - "Factor 1"
#|   - "Anxiety"
#| layout-ncol: 2

# Join with the existing data frame
Accuracy_exp1 <- Accuracy %>%
  left_join(participant_mapping,
            by = c('data_list$participants' = 'index')) %>%
  # Create the Accuracy column
  select(!`data_list$participants`) %>%
  rename(Accuracy = `rowMeans(comparison, na.rm = T)`) %>%
  left_join(df_combined %>%
              group_by(participant) %>%
              summarise(food = first(PA1),
                        stai = first(SAI_pre)), by = "participant")

# Plot no 1 : Participant Accuracy by Income
ggplot(Accuracy_exp1, aes(x = food, y = Accuracy)) +
  geom_point(color = "steelblue", size = 3) +
  stat_smooth(method = loess, color = "red", size = 1) +
  geom_label(x = 1, y = 0.75,
             label = paste("Correlation:",
                           rd(cor.test(Accuracy_exp1$food,
                                       Accuracy_exp1$Accuracy,
                                       method = "spearman")$estimate, 2)),
             fill = "white", color = "black", label.padding = unit(0.35, "lines")) +
  labs(x = "Food Deprivation", y = "Accuracy",
       title = "Participant Accuracy by Food Deprivation") +
  custom_theme

# Plot no 2: Participant Accuracy by STAI (State-Trait Anxiety Inventory)
ggplot(Accuracy_exp1, aes(x = stai, y = Accuracy)) +
  geom_point(color = "steelblue", size = 3) +
  stat_smooth(method = loess, color = "red", size = 1) +
  geom_label(x = 35, y = 0.8,
             label = paste("Correlation:",
                           rd(cor.test(Accuracy_exp1$stai,
                                       Accuracy_exp1$Accuracy,
                                       method = "spearman")$estimate, 2)),
             fill = "white", color = "black", label.padding = unit(0.35, "lines")) +
  labs(x = "SAI (State Anxiety Inventory)", y = "Accuracy",
       title = "Participant Accuracy by State Anxiety") +
  custom_theme

```

```{r, results='asis'}
#| label: tbl-exp1-accuracy
#| tbl-cap: "Regression analysis of accuracy on participants' choice behavior and demographic variables"
#| tbl-subcap: "Logistic regression models assessing the likelihood of selecting the optimal task, with individual and round-specific random effects. Covariates include age, education, points, and attributes of the chosen and unchosen tasks. Coefficients denote the log odds shift in opting for the optimal task corresponding to a unit alteration in the predictor. State Anxiety (SAI) data limited to pre-experiment questionnaire."

# Instead of computing the row means, we'll melt the comparison matrix to long format
long_comparison <- reshape2::melt(comparison %>%
                                    bind_cols(index = data_list$participants) %>%
                                    group_by(index) %>%
                                    mutate(block = row_number()) %>%
                                    ungroup(),
                                  id.vars = c("index", "block"),
                                  variable.name = "Trial",
                                  value.name = "Accuracy") %>%
  left_join(participant_mapping, by = c('index')) %>%
  select(participant, block, Trial, Accuracy) %>%
  mutate(Trial = as.numeric(Trial))

# The resulting df_combined dataframe will now have an Accuracy column that indicates 
# whether the choice made in each trial was optimal (1) or not (0).
df_accuracy <- df_combined %>%
  mutate(Trial = as.numeric(round)) %>%
  left_join(long_comparison, by = c("participant", "block", "Trial"))

# Function to fit the model
fit_model <- function(formula, data) {
  pglm(formula = formula,
       data = data,
       effect = "twoways",
       family = binomial('logit'),
       model = "random")
}

get_gof_rows <- function(model) {
  values <- model$model %>%
    group_by(pick(2, Age, Sex, Total_approvals)) %>%
    summarise(blocks = ceiling(n() / 40), total = n(), trials = n() / ceiling(n() / 40)) %>%
    ungroup() %>%
    summarise(N = n(), max = max(trials), min = min(trials), mean = mean(trials))
  Participants <- values$N
  Trials <- paste0(values$min, "-", values$max, " (M = ", round(values$mean,1),")")
  BIC <- AIC(model, k = log(nrow(model$model)))
  return(list(Participants = Participants, Trials = Trials, BIC = BIC))
}

# Define formulas
formulas <- list(
  Accuracy ~ PA1 + PA2 + PA3 + Age + Sex +
    Total_approvals + RoundLeft + complete + points +
    chosen_i + chosen_e + chosen_u +
    not_chosen_i + not_chosen_e + not_chosen_u,
  Accuracy ~ zip_income_log + Age + Sex +
    Total_approvals + RoundLeft + complete + points +
    chosen_i + chosen_e + chosen_u +
    not_chosen_i + not_chosen_e + not_chosen_u,
  Accuracy ~ zip_poverty + Age + Sex +
    Total_approvals + RoundLeft + complete + points +
    chosen_i + chosen_e + chosen_u +
    not_chosen_i + not_chosen_e + not_chosen_u,
  Accuracy ~ SAI_pre + Age + Sex +
    Total_approvals + RoundLeft + complete + points +
    chosen_i + chosen_e + chosen_u +
    not_chosen_i + not_chosen_e + not_chosen_u
)
# Fit models
models <- lapply(formulas, fit_model, data = df_accuracy)

# Generate the table
gof_list <- lapply(models, get_gof_rows)
final_gof_list <- list(
  Participants = sapply(gof_list, `[[`, "Participants"),
  Trials = sapply(gof_list, `[[`, "Trials"),
  BIC = sapply(gof_list, `[[`, "BIC")
)
custom_coef <- list("PA1" = "Food Deprivation",
                    "PA2" = "Job Stability",
                    "PA3" = "Housing Deprivation",
                    "zip_income_log" = "Log(ZIP Median Income)",
                    "zip_poverty" = "ZIP Poverty Level",
                    "SAI_pre" = "State Anxiety")
texreg(lapply(models, function(x) {
  texreg::extract(x, include.aic = FALSE, include.loglik = FALSE)
  }),
  custom.model.names = c("(1)","(2)","(3)","(4)"),
  custom.header = list("Prob(Chosen Task is Optimal)" = 1:4),
  stars = c(0.001, 0.01, 0.05, 0.1),
  custom.coef.map = custom_coef,
  custom.gof.rows = final_gof_list)

```

We employ a hierarchical Bayesian model to estimate the cost parameter for each participant, as illustrated in @fig-costs. In contrast to the pilot experiment, we set the cost of low-effort tasks to zero. Once estimated, these individualized cost parameters allowed us to compute the optimal choices for every state through a backward induction process.

@fig-exp1-accuracy-results offers a granular view of this alignment. A distinct dot represents each participant. The y-axis quantifies the accuracy of their choices, represented as the percentage of correct decisions made throughout the experiment. Simultaneously, the x-axes capture the scores for Factor 1 and the pre-experiment State Anxiety Index.

A striking observation is the invariance of accuracy across varying income and anxiety levels. This result suggests that these socio-economic and psychological factors might not be pivotal in influencing task selection accuracy in this context. @tbl-exp1-accuracy displays four other models that further corroborate this observation. Four distinct random effects logistic regression models evaluate the optimality of each participant's choice. These models incorporate a range of regressors, including the derived factors, individual anxiety metrics, and area-level economic indicators such as ZIP code poverty and median income levels. None of the results from these models reached statistical significance.

# Discussion

Our findings underscore the critical importance of prioritization strategies in task performance. Despite the intuitive appeal of tending to urgent matters, our data suggest that focusing on important tasks yielded superior performance outcomes.

The trade-off decision analysis reveals a nuanced relationship between urgency, importance, income, and anxiety. The observed preference for urgent tasks among low-income and high-anxiety individuals adds a quantitative dimension to existing literature, offering insights into the underlying mechanisms that drive decision-making. The integration of graphical representations and statistical tests strengthens the validity of these findings, contributing to a deeper understanding of human behavior in task prioritization.

We review the Key Results from the first pages: urgent choices do seem to be above 50% for key groups, but the differences-in-differences across income and anxiety levels are not significant.

Again, people might not mind leaving the High Importance task undone. This is what some friends have called the "insurance ice cream." That is, if I leave this High Importance task in my queue, I can use it when I get a task that is High Effort but Low Urgency. Using multiple regression models, controlling for various factors adds robustness to our findings. It sets the stage for future research to delve deeper into the underlying mechanisms that drive urgency bias. The potential multicollinearity and the non-significance of some variables also highlight the phenomenon's complexity, suggesting that further studies with larger sample sizes and more refined measures may be warranted to unravel the intricacies of urgency bias.

It is worth noting that this approach, while rigorous, makes certain assumptions about the nature of the decision-making process. For instance, it assumes that individuals are utility maximizers and have perfect knowledge of the task structure. While these assumptions are standard in the decision-making literature, they may not hold in all contexts.

### Intergenerational Poverty

People likely learn how to estimate transition probabilities from parents and peers. If people in this support network are not themselves proficient in estimating, then the individual is left to their own devices. Further, affective states can be passed down generations (e.g., anxiety, stress, depression).

# Future Directions: Experiment 2

## Methodology

### Poverty Measurements

Future research could explore additional dimensions and employ other statistical methods, such as fuzzy set theory, which has been shown to produce reliable results in poverty analysis ([Comparison of weighted and unweighted methods of wealth indices, 2021](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7921812/)).

### Structure

1.  A clock on the screen will display how long you have until that task, or the customer, decides to leave the line.

2.  This will mean you can no longer make money for that task.

3.  In the first round of this experiment, you will experience monetary "shocks." This means that at random times, some money might be taken from your total accumulated reward with no warning.

4.  In the second round of this experiment, the rate at which orders arrive will be doubled at random times. However, there will be no monetary shocks.

5.  Queue length is not fixed.

\- Skin conductance, Cortisol, Eye tracking

#### §Probabilistic Choice

As seen in @accuracy-results,

Revisit the experiment to address the range of urgent choices. One possibility is to add an artificial discount factor. Another possibility is to explore non-deterministic choices (that is, urgency does not mean certain decay of value from one state to another, but a probable decay).

#### Flexible Queue Size

### Simulation

## Population

In Los Angeles, 18% of residents worry every day or almost every day about paying their bills, and 23% worry about job loss (Baldassare et al., 2021). This constant mindset of worry likely affects the livelihood of these citizens. In a recent PPIC survey, about "one in five Californians report that they or someone in their household has cut back on food (21%), put off seeing a doctor or purchasing medicine to save money (18%), been unable to pay a monthly bill (17%), or had difficulty paying the rent or mortgage (17%) in the last 12 months" (Baldassare et al., 2021).

### Online Sample

Pros and cons.

### Homeless

M: Look Sera's studies

IRB: Justification

### Other Low SES Cohorts

M: Proposal

### Power Analysis

#### §Behavioral Measures

```{r}
#| eval: false
#### For Power Analysis
trade_off_scaled <- trade_off_accuracy %>%
  ungroup() %>%
  mutate(
    Dim.1 = scale(Dim.1),
    Dim.2 = scale(Dim.2),
    stai = scale(stai),
  ) %>%
  filter(!is.na(participant) &
         !is.na(stai) &
         !is.na(Dim.1))

# Urgency is whether I choose the urgent task
# in trials where there is a trade off (data = trade_off_scaled)
model_scaled <- 
  pglm(formula = Urgency ~ (Dim.1 + Dim.2)*stai,
       data = trade_off_scaled,
       effect = "twoways",
       index = c("participant", "round"),
       model = "random",
       family = binomial('logit'))

# Success rate at the 1 sd of STAI
exp(model_scaled$estimate["(Intercept)"] + model_scaled$estimate["stai"]) /
  (1 + exp(model_scaled$estimate["(Intercept)"] + model_scaled$estimate["stai"]))

# Success rate at the 1 sd of Dim.2
exp(model_scaled$estimate["(Intercept)"] + model_scaled$estimate["Dim.2"]) /
  (1 + exp(model_scaled$estimate["(Intercept)"] + model_scaled$estimate["Dim.2"]))

# Success rate at the 1 sd of stai:Dim.2
exp(model_scaled$estimate["(Intercept)"] + model_scaled$estimate["Dim.2:stai"]) /
  (1 + exp(model_scaled$estimate["(Intercept)"] + model_scaled$estimate["Dim.2:stai"]))

# Success rate at the mean of stai:Dim.2
exp(model_scaled$estimate["(Intercept)"]) /
  (1 + exp(model_scaled$estimate["(Intercept)"]))

# calculate McFadden's R-squared

model_null <- 
  pglm(formula = Urgency ~ 1,
       data = trade_off_scaled,
       index = c("participant", "round"),
       family = binomial('logit'))

as.numeric(1 - logLik(model_scaled)/logLik(model_null))

# number of effective trials per subject
length(trade_off_scaled$participant)/length(unique(trade_off_scaled$participant))


## With income + STAI

```

#### ¶Physiological Measures

"Sartorial Symbols of Social Class Elicit Class-Consistent Behavioral and Physiological Responses: A Dyadic Approach" (Kraus et al 2014)

Goal of paper: Determine the psychological response among participants paired across socio-economic groups.

N = 128, 64 dyads (20 upper class, 20 lower class, 24 neutral condition)

DV = HRV (Heart Rate Variability) reactivity differences between high vs. low class

Prior = Upper-class = -0.69, se = 0.31; Lower-class = 0.04, se = 0.31

```{r}
#| eval: false
# # HVC across SES
# Estimated sample sizes for a two-sample means test
# t test assuming sd1 = sd2 = sd
# HO: m2 = m1 versus Ha: m2 != m1
# Study parameters:
# alpha = 0.0500
# power = 0.8000
# delta = -0.7300
# m1 = 0.0400
# m2 = -0.6900
# sd = 1.3860
# Estimated sample sizes:
# N=
# N per group =
# 116
# 58
```

#### Perceived Effort

Stress has been suggested to increase perceived effort (e.g., the study will investigate whether it's more tiring to complete a task when stressed), leading low-income individuals to be less likely to take up welfare programs, regardless of eligibility (Bertrand et al., 2006; Hernanz et al., 2004).

In our model, cost can include a subjective component. Instead of counting it as simply the number of clicks, we can assume that the agent may dread or fantasize about action $a$. As such, someone who likes the task might not be bothered by doing it so the cost may be very close to zero (or negative). And vice versa for someone who hates it. Similarly, we can account for substituting *subjective* probability for objective probability. That is, people might distort the actual probability of future events.

## Hypotheses

1.  **H1:** Participants will prioritize tasks with imminent (urgent) deadlines over tasks deemed more important but with less immediate deadlines.
2.  **H2:** The introduction of monetary shocks in the first round will lead to a heightened sense of urgency, causing participants to prioritize tasks differently compared to the second round, where the rate of order arrivals is twice as big.
3.  **H3:** The variability in queue length will influence participants' task prioritization strategies, with longer queues leading to a greater focus on urgent tasks.
4.  **H4:** Participants' accuracy in trade-off decisions will vary as a function of their income and anxiety levels. Specifically, those with lower income or higher anxiety might demonstrate different task prioritization strategies than their counterparts.
5.  **H5:** Participants' choices often align with an optimal or rational protocol, as determined by a hierarchical Bayesian model, suggesting that, despite external pressures, their decision-making process has an underlying rationality.
6.  **H6:** The urgency bias will manifest differently across various demographic variables, such as income, anxiety, and ZIP code-related poverty measures.

# Conclusion

# References

# Appendix: Supplementary Models and Analyses

## Burstiness and Memory in Discreet Event Simulation

Further, with interevent times, we can calculate the burstiness and memory as a function of urgency weights.

```{r}
#| label: fig-simmer-burstiness
#| fig-cap: "Burstiness by Urgency Weight"

urgency_burstiness_grid <- read_csv("Models/DES/urgency-burstiness-grid.csv")

plt_bursty <-
  ggplot(urgency_burstiness_grid,
         aes(x = M, y = B)) +
  geom_jitter(aes(color = weights),
              size = 1,
              alpha = 0.8) +
  labs(color = "Urgency Weight") +
  scale_color_viridis(option = "D")

plt_bursty +
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = 0)

```

@fig-simmer-burstiness shows that the surviving tasks are indeed around the area of bursty phenomena as reported in the literature. However, there does not seem to be a relationship between urgency weighting and burstiness.

## Fantasy and Dread Model

$$
\begin{aligned}
& V\left(s^{\prime}\right)=r(a)-c(a)+\gamma \sum_s P\left(a, s^{\prime}, s^{\prime \prime}\right) V\left(s^{\prime \prime}\right) \\
& \mathrm{SV}\left(\mathrm{s}^{\prime}\right)=\mathrm{r}(\mathrm{a})-e\left(a \mid z_e\right)+\gamma \sum_s S P(\cdot) V\left(s^{\prime}\right) \\
& e\left(a \mid z_e\right)=z_e(c(e)) \\
& \mathrm{SP}\left(a, s^{\prime}, s^{\prime \prime} \mid z_p\right)=z_p\left(P\left(a, s^{\prime}, s^{\prime \prime}\right)\right)
\end{aligned}
$$

where $z_e, z_p$ correspond to fantasy/dread and a sense of urgency, respectively. One possible

P() depends on whether unattended task "decays"

::: {#fig-prob-weighting layout-ncol="2"}
![Probability Weighting](images/prob-weighting.png){#fig-prob-weight}

![Probability Example](images/sense-urgency-illustration.png){#fig-sense-urg}

Example of Subjective Probabilities
:::

<!-- ## Priority Queuing Simulation -->

```{r pri-q-simulation, eval=FALSE, include=TRUE}

library(simmer)
library(simmer.plot)
library(latex2exp)

# Parameters
lambda <- 5
mu <- 5
t_simul <- 150 #Calibrated to optimize simulation time (prob_continue ≈ 0)
n_simul <- 2
scale = 100 # The scale on alpha to transfer runif(0,1) to something with more variance

weights <- seq(0, 1, by = 0.001)
arri <- list()
attr <- list()
total <- list()

# Simulations with simmer
for (w in 1:length(weights)) {
  env <- simmer("poverty")
  
  person <- trajectory("Poor's Trajectory") %>%
    set_attribute(keys = "urgency", function()
      runif(1, 0, 1)) %>%
    set_attribute(keys = "importance", function()
      runif(1, 0, 1)) %>%
    set_attribute(keys = "weight", weights[w]) %>%
    set_prioritization(function() {
      prio <-
        10000 * (
          get_attribute(env, "weight") * get_attribute(env, "urgency") +
            (1 - get_attribute(env, "weight")) * get_attribute(env, "importance")
        )
      c(prio, NA, NA)
    }) %>%
    # log_(function() {
    #   paste("Priority is: ", get_prioritization(env)[1])
    # }) %>%
    seize("person", amount = 1) %>%
    timeout(function()
      rexp(1, mu)) %>%
    release("person", amount = 1)
  
  env <-
    simmer() %>%
    add_resource("person", capacity = 1) %>%
    add_generator("Task", person, function()
      rexp(1, lambda), mon = 2)
  
  # env %>% run(until = t_simul)
  
  envs <- lapply(1:n_simul, function(i) {
    env %>%
      run(until = t_simul) %>%
      wrap()
  })
  
  ## Change Variables before
  arri[[w]] <- get_mon_arrivals(envs, ongoing = TRUE)
  attr[[w]] <- get_mon_attributes(envs)
  
  # Merge
  total[[w]] <-
    inner_join(arri[[w]], attr[[w]][attr[[w]]$key == "urgency", c(2, 4, 5)], by = c("name", "replication"))
  total[[w]] <-
    total[[w]] %>%
    rename(urgency = value)
  total[[w]] <-
    total[[w]][order(total[[w]]$replication, total[[w]]$start_time, decreasing = FALSE), ]
  row.names(total[[w]]) <- NULL
  total[[w]] <-
    inner_join(total[[w]], attr[[w]][attr[[w]]$key == "importance", c(2, 4, 5)], by = c("name", "replication"))
  total[[w]] <-
    total[[w]] %>%
    rename(importance = value)
  total[[w]] <-
    total[[w]][order(total[[w]]$replication, total[[w]]$start_time, decreasing = FALSE), ]
  row.names(total[[w]]) <- NULL
  total[[w]]$waiting_time <-
    total[[w]]$end_time - total[[w]]$start_time - total[[w]]$activity_time

    # Take care of precision problems yielding negative wait times.
  if (nrow(total[[w]][total[[w]]$waiting_time < 0 &
                      !is.na(total[[w]]$waiting_time), ]) > 0) {
    total[[w]][total[[w]]$waiting_time < 0 &
                 !is.na(total[[w]]$waiting_time), ]$waiting_time <- 0
  }

  #Weibull distribution with monomial function
  alpha = (scale - scale * as.numeric(total[[w]]$urgency)) #for now
  beta = 1
  total[[w]]$prob_fail <-
    1 - exp(-1 * (total[[w]]$waiting_time / alpha) ^ (beta))

  # Get probability of survival
  total[[w]] <- total[[w]] %>%
    mutate(prob_continue = (1 - prob_fail)) %>%
    group_by(replication) %>%
    mutate(prob_continue = lag(cumprod(prob_continue), k=1, default=1))

  cat('Simulation', w, 'of', length(weights), '\n')
}

sigma_list <- lapply(X = total, function(X)   sd(X[!is.na(X$waiting_time), ]$waiting_time))
mu_list    <- lapply(X = total, function(X) mean(X[!is.na(X$waiting_time), ]$waiting_time))
lag_time <- lapply(X = total, function(X) X %>%
                     filter(!is.na(waiting_time)) %>%
                     group_by(replication) %>%
                     mutate(waiting_time_lag = lag(waiting_time, default = 0)) %>%
                     dplyr::select(waiting_time, waiting_time_lag) %>%
                     cor())
memory   <- lapply(X = lag_time, function(X) X[2,3])


# Burstiness -------------------------------------------------------------
burstiness <- data.frame(weights) %>%
  mutate(sigma = unlist(sigma_list)) %>%
  mutate(mu = unlist(mu_list)) %>%
  mutate(B = (sigma - mu) / (sigma + mu)) %>%
  mutate(M = unlist(memory))
write_csv(burstiness, file = "Models/DES/urgency-burstiness-grid.csv")

# Probability of Survival -------------------------------------------------
prob_survival <- lapply(X = total,
                        function(X) X %>%
                          group_by(name) %>%
                          summarise(mean_survival = mean(prob_continue),
                                    mean_time = mean(end_time)) %>%
                          rename(task = name) %>%
                          mutate(task = readr::parse_number(task))
                          )
names(prob_survival) <- weights
survival <- prob_survival %>%
  bind_rows(.id = "weight")

```

## Dynamic Programming Simulation

In this analysis, we constructed a Markov Decision Process (MDP) model of the game, then used dynamic programming to solve the MDP and derive an optimal policy -- the best course of action at each state. To derive a dynamic programming strategy to optimally play the game, we must clearly define the state, action, and reward at each step in the game.

1.  **State**: The state of the game at any given time can be represented by the current tasks in the queue, each of which is characterized by its effort, importance (value), and urgency. Additionally, the state should also include the round number because the available tasks and their urgency can change from round to round.

2.  **Action**: An action in this game is the selection of a task from the queue.

3.  **Reward**: The reward is the profit (points) gained from completing a task, which is determined by its value (importance).

With these definitions, we can formulate the optimal policy of the game using dynamic programming. The goal is to maximize the total profit over the game.

We denote the state at round $i$ as $s_i$ and an action at round $i$ as $a_i$. The reward of taking action $a_i$ at state $s_i$ is denoted as $r(s_i, a_i)$. The state-transition function, which describes the new state after taking an action, is denoted as $T(s_i, a_i)$. Our aim is to find the policy $\pi^*$ that maximizes the total reward:

$$
 \pi^* = \arg\max_{\pi} \sum_{i=1}^{40} r(s_i, \pi(s_i))
$$

The Bellman equation for this game can be written as:

$$
V(s) = \max_{a} \left( r(s, a) + V(T(s, a)) \right)
$$

This equation states that the value of a state $s$ is the maximum over all actions $a$ of the immediate reward $r(s, a)$ plus the value of the state resulting from taking action $a$, $V(T(s, a))$.

The crux of this methodology revolves around the Value Iteration algorithm, which involves iteratively updating the value function (the expected cumulative reward from each state) until convergence. To find the optimal policy, we use backward induction; that is, we start at the end of the game and work backward, iteratively computing the value function for each state until we reach the start of the game. At each state, the optimal action is the one that maximizes the immediate reward plus the value of the next state.

Interestingly, after a sufficient number of iterations (over 100 trials), we observed a steady state in the value function, whereby the expected cumulative reward was nearly identical across all states. This convergence suggests that as we approach infinity, the long-term expected reward is almost the same, irrespective of the state under an optimal policy.

Notably, this does not imply that the policy for each state will be identical. However, as is common in many Markov Decision Processes, the task-based game has a level of inherent balance, where we have structured the potential outcomes of different actions to ensure a relatively even distribution of long-term rewards across various states.

Above all, these findings underline the complexity of decision-making processes and the intricate dynamics in this and other task-based games. In practice, the large number of possible states in this game (due to the different combinations of tasks and their characteristics) might make exact dynamic programming infeasible for humans. As such, approximation methods such as function approximation or reinforcement learning techniques are necessary.

```{python, eval = FALSE}
import pandas as pd
import ast

# Load the transition probabilities from the CSV file
transition_df = pd.read_csv('./Models/dyn_prog/transition_df.csv')
# Define the discount factor
gamma = 0.9
# Maximum number of rounds
num_rounds = 40
# Cost and Reward
costH = 0.5
costL = 0.1
rewardH = 2
rewardL = 1

def reward(state, action):
    # Split the state into tasks
    tasks = state.split(',')
    # The task is chosen based on the action
    if len(tasks) < 2 or tasks[action] == '<NA>':
      return None
    # Calculate Cost
    cost = costH if tasks[action][1] == 'H' else costL
    # Calculate the reward
    if tasks[action][0] == 'H':
      return rewardH - cost
    elif tasks[action][0] == 'L':
      return rewardL - cost
    else:
      return None

# Create empty dataframes to store the values and actions for each state and round
value_df = pd.DataFrame(index=transition_df['Unnamed: 0'], columns=range(1, num_rounds + 1))
policy_df = pd.DataFrame(index=transition_df['Unnamed: 0'], columns=range(1, num_rounds + 1))

# Fill in the last column of the value matrix with the reward for each state-action pair at the final time step
for state in transition_df['Unnamed: 0']:
    Q = []
    for action in [0, 1]:
        r = reward(state, action)
        if r is not None:  # If the action is valid
            Q.append(r)
        else:  # If the action is not valid
            Q.append(0)
    value_df.loc[state, num_rounds] = max(Q)
    policy_df.loc[state, num_rounds] = Q.index(max(Q))  # The action that yields the maximum reward

# Work backwards, iteratively filling in each column of the matrix
for round in reversed(range(1, num_rounds)):  # From (num_rounds - 1) to 1
    for state in transition_df['Unnamed: 0']:
        # Identify the index of the current state
        idx = transition_df.index[transition_df['Unnamed: 0'] == state][0]
        # Calculate the expected cumulative reward for each possible action
        Q = []
        for action in [0, 1]:
            r = reward(state, action)
            if r is not None:  # If the action is valid
                transition_probs = ast.literal_eval(transition_df.iloc[idx, action + 1])
                Q.append(r + gamma * sum(transition_probs.get(next_state, 0) * value_df.loc[next_state, round + 1]
                                         for next_state in transition_df['Unnamed: 0']))
            else:  # If the action is not valid
                Q.append(0)
        # Update the value function and the policy
        value_df.loc[state, round] = max(Q)
        policy_df.loc[state, round] = Q.index(max(Q))  # The action that yields the maximum expected cumulative reward

value_df.to_csv('./dyn_prog/value_df.csv')
policy_df.to_csv('./dyn_prog/policy_df.csv')

```

```{r dyn-pro-simulation, eval=FALSE, include=TRUE}

library(stringi)
library(stringr)

#Importance
imp <- c(1,2)
#Cost
cost1 = 0
cost2_grid <- seq(from = 0.1, to = 0.9, by = 0.05)
#Discounting
gamma_grid <- seq(from = 0.8, to = 1, by = 0.025)
#Choices
tasks <- c("HHU",
            "HH0",
            "HLU",
            "HL0",
            "LHU",
            "LH0",
            "LLU",
            "LL0")
tasks <- as.data.frame(tasks)
# Urgency Ratios
ratios <- c()

for (gamma in gamma_grid) {
  print(gamma)
  for (cost2 in cost2_grid) {
    # Add values
    tasks$value  <- c(imp[2]-cost2,
                      imp[2]-cost2,
                      imp[2]-cost1,
                      imp[2]-cost1,
                      imp[1]-cost2,
                      imp[1]-cost2,
                      imp[1]-cost1,
                      imp[1]-cost1)
    #Look up values
    r_choice <- tasks$value
    names(r_choice) <- tasks$tasks
    ## Use unname(r_choice["HH0"]) for example
    
    # States
    S <- as.data.frame(t(combn(tasks$tasks,2)))
    for (chr in tasks$tasks) {
      # Add states with two of the same task
      S <- rbind(S,c(chr,chr))
      # Add states with only one task transition to one task
      S <- rbind(S,c(chr,NA))
      # Add states with only one task transitioning to two tasks
      S <- rbind(S,c(chr,"TR"))
    }
    
    #Choice|States
    ## 1st column is choice.
    ## 1st+2nd columns are the state
    ch <- expand.grid(tasks$tasks,tasks$tasks)
    # Fix factor levels for next step
    levels(ch$Var2)
    levels(ch$Var2) = c("HHU", "HH0", "HLU", "HL0", "LHU", "LH0", "LLU", "LL0", "TR")
    for (chr in tasks$tasks) {
      ch <- rbind(ch,c(chr,NA))
      ch <- rbind(ch,c(chr,"TR"))
    }
    
    # Transition Probabilities
    choices <- paste(ch$Var1,ch$Var2,sep = "x")
    states <- paste(S$V1,S$V2,sep = "x")
    transitions <- expand.grid(choices,states)
    # Remaining task (last 3 characters) is in the next state, but no NA
    transitions$prob <- NA
    ## Non-urgent tasks:
    ## Note this is also transitioning to NA and TR states. Fix it in line 91 and __
    transitions[str_detect(str = str_sub(transitions$Var1,-3), pattern = "0"),]$prob <- 
      str_detect(str = transitions[str_detect(str = str_sub(transitions$Var1,-3), pattern = "0"),]$Var2,
                 pattern = str_sub(transitions[str_detect(str = str_sub(transitions$Var1,-3), pattern = "0"),]$Var1,-3))
    ## Urgent tasks: 
    ### If HXU -> LXU
    transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
                  str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "H"),]$prob <-
      str_detect(str = transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
                                     str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "H"),]$Var2,
                 pattern = paste("L",
                                 str_sub(transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
                                                       str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "H"),]$Var1,
                                         start = -2,
                                         end = -2),"U",sep = ""))
    ### If LXU -> NA
    ## first change all transitions to false
    transitions[str_detect(str = str_sub(transitions$Var2,-3), pattern = "NA"),]$prob <- FALSE
    # Now calculate other transitions
    transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
                  str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "L"),]$prob <-
      str_detect(str = transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
                                     str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "L"),]$Var2,
                 pattern = "NA")
    
    ## Single task with transition to single task:
    transitions[str_detect(str = transitions$Var1, pattern = "NA"),]$prob <-
      str_detect(str = transitions[str_detect(str = transitions$Var1, pattern = "NA"),]$Var2,
                 pattern = "TR")
    ## Single task with transition to single task:
    transitions[str_detect(str = transitions$Var1, pattern = "TR"),]$prob <- 0
    
    #Transforming them into probabilities by dividing by 8
    transitions$prob <- as.numeric(transitions$prob)
    transitions$prob <- transitions$prob / 8
    
    ## Single task with transition to single task:
    transitions[str_detect(str = transitions$Var1, pattern = "TR") &
                  str_length(transitions$Var2) == 7,]$prob <- 1/36
    
    ##################################################
    ################# Simulation
    ##################################################
    
    # Backwards induction
    ## Determine number of loops
    rounds = 20
    ## Create column with values of each choice for each round
    col_names <- paste("rd", c(1:rounds), sep = "")
    ch[col_names] <- NA
    ## Last round:
    ### fill in column in "ch" with the values
    for(choice in tasks$tasks) {
      ### first column is choice: find in tasks table the value of that choice
      ch[ch$Var1 == choice,rounds+2] <- tasks[tasks$tasks == choice,]$value
    }
    ### Multiply by discount factor^round
    ch[,rounds+2] <- ch[,rounds+2]*gamma^(rounds-1)
    
    
    ## Create state values for each round
    S[col_names] <- NA
    ### for each state in "S" choose the highest value in "ch" and create another column with the values
    best_option <- function(round, choice_matrix = ch, state_matrix = S, label_matrix = label){
      for(row in c(1:nrow(state_matrix))) {
        if (is.na(state_matrix[row,]$V2)) {
          state_matrix[row,round + 2] <- choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V1 &
                                                         is.na(choice_matrix$Var2),round +2]
          label_matrix[row,round + 2] <- as.character(choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V1 & 
                                                                      is.na(choice_matrix$Var2), 1])
        } else if (as.character(state_matrix[row,]$V2) == "TR") {
          state_matrix[row,round + 2] <- na.exclude(choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V1 &
                                                                    choice_matrix$Var2 == state_matrix[row,]$V2,round + 2])
          label_matrix[row,round + 2] <- as.character(choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V1 &
                                                                      is.na(choice_matrix$Var2), 1])
        } else {
          choice1 <- choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V1 &
                                     choice_matrix$Var2 == state_matrix[row,]$V2 &
                                     !is.na(choice_matrix$Var2) &
                                     as.character(choice_matrix$Var2) != "TR",round +2]
          choice2 <- choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V2 &
                                     choice_matrix$Var2 == state_matrix[row,]$V1 &
                                     !is.na(choice_matrix$Var2) &
                                     as.character(choice_matrix$Var2) != "TR",round +2]
          if (choice1 > choice2) {
            state_matrix[row,round + 2] <- choice1
            # ### save choices: change the suboptimal choices to NA
            # choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V2 &
            #                 choice_matrix$Var2 == state_matrix[row,]$V1 &
            #                 !is.na(choice_matrix$Var2) &
            #                 as.character(choice_matrix$Var2) != "TR",round +2] <- NA
            label_matrix[row,round + 2] <- as.character(na.exclude(choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V1 &
                                                                        choice_matrix$Var2 == state_matrix[row,]$V2, 1]))
          } else if (choice1 < choice2) {
            state_matrix[row,round + 2] <- choice2
            # ### save choices: change the suboptimal choices to NA
            # choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V1 &
            #                 choice_matrix$Var2 == state_matrix[row,]$V2 &
            #                 !is.na(choice_matrix$Var2) &
            #                 as.character(choice_matrix$Var2) != "TR",round +2] <- NA
            label_matrix[row,round + 2] <- as.character(na.exclude(choice_matrix[choice_matrix$Var1 == state_matrix[row,]$V2 &
                                                                        choice_matrix$Var2 == state_matrix[row,]$V1, 1]))
          } else if (choice2 == choice1){
            state_matrix[row,round + 2] <- choice1
            label_matrix[row,round + 2] <- "either"
          }
        }
      }
      return(list(state_matrix,choice_matrix,label_matrix))
    }
    
    label <- S
    new_states_choices <- best_option(rounds)
    S <- new_states_choices[[1]]
    ch <- new_states_choices[[2]]
    label <- new_states_choices[[3]]
    ## second to last round to first round
    ### loop through the choices|states in "S"
    ### For each choice|state, calculate the the expected value
    
    # We need to change "transitions" for simplicity of search
    transitions$choice <- substr(transitions$Var1, 1, 3)
    transitions$non_choice <- substr(transitions$Var1, 5, 7)
    transitions[transitions$non_choice == "NA",]$non_choice <- NA
    transitions$state2_1 <- substr(transitions$Var2, 1, 3)
    transitions$state2_2 <- substr(transitions$Var2, 5, 7)
    transitions[transitions$state2_2 == "NA",]$state2_2 <- NA
    
    for(i in c(1:(rounds-1))){
      values <- S[,c(1,2,(rounds+3-i))]
      for(row in c(1:nrow(ch))){
        #### create probability vector P [44x1] from "transitions"
        if(!is.na(ch[row,2])) {
          prob_weight <- 
            transitions[ch[row,1] == transitions$choice &
                          ch[row,2] == transitions$non_choice &
                          !is.na(ch[row,2]) &
                          !is.na(transitions$non_choice),]
        } else if(is.na(ch[row,2])) {
          prob_weight <- 
            transitions[ch[row,1] == transitions$choice &
                          is.na(ch[row,2]) &
                          is.na(transitions$non_choice),]
        }
        
        #### Make sure "S" is in the same order [1x44]
        prob_weight <- merge(x = prob_weight,
                             y = values,
                             by.x = c("state2_1", "state2_2"),
                             by.y = c("V1", "V2"))
        prob_weight$weighted_value <- prob_weight$prob * values[,c(length(values))]
        ### Multiply by discount factor^round
        ch[row,rounds+2-i] <- gamma^(rounds-1-i)*tasks[tasks$tasks == ch[row,1],]$value + sum(prob_weight$weighted_value)
      }
      new_states_choices <- best_option(rounds-i)
      S <- new_states_choices[[1]]
      ch <- new_states_choices[[2]]
      label <- new_states_choices[[3]]
    }
    urgency <- apply(label[,-c(1:2)], 2, function(X) substr(X, nchar(X), nchar(X)))
    ratios <- append(ratios, table(urgency)["U"]/sum(table(urgency)))
  }
}

ratios_grid <- matrix(ratios,
                      nrow = length(gamma_grid),
                      ncol = length(cost2_grid),
                      dimnames = list(gamma_grid,
                                      cost2_grid))

### Export labels
write.csv(ratios_grid,"./Models/pilot/pilot-simulation-grid.csv")

```

<!-- ## Bayesian Model for Cost Estimation -->

<!-- ### Model -->

```{stan cost-model, eval=FALSE, include=TRUE, output.var="my_model"}
data {
  int<lower=1> N;
  int<lower=1> T;
  int<lower=2> nOpt;
  int<lower=1, upper=T> Tsubj[N];
  int<lower=0, upper=nOpt> choice[N, T]; //left or right?
  int<lower=0, upper=80> opt_st[N, T]; //option-state: an easy way to map the choices for choice prob calculation
  int value_lookup[80];
  int state_lookup[52, nOpt];
  matrix<lower=0, upper = 1>[80, 52] prob_weight;
  int<lower=0, upper=80> counterpart[80];
  // real outcome[N, T];  // no lower and upper bounds
}
transformed data {
  vector[nOpt] initV;  // initial values for EV
  initV = rep_vector(0.0, nOpt);
}
parameters {
// Declare all parameters as vectors for vectorizing
  // Hyper(group)-parameters
  vector[2] mu_pr;
  vector<lower=0>[2] sigma;

  // Subject-level parameters (for transformation from hyper to subj parameter)
  vector[N] costL;  // cost_low
  vector[N] costH;    // cost_high
}
model {
  // Hyperparameters
  mu_pr  ~ normal(0, 5); //weakly informative priors
  sigma ~ gamma(2,0.1); //weakly informative priors

  // individual parameters
  for (i in 1:N) {
    //tau[i]   = Phi_approx(mu_pr[1]  + sigma[1]  * tau_pr[i]); //approx Normal CDF + noise
    costL[i] ~ normal(mu_pr[1], sigma[1]);
    costH[i] ~ normal(mu_pr[2], sigma[2]);
  }

  // subject loop and trial loop
  for (i in 1:N) {
    vector[nOpt] ev; // expected value
    vector[4] value; // vector of value option, lookup table
    matrix[80, Tsubj[i]] ch; 
    matrix[52, Tsubj[i]] st;
    int round_back; // backwards counter for induction
    real weighted_value;
    
    ev = initV;

    // Declaring values for each option, lookup table (make it loop later)
    value[1] = 2 - costH[i];
    value[2] = 1 - costH[i];
    value[3] = 1 - costL[i];
    value[4] = 2 - costL[i];


    // Backwards induction
    //  fill in column in "ch" with the values
    for(option in 1:80) {
      // first column is choice: find in tasks table the value of that choice
      // lookup is a vector that tells you which cost correspondends to each choice
      ch[option, Tsubj[i]] = value[value_lookup[option]];
    }
    //    Create state values for each round
    // state_lookup tells you which choice|state maps onto which state
    // for each state in "S" choose the highest value in "ch" and create another column with the values
    for(state in 1:52) {
      if (ch[state_lookup[state,1], Tsubj[i]] >= ch[state_lookup[state,2], Tsubj[i]]) {
        st[state, Tsubj[i]] = ch[state_lookup[state,1], Tsubj[i]];
      } else if (ch[state_lookup[state,1], Tsubj[i]] < ch[state_lookup[state,2], Tsubj[i]]) {
        st[state, Tsubj[i]] = ch[state_lookup[state,2], Tsubj[i]];
      }
    }
        // compute action probabilities
        ev[1] = ch[opt_st[i, Tsubj[i]], Tsubj[i]];
        ev[2] = ch[counterpart[opt_st[i, Tsubj[i]]], Tsubj[i]];
        choice[i, Tsubj[i]] ~ categorical_logit(ev);
        
        for (t in 1:(Tsubj[i]-1)) {
          round_back = Tsubj[i] - t;
          for(option in 1:80) {
            // use action probabilities
            weighted_value = dot_product(prob_weight[option], col(st, (round_back + 1)) );
            ch[option, round_back] = value[value_lookup[option]] + weighted_value;
          }
          for(state in 1:52) {
            if (ch[state_lookup[state,1], round_back] >= ch[state_lookup[state,2], round_back]) {
              st[state, round_back] = ch[state_lookup[state,1], round_back];
            } else if (ch[state_lookup[state,1], round_back] < ch[state_lookup[state,2], round_back]) {
              st[state, round_back] = ch[state_lookup[state,2], round_back];
            }
          }
          // compute action probabilities
          ev[1] = ch[opt_st[i, round_back], round_back];
          ev[2] = ch[counterpart[opt_st[i, round_back]], round_back];
          choice[i, round_back] ~ categorical_logit(ev);
        }
  }
  
}
```

<!-- ### Model Data -->

```{r cost-model-data, eval=FALSE, include=TRUE}
# Data Wrangling ----------------------------------------------------------
load("Prolific-pilot1.Rdata")
data <- pilot1[!is.na(pilot1$participant),]
data <- data %>%
  group_by(participant) %>%
  mutate(COUNTER = row_number())
Tsubj <- data %>%
  group_by(participant) %>%
  summarize(n = n())

# Creating Choice set ----------------------------------------------------------
choices <- c("HHU", "HH0", "HLU", "HL0", "LHU", "LH0", "LLU", "LL0")
ch <- expand.grid(choices, choices)
# Fix factor levels for next step
levels(ch$Var2) = append(choices, "TR")
for (chr in choices) {
  ch <- rbind(ch,c(chr,NA))
  ch <- rbind(ch,c(chr,"TR"))
}

# Creating State set ----------------------------------------------------------
S <- as.data.frame(t(combn(choices,2)))
for (chr in choices) {
  # Add states with two of the same task
  S <- rbind(S,c(chr,chr))
  # Add states with only one task transition to one task
  S <- rbind(S,c(chr,NA))
  # Add states with only one task transitioning to two tasks
  S <- rbind(S,c(chr,"TR"))
}

# Create Transition Set ----------------------------------------------------------
# Transition Probabilities
choices <- paste(ch$Var1,ch$Var2,sep = "x")
states <- paste(S$V1,S$V2,sep = "x")
transitions <- expand.grid(choices,states)
# Remaining task (last 3 characters) is in the next state, but no NA
transitions$prob <- NA
## Non-urgent tasks:
transitions[str_detect(str = str_sub(transitions$Var1,-3), pattern = "0"),]$prob <- 
  str_detect(str = transitions[str_detect(str = str_sub(transitions$Var1,-3), pattern = "0"),]$Var2,
             pattern = str_sub(transitions[str_detect(str = str_sub(transitions$Var1,-3), pattern = "0"),]$Var1,-3))
## Urgent tasks: 
### If HXU -> LXU
transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
              str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "H"),]$prob <-
  str_detect(str = transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
                                 str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "H"),]$Var2,
             pattern = paste("L",
                             str_sub(transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
                                                   str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "H"),]$Var1,
                                     start = -2,
                                     end = -2),"U",sep = ""))
### If LXU -> NA
## first change all transitions to false
transitions[str_detect(str = str_sub(transitions$Var2,-3), pattern = "NA"),]$prob <- FALSE
# Now calculate other transitions
transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
              str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "L"),]$prob <-
  str_detect(str = transitions[str_detect(str = str_sub(transitions$Var1,-1), pattern = "U") & 
                                 str_detect(str = str_sub(transitions$Var1,start = -3, end = -3), pattern = "L"),]$Var2,
             pattern = "NA")

## Single task with transition to single task:
transitions[str_detect(str = transitions$Var1, pattern = "NA"),]$prob <-
  str_detect(str = transitions[str_detect(str = transitions$Var1, pattern = "NA"),]$Var2,
             pattern = "TR")
## Single task with transition to single task:
transitions[str_detect(str = transitions$Var1, pattern = "TR"),]$prob <- 0

#Transforming them into probabilities by dividing by 8
transitions$prob <- as.numeric(transitions$prob)
transitions$prob <- transitions$prob / 8

## Single task with transition to single task:
transitions[str_detect(str = transitions$Var1, pattern = "TR") &
              str_length(transitions$Var2) == 7,]$prob <- 1/36
# We need to change "transitions" for simplicity of search
transitions$choice <- substr(transitions$Var1, 1, 3)
transitions$non_choice <- substr(transitions$Var1, 5, 7)
transitions[transitions$non_choice == "NA",]$non_choice <- NA
transitions$state2_1 <- substr(transitions$Var2, 1, 3)
transitions$state2_2 <- substr(transitions$Var2, 5, 7)
transitions[transitions$state2_2 == "NA",]$state2_2 <- NA


# create choice[N,T] ----------------------------------------------------------
data$choice_bin <- 1
data[data$choice == "R",]$choice_bin <- 2
choice <- data %>%
  dplyr::select(participant, COUNTER, choice_bin) %>%
  group_by(COUNTER) %>%
  spread(COUNTER, choice_bin)
# Take NAs out
choice[is.na(choice)] <- 0


# Option-State ------------------------------------------------------------
## an easy way to map the choices for choice prob calculation
ch_opt_translation <- ch[,c(1:2)]
ch_opt_translation$index <- c(1:length(ch_opt_translation$Var1))
ch_opt_translation$i1 <- NA
ch_opt_translation$e1 <- NA
ch_opt_translation$i2 <- NA
ch_opt_translation$e2 <- NA

ch_opt_translation$u1 <- grepl("U", ch_opt_translation$Var1)
ch_opt_translation$u2 <- grepl("U", ch_opt_translation$Var2)
ch_opt_translation[is.na(ch_opt_translation$Var2), ]$u2 <- NA
ch_opt_translation$u1 <- as.numeric(ch_opt_translation$u1) + 1
ch_opt_translation$u2 <- as.numeric(ch_opt_translation$u2) + 1

ch_opt_translation$i1 <- ifelse(substring(ch_opt_translation$Var1, 1, 1) == "H", 2, 1)
ch_opt_translation$i2 <- ifelse(substring(ch_opt_translation$Var2, 1, 1) == "H", 2, 1)
ch_opt_translation[is.na(ch_opt_translation$Var2), ]$i2 <- NA

ch_opt_translation$e1 <- ifelse(substring(ch_opt_translation$Var1, 2, 2) == "H", 2, 1)
ch_opt_translation$e2 <- ifelse(substring(ch_opt_translation$Var2, 2, 2) == "H", 2, 1)
ch_opt_translation[is.na(ch_opt_translation$Var2), ]$e2 <- NA

ch_opt_translation[grepl("TR", ch_opt_translation$Var2), ]$i2 <- 
  ch_opt_translation[grepl("TR", ch_opt_translation$Var2), ]$i1
ch_opt_translation[grepl("TR", ch_opt_translation$Var2), ]$e2 <- 
  ch_opt_translation[grepl("TR", ch_opt_translation$Var2), ]$e1
ch_opt_translation[grepl("TR", ch_opt_translation$Var2), ]$u2 <- 
  ch_opt_translation[grepl("TR", ch_opt_translation$Var2), ]$u1

ch_opt_translation[grepl("TR", ch_opt_translation$Var2), ]$i1 <- NA
ch_opt_translation[grepl("TR", ch_opt_translation$Var2), ]$e1 <- NA
ch_opt_translation[grepl("TR", ch_opt_translation$Var2), ]$u1 <- NA

data <- merge(x = data,
              y = ch_opt_translation[,-c(1:2)],
              by = c("u1", "u2", "e1", "e2", "i1", "i2"))

opt_st <- data %>%
  dplyr::select(participant, COUNTER, index) %>%
  group_by(COUNTER) %>%
  spread(COUNTER, index)
# Take NAs out
opt_st[is.na(opt_st)] <- 0

ch_opt_translation$value <- 0
ch_opt_translation[grepl("HH", ch_opt_translation$Var1),]$value = 1
ch_opt_translation[grepl("LH", ch_opt_translation$Var1),]$value = 2
ch_opt_translation[grepl("LL", ch_opt_translation$Var1),]$value = 3
ch_opt_translation[grepl("HL", ch_opt_translation$Var1),]$value = 4


S$st_index <- c(1:nrow(S))
S <- merge(x = S,
           y = ch_opt_translation[,c(1:3)],
           by.x = c("V1", "V2"),
           by.y = c("Var1", "Var2"))
ch_opt_translation$index2 <- ch_opt_translation$index
S <- merge(x = S, 
           y = ch_opt_translation[,c(1:2,11)],
           by.x = c("V2", "V1"),
           by.y = c("Var1", "Var2"),
           all.x = TRUE)
state_lookup <- S %>%
  dplyr::select(st_index, index, index2)
# Take NAs out
state_lookup[is.na(state_lookup$index2),]$index2 <- state_lookup[is.na(state_lookup$index2),]$index
# Order state_lookup
state_lookup <- state_lookup %>%
  arrange(order_by = st_index)

prob_weight <- merge(x = transitions,
                      y = ch_opt_translation[,c(1:3)],
                      by.x = c("choice", "non_choice"),
                      by.y = c("Var1", "Var2"))
prob_weight <- merge(x = prob_weight,
                     y = ch_opt_translation[,c(1:2,11)],
                     by.x = c("state2_1", "state2_2"),
                     by.y = c("Var1", "Var2"))


# Map Choices to States ---------------------------------------------------
choice_state <- as.data.frame(c(1:80))
choice_state <- merge(x = choice_state,
                      y = state_lookup[,-c(3)],
                      by.x = c("c(1:80)"),
                      by.y = c("index"),
                      all.x = TRUE)
choice_state <- merge(x = choice_state,
                      y = state_lookup[,-c(2)],
                      by.x = c("c(1:80)"),
                      by.y = c("index2"),
                      all.x = TRUE)
choice_state$st_index <- choice_state$st_index.x
choice_state[is.na(choice_state$st_index.x),]$st_index <- choice_state[is.na(choice_state$st_index.x),]$st_index.y
choice_state <- choice_state %>%
  dplyr::select(`c(1:80)`, st_index)
prob_weight <- merge(x=prob_weight,
                     y=choice_state,
                     by.x = "index2",
                     by.y= "c(1:80)")
prob_weight <- prob_weight %>%
  dplyr::select(index, st_index, prob)

prob_weight <- prob_weight %>%
  group_by(index) %>%
  spread(st_index, prob)


# Counterpart choice|states -----------------------------------------------
counterpart <- merge(x = choice_state, y = state_lookup[,-c(1)], by.x = "c(1:80)", by.y = "index", all.x = TRUE)
counterpart <- merge(x = counterpart, y = state_lookup[,-c(1)], by.x = "c(1:80)", by.y = "index2", all.x = TRUE)
counterpart$index_ALL <- counterpart$index
counterpart[is.na(counterpart$index),]$index_ALL <- counterpart[is.na(counterpart$index),]$index2
counterpart <- counterpart %>%
  dplyr::select(index_ALL)

model_data <- list( N = length(unique(data$participant)), #number of part
                    T = max(data$COUNTER), # number of max rounds
                    nOpt = 2,
                    Tsubj = Tsubj$n, # number of round
                    choice = choice[,c(-1)],
                    opt_st = opt_st[,c(-1)],
                    value_lookup = ch_opt_translation$value,
                    state_lookup = state_lookup[,c(-1)],
                    prob_weight = prob_weight[,c(-1)],
                    counterpart = counterpart$index_ALL) # transition probabilities

```

<!-- ### Estimation -->

```{r cost-model-estimation, eval=FALSE, include=TRUE}

load("prolific1StanData.Rdata")
# my_model <- stan_model(file = "recipes/hier-bayes-simple.stan", verbose = TRUE)
Prolific1_Stan_results <- sampling(object = my_model, data = model_data,
                                   iter = 1000,
                                   chains = 1,
                                   cores = 3)

```

## Correlations in Experiment 1 Variables

```{r}

cor(df[c("PA1", "PA2", "PA3", "zip_income", "zip_poverty_log",
         "SAI_pre", "SAI_post", "TAI_post",
         "Total_approvals", "Age")],
    method = "spearman", use = "pairwise.complete.obs")

```

## Sensitivity Analyses

### Pilot Urgency Regression

```{r, results='asis'}
#| label: tbl-sensitivity
#| tbl-cap: "Model Comparison based on BIC, number of variables, and included attributes"

two_options <- joint_pilot %>%
  filter(!is.na(participant), !is.na(round)) %>%
  mutate(income = as.numeric(income),
         logRT = log(as.numeric(RT)),
         platform = factor(platform)) %>%
  filter(logRT != Inf & logRT != -Inf) %>%
  group_by(participant, block) %>%
  mutate(max_round_in_block = max(round)) %>% ungroup() %>%
  group_by(participant) %>% arrange(block) %>%
  mutate(first_block_rounds = first(max_round_in_block),
         round = round + first_block_rounds * (block - 1)) %>% # Only works for 1 or 2 rounds
  select(-max_round_in_block, -first_block_rounds)
two_options <- pdata.frame(two_options, index = c("participant", "round"))

# Function to fit the model
fit_model <- function(formula, data) {
  pglm(formula = formula,
       data = data,
       effect = "twoways",
       family = binomial('logit'),
       model = "random")
}

# Function to calculate observations
get_gof_rows <- function(model) {
  seq_ivs <- c(2:5)
  if (ncol(model$model) < 6) {
    seq_ivs <- c(2:3)
  } 
  obs_trials <- model$model %>%
    group_by(pick(seq_ivs)) %>%
    summarise(trials = n()) %>% ungroup() %>%
    summarise(max = max(trials), min = min(trials), mean = mean(trials))
   obs_participants <- model$model %>%
    group_by(pick(seq_ivs)) %>%
    mutate(id = row_number()) %>% ungroup() %>%
    summarise(N = max(id))
  Participants <- obs_participants$N
  Trials <- paste0(obs_trials$min, "-", obs_trials$max, " (M = ", round(obs_trials$mean,1),")")
  BIC <- AIC(model, k = log(nrow(model$model)))
  return(list(Participants = Participants, Trials = Trials, BIC = BIC))
}

formulas <- list(
  chosen_u ~ Dim.1*Dim.2,
  chosen_u ~ Dim.1*Dim.2 + age + male + points,
  chosen_u ~ Dim.1*Dim.2 + age + male + points +
    chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u,
  chosen_u ~ age + male +
    (Dim.1 + Dim.2)*(chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u) + 
    points,
  
  chosen_u ~ income*stai,
  chosen_u ~ income*stai + age + male + points + platform,
  chosen_u ~ income*stai + age + male + points + platform +
    chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u,
  chosen_u ~ age + male +
    (income + stai)*(chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u) +
    platform + points,
  
  chosen_u ~ poverty_zip*stai,
  chosen_u ~ poverty_zip*stai + age + male + points,
  chosen_u ~ poverty_zip*stai + age + male + points +
    chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u,
  chosen_u ~ age + male +
    (poverty_zip + stai)*(chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u) +
    points,
  
  chosen_u ~ median_income_zip*stai,
  chosen_u ~ median_income_zip*stai + age + male + points,
  chosen_u ~ median_income_zip*stai + age + male + points +
    chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u,
  chosen_u ~ age + male +
    (median_income_zip + stai)*(chosen_i + chosen_e + not_chosen_i + not_chosen_e + not_chosen_u) +
    points
)
# Fit the models using your fit_model function
models <- lapply(formulas, fit_model, data = two_options)

gof_list <- lapply(models, get_gof_rows)
# Transpose the list to match the desired structure
final_gof_list <- list(
  Participants = sapply(gof_list, `[[`, "Participants"),
  Trials = sapply(gof_list, `[[`, "Trials"),
  BIC = sapply(gof_list, `[[`, "BIC")
)

# Initialize an empty data frame for results
results_table <- data.frame(
  BIC = numeric(),
  Num_Variables = integer(),
  Participants = integer(),
  Trials = character(),
  # Demographic_Variables = character(),
  # Choice_Attributes = character(),
  # Interacted_With_Choice_Attributes = character(),
  stringsAsFactors = FALSE
)

for (i in 1:length(models)) {
  model <- models[[i]]
  formula <- formulas[[i]]
  bic <- AIC(model, k = log(nrow(model$model)))
  num_variables <- length(models[[i]]$estimate) - 1 # Subtracting sigma
  
  # Add to the results table
  results_table <- rbind(results_table, data.frame(
    BIC = bic,
    Num_Variables = num_variables,
    Participants = final_gof_list$Participants[i],
    Trials = final_gof_list$Trials[i],
    # Demographic_Variables = ifelse(any(grepl("age|male", deparse(formula))), "Yes", "No"),
    # Choice_Attributes = ifelse(any(grepl("chosen_i|chosen_e|not_chosen_i|not_chosen_e|not_chosen_u",
    #                                      deparse(formula))), "Yes", "No"),
    # Interacted_With_Choice_Attributes = ifelse(any(grepl("\\* \\(chosen_i", deparse(formula))), "Yes", "No"),
    stringsAsFactors = FALSE
  ))
}

# Define the row groups
results_table$Row_Group <- rep(c("PCs 1 and 2",
                                 "Income and STAI",
                                 "ZIP Poverty Level and STAI",
                                 "ZIP Median Income and STAI"), each = 4)
# Add a column for the row labels with the desired labels
results_table$Row_Label <- rep(c("(a) Base Model", "(b) + Demographics",
                                 "(c) + Choice Attributes",
                                 "(d) + Interaction with Anxiety"), 4)
# Create the table using the gt package
gt_table <- results_table %>%
  gt(rowname_col = "Row_Label", groupname_col = "Row_Group") %>%
  cols_label(
    BIC = "BIC",
    Num_Variables = "Regressors",
    Participants = "Participants",
    Trials = "Trials"
  )

# Print the table
xtable::xtable(data.frame(
  Model = results_table$Row_Label,
  BIC = results_table$BIC,
  Regressors = results_table$Num_Variables,
  Participants = results_table$Participants,
  Trials = results_table$Trials,
  stringsAsFactors = FALSE
))

```

# Appendix: Images

## The Eisenhower Matrix {#sec-eisenhower}

"Who can define for us with accuracy the difference between the long and short term! Especially whenever our affairs seem to be in crisis, we are almost compelled to give our first attention to the urgent present rather than to the important future."

\-\-- Dwight D. Eisenhower, 1961 address to the Century Association

![Source: https://todoist.com/productivity-methods/eisenhower-matrix](images/eisenhower-matrix.png){width="5.36in"}
{{< pagebreak >}}

## Pilot Experiment Image

![Game interface for Pilot Experiment. Participants had a queue with two tasks on top of the screen and a series of icons they must press in order to complete a task. The clocks (hearts, in this version) and dollar signs on a task represent the urgency and importance of the task, respectively. The right side of the screen displays a rounds counter (top) and a points counter (bottom).](images/totalice.jpeg){#fig-pilot-exp}

{{< pagebreak >}}

## Priority Queuing

A list can contain an arbitrary number of tasks and the priority of each task is an integer drawn from some distribution. The tasks are set to arrive with the rate $\lambda$ following a Poisson dynamics with exponential arrival time distribution and they are executed with rate $\mu$ by always choosing the one with the highest priority.

![Sample Queue](images/prioq-illustration.png){width="3.2in"}

{{< pagebreak >}}

## Principal Component Analysis for Pilot Experiment

```{r}
#| label: fig-loadings
#| eval: false
#| fig-cap: "Heatmap of component loadings for the pilot experiment. Each row corresponds to a variable, and each column corresponds to a PC The color of each cell indicates the loading of the variable on the PC, with red indicating high positive loadings, and white indicating negative loadings."

# Extract the loadings
loadings <- as.matrix(qualtrics.var)
# Create the heatmap
heatmap(loadings)

```

{{< pagebreak >}}

## Factor Analysis for Experiment 1

@fig-mice offers a visual representation of the imputation process. The intermingling of different imputation streams indicates a successful multiple imputation process, suggesting that the chains have converged. Additionally, we expect no visible trends in the later iterations, indicating that the imputations have reached a stable solution.

```{r}
#| label: fig-mice
#| fig-cap: "Visual representation of the MICE imputation process. The left plots show the mean of the imputed values across iterations, while the right plots display the corresponding standard deviations. The intermingling of different imputation streams suggests successful convergence of the chains."
#| layout-nrow: 7
#| fig-subcap:
#|  - ""

plot(imputed_data)

```

Next, we conducted Factor Analysis on the complete datasets generated by the MICE procedure. The output below shows the factor loadings, which represent the correlations between the observed variables and the factors. High absolute values indicate a strong relationship with the factor. Next, we will examine the factor loadings in a more interpretable format by creating a loading plot. @fig-exp1-loadings displays the loadings of each variable on each factor, facilitating the interpretation of the factors. Variables with high loadings on the same factor are likely to be related to each other and represent the same underlying construct.

```{r}
#| label: fig-exp1-loadings
#| fig-cap: "Heatmap of factor loadings for Experiment 1. Each row corresponds to a variable, and each column corresponds to a factor. The color of each cell indicates the loading of the variable on the factor, with red indicating high positive loadings, and white indicating negative loadings."

# Extract the loadings
loadings <- as.matrix(poverty3$loadings)
# Create the heatmap
heatmap(loadings)

```


# Appendix: Documentation

## Questionnaires {#sec-questionnaires}

<!-- ## IRB -->
